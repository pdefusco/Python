{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron in KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Simple MLP for MNIST image data prediction to showcase Keras basic functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, \n",
    "                               '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, \n",
    "                               '%s-images-idx3-ubyte' % kind)\n",
    "        \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', \n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, \n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", \n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, \n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255.) - .5) * 2\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('image_datasets', kind='train')\n",
    "print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_mnist('image_datasets', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean centering:\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_centered.shape, y_train.shape)\n",
    "print(X_test_centered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 labels:  [5 0 4]\n",
      "\n",
      "First 3 labels: (one-hot):\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#One hot encoding target feature i.e. digit class 1-9:\n",
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    "print('First 3 labels: ', y_train[:3])\n",
    "print('\\nFirst 3 labels: (one-hot):\\n', y_train_onehot[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a model one can easily initialize the Sequential object:\n",
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding INPUT layer - NB input_dim is equal to the shape of the input dataset\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=X_train_centered.shape[1], \n",
    "        kernel_initializer='glorot_uniform', \n",
    "        bias_initializer='zeros', \n",
    "        activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a hidden layer - NB the input_dim is equal to the number of units from the previous layer\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=50, #changed to 50\n",
    "        kernel_initializer='glorot_uniform', \n",
    "        bias_initializer='zeros', \n",
    "        activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the output layer - NB the number of units is equal to the number of class categories \n",
    "#in the one hot encoded y vector\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=y_train_onehot.shape[1], #same number \n",
    "        input_dim=50, #Same number as units in previous layer\n",
    "        kernel_initializer='glorot_uniform', \n",
    "        bias_initializer='zeros', \n",
    "        activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, setting the optimizer with SGD\n",
    "sgd_optimizer = keras.optimizers.SGD(lr=0.001, decay=1e-7, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last step: compiling the model:\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical cross entropy is the cost function for logistic regression generalized for multiclass problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.8981 - val_loss: 0.4544\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 1s 28us/step - loss: 0.4487 - val_loss: 0.3316\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 2s 31us/step - loss: 0.3627 - val_loss: 0.2832\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.3190 - val_loss: 0.2544\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.2904 - val_loss: 0.2348\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.2688 - val_loss: 0.2207\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.2516 - val_loss: 0.2089\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 2s 30us/step - loss: 0.2373 - val_loss: 0.1993\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s 30us/step - loss: 0.2249 - val_loss: 0.1908\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 2s 30us/step - loss: 0.2139 - val_loss: 0.1837\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s 31us/step - loss: 0.2041 - val_loss: 0.1775\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s 30us/step - loss: 0.1953 - val_loss: 0.1722\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1873 - val_loss: 0.1672\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1799 - val_loss: 0.1629\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.1732 - val_loss: 0.1593\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1670 - val_loss: 0.1557\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1611 - val_loss: 0.1522\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 32us/step - loss: 0.1557 - val_loss: 0.1493\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.1506 - val_loss: 0.1466\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 2s 28us/step - loss: 0.1458 - val_loss: 0.1439\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.1415 - val_loss: 0.1415\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1373 - val_loss: 0.1401\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.1333 - val_loss: 0.1375\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.1294 - val_loss: 0.1364\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 2s 30us/step - loss: 0.1260 - val_loss: 0.1346\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.1227 - val_loss: 0.1330\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 2s 30us/step - loss: 0.1194 - val_loss: 0.1316\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1164 - val_loss: 0.1306\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1134 - val_loss: 0.1297\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 2s 30us/step - loss: 0.1106 - val_loss: 0.1285\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 1s 26us/step - loss: 0.1080 - val_loss: 0.1268\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.1054 - val_loss: 0.1262\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.1030 - val_loss: 0.1253\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.1007 - val_loss: 0.1245\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.0984 - val_loss: 0.1241\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.0962 - val_loss: 0.1234\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 1s 27us/step - loss: 0.0941 - val_loss: 0.1225\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 2s 28us/step - loss: 0.0920 - val_loss: 0.1222\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 1s 28us/step - loss: 0.0901 - val_loss: 0.1213\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 2s 28us/step - loss: 0.0881 - val_loss: 0.1207\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s 28us/step - loss: 0.0862 - val_loss: 0.1202\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 2s 28us/step - loss: 0.0845 - val_loss: 0.1203\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 2s 28us/step - loss: 0.0827 - val_loss: 0.1190\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 2s 28us/step - loss: 0.0810 - val_loss: 0.1187\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.0793 - val_loss: 0.1186\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.0777 - val_loss: 0.1182\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.0762 - val_loss: 0.1182\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.0747 - val_loss: 0.1174\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.0732 - val_loss: 0.1173\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 29us/step - loss: 0.0718 - val_loss: 0.1168\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model:\n",
    "history = model.fit(X_train_centered, y_train_onehot, batch_size=100, epochs=50, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is converging to a training loss of 0.07 and a validation loss of 0.11. Let's see if we can do better with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/60\n",
      "54000/54000 [==============================] - 3s 49us/step - loss: 0.0722 - val_loss: 0.1166\n",
      "Epoch 2/60\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.0696 - val_loss: 0.1160\n",
      "Epoch 3/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0671 - val_loss: 0.1165\n",
      "Epoch 4/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0647 - val_loss: 0.1152\n",
      "Epoch 5/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0622 - val_loss: 0.1166\n",
      "Epoch 6/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0599 - val_loss: 0.1161\n",
      "Epoch 7/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0579 - val_loss: 0.1153\n",
      "Epoch 8/60\n",
      "54000/54000 [==============================] - 3s 49us/step - loss: 0.0559 - val_loss: 0.1147\n",
      "Epoch 9/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0540 - val_loss: 0.1139\n",
      "Epoch 10/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0521 - val_loss: 0.1145\n",
      "Epoch 11/60\n",
      "54000/54000 [==============================] - 3s 46us/step - loss: 0.0503 - val_loss: 0.1142\n",
      "Epoch 12/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0487 - val_loss: 0.1142\n",
      "Epoch 13/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0471 - val_loss: 0.1143\n",
      "Epoch 14/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0455 - val_loss: 0.1152\n",
      "Epoch 15/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0440 - val_loss: 0.1140\n",
      "Epoch 16/60\n",
      "54000/54000 [==============================] - 3s 49us/step - loss: 0.0427 - val_loss: 0.1144\n",
      "Epoch 17/60\n",
      "54000/54000 [==============================] - 3s 49us/step - loss: 0.0413 - val_loss: 0.1158\n",
      "Epoch 18/60\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.0400 - val_loss: 0.1152\n",
      "Epoch 19/60\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.0387 - val_loss: 0.1148\n",
      "Epoch 20/60\n",
      "54000/54000 [==============================] - 3s 59us/step - loss: 0.0375 - val_loss: 0.1157\n",
      "Epoch 21/60\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.0363 - val_loss: 0.1164\n",
      "Epoch 22/60\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.0352 - val_loss: 0.1155\n",
      "Epoch 23/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0342 - val_loss: 0.1167\n",
      "Epoch 24/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0330 - val_loss: 0.1160\n",
      "Epoch 25/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0320 - val_loss: 0.1169\n",
      "Epoch 26/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0310 - val_loss: 0.1157\n",
      "Epoch 27/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0302 - val_loss: 0.1174\n",
      "Epoch 28/60\n",
      "54000/54000 [==============================] - 2s 46us/step - loss: 0.0292 - val_loss: 0.1176\n",
      "Epoch 29/60\n",
      "54000/54000 [==============================] - 2s 46us/step - loss: 0.0283 - val_loss: 0.1183\n",
      "Epoch 30/60\n",
      "54000/54000 [==============================] - 3s 46us/step - loss: 0.0275 - val_loss: 0.1191\n",
      "Epoch 31/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0267 - val_loss: 0.1188\n",
      "Epoch 32/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0259 - val_loss: 0.1193\n",
      "Epoch 33/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0251 - val_loss: 0.1180\n",
      "Epoch 34/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0245 - val_loss: 0.1200\n",
      "Epoch 35/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0238 - val_loss: 0.1196\n",
      "Epoch 36/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0231 - val_loss: 0.1196\n",
      "Epoch 37/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0224 - val_loss: 0.1215\n",
      "Epoch 38/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0218 - val_loss: 0.1207\n",
      "Epoch 39/60\n",
      "54000/54000 [==============================] - 3s 49us/step - loss: 0.0212 - val_loss: 0.1210\n",
      "Epoch 40/60\n",
      "54000/54000 [==============================] - 3s 48us/step - loss: 0.0206 - val_loss: 0.1211\n",
      "Epoch 41/60\n",
      "54000/54000 [==============================] - 3s 49us/step - loss: 0.0200 - val_loss: 0.1220\n",
      "Epoch 42/60\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0195 - val_loss: 0.1224\n",
      "Epoch 43/60\n",
      "54000/54000 [==============================] - 2s 46us/step - loss: 0.0190 - val_loss: 0.1223\n",
      "Epoch 44/60\n",
      "54000/54000 [==============================] - 2s 46us/step - loss: 0.0185 - val_loss: 0.1230\n",
      "Epoch 45/60\n",
      "54000/54000 [==============================] - 2s 46us/step - loss: 0.0180 - val_loss: 0.1233\n",
      "Epoch 46/60\n",
      "54000/54000 [==============================] - 2s 46us/step - loss: 0.0176 - val_loss: 0.1233\n",
      "Epoch 47/60\n",
      "54000/54000 [==============================] - 3s 46us/step - loss: 0.0171 - val_loss: 0.1245\n",
      "Epoch 48/60\n",
      "54000/54000 [==============================] - 3s 46us/step - loss: 0.0167 - val_loss: 0.1237\n",
      "Epoch 49/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0162 - val_loss: 0.1245\n",
      "Epoch 50/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0158 - val_loss: 0.1246\n",
      "Epoch 51/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0154 - val_loss: 0.1249\n",
      "Epoch 52/60\n",
      "54000/54000 [==============================] - 3s 47us/step - loss: 0.0151 - val_loss: 0.1257\n",
      "Epoch 53/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0147 - val_loss: 0.1261\n",
      "Epoch 54/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0144 - val_loss: 0.1272\n",
      "Epoch 55/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0141 - val_loss: 0.1267\n",
      "Epoch 56/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0137 - val_loss: 0.1268\n",
      "Epoch 57/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0134 - val_loss: 0.1274\n",
      "Epoch 58/60\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.0131 - val_loss: 0.1274\n",
      "Epoch 59/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0128 - val_loss: 0.1282\n",
      "Epoch 60/60\n",
      "54000/54000 [==============================] - 2s 44us/step - loss: 0.0125 - val_loss: 0.1282\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model:\n",
    "history = model.fit(X_train_centered, y_train_onehot, batch_size=50, epochs=60, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above reached minimum validation loss around the 39th epoch. At that stage, it reached a training loss of 0.02. We are overfitting a little bit. Most importantly, it seems that the validation loss is unchanged from the previous model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further hyperparameter tuning would be needed to finalize the model. We could change values for momentum, weight decay, number of hidden units, and learning rage. Now we create some model evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = correct_preds / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 predictions:  [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "print('First 3 predictions: ', y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.605%\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy: {}%'.format(train_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict_classes(X_test_centered, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = correct_preds / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.21%\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %.2f%%' %(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
