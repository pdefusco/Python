{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Mechanics (Practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: practice notebook to demo key aspects of the TF library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of constant:  Tensor(\"Rank:0\", shape=(), dtype=int32)\n",
      "Shape of constant:  (4,)\n"
     ]
    }
   ],
   "source": [
    "#A tensor is a data structure similar to an array of d dimensions. \n",
    "#We define a graph and then obtain tensor rank and shape:\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    #Defining constants - different from placeholders as the data structure has been initialized with values\n",
    "    t = tf.constant([1,2,3,4])\n",
    "    #Getting rank of constant\n",
    "    r = tf.rank(t)\n",
    "    #Getting shape of constant\n",
    "    s = t.get_shape()\n",
    "    \n",
    "    print('Rank of constant: ', r)\n",
    "    print('Shape of constant: ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1\n"
     ]
    }
   ],
   "source": [
    "#Notice the rank was not printed because it needs to be executed as part of graph execution:\n",
    "#We create a session and pass the graph we created as argument:\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(\"Rank:\", r.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The key objective of TF is to create a graph and easily calculate gradients at each node. \n",
    "#### The individual steps for building and compiling a graph are:\n",
    "    1 Instantiate a new and empty graph\n",
    "    2 Add nodes (tensors and operations) to the graph\n",
    "    3 Execute the graph:\n",
    "        a. Start a new session\n",
    "        b. Initialize the variables in a graph\n",
    "        c. Run the computation graph in this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreating the above process:\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name = 'a')\n",
    "    b = tf.constant(2, name = 'b')\n",
    "    c = tf.constant(3, name = 'c')\n",
    "    \n",
    "    z = a*b + c    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print('output: ', sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New graph using placeholders:\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    #Creating nodes with placeholders\n",
    "    tf_a = tf.placeholder(tf.int32, shape=[], name = 'tf_a') #Notice the shape is undefined\n",
    "    tf_b = tf.placeholder(tf.int32, shape=[], name = 'tf_b')\n",
    "    tf_c = tf.placeholder(tf.int32, shape=[], name = 'tf_c')#This placeholder has rank 3\n",
    "    #Defining computation nodes\n",
    "    r1 = tf_a-tf_b\n",
    "    r2 = 2*r1\n",
    "    z = r2 + tf_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z:  0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    #The below dictionary is used to set placeholder values with data arrays\n",
    "    feed = {tf_a:1, tf_b:2, tf_c:2}\n",
    "    print('z: ', sess.run(z, feed_dict=feed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also set placeholders for variables of varying size:\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(tf.float32, shape=[None, 2], name='tf_x')\n",
    "    x_mean = tf.reduce_mean(tf_x, axis=0, name='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding data with shape:  (5, 2)\n",
      "Result:  [0.62 0.47]\n",
      "Feeding data with shape:  (10, 2)\n",
      "Result:  [0.46 0.49]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    x1 = np.random.uniform(low=0, high=1, size=(5,2)) #size array dim 1 is 5 and dim 2 has to be set to 2\n",
    "    print('Feeding data with shape: ', x1.shape)\n",
    "    print('Result: ', sess.run(x_mean, feed_dict={tf_x:x1}))\n",
    "    \n",
    "    x2 = np.random.uniform(low=0, high=1, size=(10,2)) #size array dim 1 changed but dim 2 did not\n",
    "    print('Feeding data with shape: ', x2.shape)\n",
    "    print('Result: ', sess.run(x_mean, feed_dict={tf_x:x2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables: two ways to create them and/or use them:\n",
    "        1 tf.Variable(<initial-value>, name='variable_name')\n",
    "        2 tf.get_variable(name, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(2, 4) dtype=int64_ref>\n"
     ]
    }
   ],
   "source": [
    "#Defining variables:\n",
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w = tf.Variable(np.array([[1,2,3,4], [5,6,7,8]]), name='w')\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: variables are not created in memory until they are initialized with the global_variables_initializer function. Variable values are not set until initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Scoping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'net_a/layer-1/weights:0' shape=(10, 4) dtype=float32_ref> \n",
      " <tf.Variable 'net_a/layer-2/weights:0' shape=(20, 10) dtype=float32_ref> \n",
      " <tf.Variable 'net_b/layer-3/Variable:0' shape=(10, 10) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "#Variables can be scoped within a network by means of the variable_scope function:\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    \n",
    "    with tf.variable_scope('net_a'):\n",
    "        \n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w1 = tf.Variable(tf.random_normal(shape=(10,4)), name='weights')\n",
    "            \n",
    "        with tf.variable_scope('layer-2'):\n",
    "            w2 = tf.Variable(tf.random_normal(shape=(20,10)), name='weights')\n",
    "            \n",
    "    with tf.variable_scope('net_b'):\n",
    "        \n",
    "        with tf.variable_scope('layer-3'):\n",
    "            w3 = tf.Variable(tf.random_normal(shape=(10,10), name='weights'))\n",
    "\n",
    "print(w1,'\\n',w2,'\\n',w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Network by Reusing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to create classifier:\n",
    "\n",
    "def build_classifier(data, labels, n_classes=2):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    #Notice: using get_variable to create a new variable\n",
    "    #Also notice the data type is tf.float32 not just float32\n",
    "    weights = tf.get_variable(name='weights', shape=(data_shape[1], n_classes), dtype=tf.float32) \n",
    "    bias = tf.get_variable(name='bias', initializer=tf.zeros(shape=n_classes))\n",
    "    logits = tf.add(tf.matmul(data, weights), bias, name='logits')\n",
    "    \n",
    "    return logits, tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to generate data from subnetwork:\n",
    "\n",
    "def build_generator(data, n_hidden):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    \n",
    "    w1 = tf.Variable(tf.random_normal(shape=(data_shape[1], n_hidden)), name='w1')\n",
    "    b1 = tf.Variable(tf.zeros(shape=n_hidden), name='b1')\n",
    "    hidden = tf.add(tf.matmul(data, w1), b1, name = 'hidden_pre_activation')\n",
    "    hidden = tf.nn.relu(hidden, 'hidden_activation')\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_normal(shape=(n_hidden, data_shape[1])), name='w2')\n",
    "    b2 = tf.Variable(tf.zeros(shape=data_shape[1]), name='b2')\n",
    "    output = tf.add(tf.matmul(hidden, w2), b2, name='output')\n",
    "    \n",
    "    return output, tf.nn.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Graph:\n",
    "\n",
    "batch_size = 64\n",
    "g =  tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size,100), dtype = tf.float32, name='tf_X')\n",
    "    \n",
    "    #Building the generator for the subgraph:\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "        \n",
    "    #Building the classifier:\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        cls_out1 = build_classifier(data=tf_X, labels = tf.ones(shape=batch_size))\n",
    "        \n",
    "        #Reusing the same classifier for generated data:\n",
    "        scope.reuse_variables()\n",
    "        cls_out2 = build_classifier(data=gen_out1[1], labels = tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2,) for Tensor 'tf_X:0', which has shape '(64, 100)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b1e5ac2d7cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_X\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_out2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1076\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (2,) for Tensor 'tf_X:0', which has shape '(64, 100)'"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    feed = {tf_X:[3,4]}\n",
    "    \n",
    "    print(sess.run(cls_out2, feed_dict=feed))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
