{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and Cleaning Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook gives an introduction to getting raw data in JSON format and converting it to a format that is easily\n",
    "understandable by libraries such as Pandas and NumPy. We clean the data and demonstrate how to deal with missing values.\n",
    "Outline:\n",
    "    Get raw JSON data\n",
    "    Visualize data\n",
    "    Load data to pandas Dataframe\n",
    "    Handle missing values using various methods\n",
    "    Detect and remove outliers\n",
    "    Correlation\n",
    "    Plot heatmap for correlation\n",
    "    Statistical analysis\n",
    "    Percentile and Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get beer reviews data from Prof. Julian McAuley's website (UC San Diego)\n",
    "# http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in urllib.request.urlopen(fname):\n",
    "    yield eval(l)\n",
    "# Yield is a keyword that is used like return, except the function will return a generator.\n",
    "# Refer - http://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do-in-python for more details on this keyword\n",
    "\n",
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'data' variable now contains JSON data\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of beer reviews that we have\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of features\n",
    "# Does not count the number of sub-features (or nested features). E.g. - mday, min, mon, sec etc \n",
    "len(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Restricting number of samples for simplicity and quick execution\n",
    "import random\n",
    "random.shuffle(data) # Shuffle the data so that we are more likely to get a true picture of the data\n",
    "data = data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking just two features and plotting them\n",
    "# This will also give us an idea if the two features taken are somehow correlated\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [d['beer/ABV'] for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "plt.scatter(x,y) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We used scatter, because a normal plot wouldn't have made much sense\n",
    "plt.plot(x,y) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Okay, so they were not correlated much.\n",
    "# Taste should be a better indication of the overall rating, right?\n",
    "\n",
    "x = [d['review/taste'] for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "# Bingo! More positive correlation than the last case for sure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we need just ABV (Alcohol By Volume) and the overall beer rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How scikit-learn expects data?\n",
    "# X = input - set of features that we have\n",
    "# y = output - the prediction that we need to make (can be real valued or discrete)\n",
    "# e.g. - Given an email, predict spam (1) or not spam (0). Here X = email, y = spam/not spam: Classification Problem\n",
    "# e.g. - Given area of the house in square feet, predict the price of the house\n",
    "# X = area in square feet, y = Price: Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What if ABV values is missing from some reviews?\n",
    "X = [d['beer/ABV'] if 'beer/ABV' in d else 5 for d in data] # Replace the value by 5 whereever ABV value is missing\n",
    "y = [d['review/overall'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Better would be to substitute by mean\n",
    "\n",
    "# find the mean\n",
    "sum_abv = 0.0\n",
    "for d in data:\n",
    "    if 'beer/ABV' in d:\n",
    "        sum_abv += d['beer/ABV']\n",
    "mean_abv = sum_abv/len(data)\n",
    "\n",
    "X = [d['beer/ABV'] if 'beer/ABV' in d else mean_abv for d in data]\n",
    "y = [d['review/overall'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "pd_df = pandas.DataFrame(data)\n",
    "pd_df = pd_df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if there are any values of ABV which are null/empty/NaN\n",
    "null_cols = pandas.isnull(pd_df['beer/ABV'])\n",
    "print (np.sum(null_cols == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No review with invalid ABV value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What about reviewer's age?\n",
    "null_cols = pandas.isnull(pd_df['user/ageInSeconds'])\n",
    "print (np.sum(null_cols == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# short demonstration on how to handle missing data before we use it on Beer reviews data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary with data of few famous TV series characters\n",
    "dict = {\"name\": [\"Jon\", \"Penny\", \"Ross\", \"Sansa\"],\n",
    "       \"age\": [25, 33, 41, None], # Note the 'None' here\n",
    "       \"gender\": ['M', 'F', 'M', 'F'] }\n",
    "\n",
    "tv_chars = pd.DataFrame(dict)\n",
    "print (tv_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv_chars.fillna(tv_chars.mean())\n",
    "# takes the mean of ages and puts it as Sansa's age!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or you can interpolate!\n",
    "\n",
    "dict = {\"name\": [\"Jon\", \"Penny\", \"Ross\", \"Sansa\"],\n",
    "       \"age\": [25, 33, 41, None], # Note the 'None' here\n",
    "       \"gender\": ['M', 'F', 'M', 'F'] }\n",
    "\n",
    "tv_chars = pd.DataFrame(dict)\n",
    "tv_chars.fillna(tv_chars.interpolate())\n",
    "\n",
    "# Note - output can be different than the one using mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Back to the Beer reviews data we were looking at\n",
    "\n",
    "# Fill NA/NaN values using the specified method\n",
    "pd_df.fillna(0)\n",
    "# This method works in most cases, but should be avoided. Better ways to deal with null values are:\n",
    "# -> Fill with that column's mean\n",
    "# -> Drop the row altogether (provided null values constitute a small subset of the total sample size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filling with column's mean\n",
    "pd_df.fillna(pd_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seaborn is an interesting library which allows us to plot confusion matrices and heatmaps\n",
    "import seaborn as sns\n",
    "\n",
    "# Get all correlations\n",
    "corr = pd_df.corr()\n",
    "# Plot the heatmap\n",
    "corr_plot = sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values).get_figure()\n",
    "# Save the figure on disk and view it\n",
    "corr_plot.savefig('./correlation_matrix.png', dpi=1024, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finding and Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create example dataset of normally distributed data. \n",
    "df= pd.DataFrame({'Data':np.random.normal(size=200)})  \n",
    "\n",
    "# keep only the ones that are within +3 to -3 standard deviations in the column 'Data'.\n",
    "df[np.abs(df.Data-df.Data.mean())<=(3*df.Data.std())] \n",
    "\n",
    "# or if you prefer the other way around\n",
    "df[~(np.abs(df.Data-df.Data.mean())>(3*df.Data.std()))] "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "data = {'Category': ['cat2','cat1','cat2','cat1','cat2','cat1','cat2','cat1','cat1','cat1','cat2'],\n",
    "        'values': [1,2,3,1,2,3,1,2,3,5,1]}\n",
    "my_data = pd.DataFrame(data)\n",
    "my_data.groupby('Category').mean()\n",
    "\n",
    "# Finding p-values\n",
    "cat1 = my_data[my_data['Category']=='cat1']\n",
    "cat2 = my_data[my_data['Category']=='cat2']\n",
    "\n",
    "ttest_ind(cat1['values'], cat2['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding percentiles \n",
    "\n",
    "a = np.array([[10, 7, 4], [3, 2, 1]])\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.percentile(a, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.percentile(a, 50, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.percentile(a, 50, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.percentile(a, 50, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quantiles\n",
    "from pandas import DataFrame\n",
    "df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
    "                   columns=['a', 'b'])\n",
    "print (df)\n",
    "df.quantile(.1)\n",
    "df.quantile([.1, .5])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
