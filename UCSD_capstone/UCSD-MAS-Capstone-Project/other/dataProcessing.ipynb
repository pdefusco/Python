{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook integrate data from different sources\n",
    "\n",
    "the notebook uses code developed in different notebooks to do all data processing in one place and output the master file\n",
    "\n",
    "more work will need to be done to rearrange the order in which some of \n",
    "these operations are done - everything that can be done individually on the listings or calendar dataframes should be done there and not on the entire master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv('production_data/original_data/listings.csv')\n",
    "#list_summ = pd.read_csv('inside_airbnb/listings_summ.csv')\n",
    "#neighborhoods = pd.read_csv('inside_airbnb/neighbourhoods.csv')\n",
    "#reviews = pd.read_csv('inside_airbnb/reviews.csv')\n",
    "#reviews_summ = pd.read_csv('inside_airbnb/reviews_summ.csv')\n",
    "calendar = pd.read_csv('production_data/original_data/calendar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calendar Preprocessing & New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this cell takes columns created in calendarConstruction nb\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar['month'] = calendar['date'].apply(lambda x: x.month)\n",
    "calendar['day'] = calendar['date'].apply(lambda x: x.day)\n",
    "calendar['holiday'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal = calendar.copy()\n",
    "cal['price'] = cal['price'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "#Transform Price from Object to Numeric Data Type\n",
    "cal['price'] = cal['price'].apply(pd.to_numeric, errors='coerce')\n",
    "cal['price'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Just using the calendar listingid, date and price to merge with listings\n",
    "c = cal.loc[cal.available!='f']\n",
    "c = c[['listing_id','date','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listings Preprocessing & New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings = listings.loc[listings.room_type == 'Entire home/apt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now cells taken from Amenities Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_amenities = set()\n",
    "\n",
    "for idx in listings['amenities'].map(string_to_set).index:\n",
    "    all_amenities = all_amenities.union(listings['amenities'].map(string_to_set)[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_amenities_dict = {}\n",
    "count = 0\n",
    "\n",
    "for c in all_amenities:\n",
    "    all_amenities_dict[c] = count\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def amenities_one_hot_encode(x):\n",
    "    vec = np.zeros((len(all_amenities), 1))\n",
    "    \n",
    "    for asset in x:\n",
    "        idx = all_amenities_dict[asset]\n",
    "        vec[idx] = 1\n",
    "        \n",
    "    return vec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings['amenities_set'] = listings['amenities'].map(string_to_set)\n",
    "listings['amenities_encoding'] = listings['amenities_set'].map(amenities_one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_amenity(x, amen_):\n",
    "    if amen_ in x:\n",
    "        return 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for amen in all_amenities:\n",
    "    listings['has' + amen] = 0\n",
    "    listings['has' + amen] = listings['amenities_set'].map(lambda x: has_amenity(x, amen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_amenties_list = []\n",
    "for amen in all_amenities:\n",
    "    has_amenties_list.append('has' + amen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings[has_amenties_list] = listings[has_amenties_list].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comma_split_sum(x):\n",
    "    b = x.split(',')\n",
    "    v = ''\n",
    "    \n",
    "    for h in b:\n",
    "        v = v + h\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings['numerical_price'] = listings['price'].map(lambda x: x[1:]).map(comma_split_sum).map(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master = listings.merge(c, how='inner', left_on='id', right_on='listing_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in master['transit']:\n",
    "    lst.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master['transit_length'] = (pd.Series([len(i) for i in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(text)/len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master['transit_variety'] = pd.Series([lexical_diversity(i) for i in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master['transit_vocab_size'] = pd.Series([len(set(i)) for i in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content)/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master['date'] = master['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_txt_features(pdseries):\n",
    "\n",
    "    textLength = []\n",
    "    textWordsPerc = []\n",
    "    textPuncPerc = []\n",
    "    textDigitsPerc = []\n",
    "\n",
    "    for i in pdseries:\n",
    "        tokens = re.findall(r\"[\\w']+|[.,!?;]\", i)\n",
    "        textLength.append(len(tokens))\n",
    "\n",
    "        if len(tokens)==0:\n",
    "            textWordsPerc.append(0)\n",
    "            textPuncPerc.append(0)\n",
    "            textDigitsPerc.append(0)\n",
    "\n",
    "        else:\n",
    "            textWordsPerc.append(len(i.split())/float(len(tokens)))\n",
    "            textPuncPerc.append(len(''.join(c for c in i if c in string.punctuation))/float(len(tokens)))\n",
    "            textDigitsPerc.append(len(''.join(c for c in i if c in string.digits))/float(len(tokens)))\n",
    "\n",
    "    print textLength, textWordsPerc, textPuncPerc, textDigitsPerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8b282b07f2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Careful when running this - might time out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_txt_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-c8cc07ceee53>\u001b[0m in \u001b[0;36mcreate_txt_features\u001b[0;34m(pdseries)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdseries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"[\\w']+|[.,!?;]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtextLength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 're' is not defined"
     ]
    }
   ],
   "source": [
    "#Careful when running this - might time out\n",
    "for i in master.columns:\n",
    "    master[i] = create_txt_features(master[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now code taken from createFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in master['host_response_time']:\n",
    "    if i == None:\n",
    "        lst.append(None)\n",
    "    elif i =='within an hour':\n",
    "        lst.append(1)\n",
    "    elif i == 'within a day':\n",
    "        lst.append(24)\n",
    "    elif i == 'within a few hours':\n",
    "        lst.append(4)\n",
    "    elif i == 'a few days or more':\n",
    "        lst.append(50)\n",
    "if len(lst) == len(master['host_response_time']):\n",
    "    master['MaxResponseTimeHours'] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master['host_response_rate'] = master['host_response_rate'].astype(str).map(lambda x: x.lstrip('%'))\n",
    "master['host_response_rate'] = master['host_response_rate'].apply(pd.to_numeric, errors='coerce')\n",
    "master['host_response_rate'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst =[]\n",
    "for i in master['host_is_superhost']:\n",
    "    if i == None:\n",
    "        lst.append(None)\n",
    "    elif i =='t':\n",
    "        lst.append(1)\n",
    "    elif i == 'f':\n",
    "        lst.append(0)\n",
    "if len(lst) == len(master['host_is_superhost']):\n",
    "    master['host_is_superhost'] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in master['host_since']:\n",
    "    if i == None:\n",
    "        lst.append(None)\n",
    "    elif i!= None:\n",
    "        lst.append(datetime.strptime(i,'%Y-%m-%d'))\n",
    "if len(lst) == len(master['host_since']):\n",
    "    master['host_since'] = lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Simple Features by Multiplying and Dividing All Numerical Features (Cartesian Product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operating only on Master numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_num = master.select_dtypes(include=['float64','int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop columns that are not needed\n",
    "master_num = master_num.drop(columns=['scrape_id',\n",
    "'host_id','zipcode','latitude',\n",
    "'longitude','license','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_num = master_num.reset_index()\n",
    "master_num = master_num.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_num = master_num.replace([np.inf, -np.inf], np.nan)\n",
    "master_num = master_num.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_num['host_response_rate'] = pd.to_numeric(master_num['host_response_rate'],downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_num['neighbourhood_group_cleansed'] = pd.to_numeric(master_num['neighbourhood_group_cleansed'],downcast='unsigned')\n",
    "master_num['bathrooms'] = pd.to_numeric(master_num['bathrooms'],downcast='unsigned')\n",
    "master_num['bedrooms'] = pd.to_numeric(master_num['bedrooms'],downcast='unsigned')\n",
    "master_num['beds'] = pd.to_numeric(master_num['beds'],downcast='unsigned')\n",
    "master_num['square_feet'] = pd.to_numeric(master_num['square_feet'],downcast='unsigned')\n",
    "master_num['has_availability'] = pd.to_numeric(master_num['has_availability'],downcast='unsigned')\n",
    "master_num['review_scores_rating'] = pd.to_numeric(master_num['review_scores_rating'],downcast='unsigned')\n",
    "master_num['review_scores_accuracy'] = pd.to_numeric(master_num['review_scores_accuracy'],downcast='unsigned')\n",
    "master_num['review_scores_cleanliness'] = pd.to_numeric(master_num['review_scores_cleanliness'],downcast='unsigned')\n",
    "master_num['review_scores_checkin'] = pd.to_numeric(master_num['review_scores_checkin'],downcast='unsigned')\n",
    "master_num['review_scores_cleanliness'] = pd.to_numeric(master_num['review_scores_cleanliness'],downcast='unsigned')\n",
    "master_num['review_scores_communication'] = pd.to_numeric(master_num['review_scores_communication'],downcast='unsigned')\n",
    "master_num['review_scores_location'] = pd.to_numeric(master_num['review_scores_location'],downcast='unsigned')\n",
    "master_num['review_scores_value'] = pd.to_numeric(master_num['review_scores_value'],downcast='unsigned')\n",
    "master_num['reviews_per_month'] = pd.to_numeric(master_num['reviews_per_month'],downcast='unsigned')\n",
    "master_num['price_y'] = pd.to_numeric(master_num['price_y'],downcast='unsigned')\n",
    "master_num['transitTextWordsPerc'] = pd.to_numeric(master_num['transitTextWordsPerc'],downcast='unsigned')\n",
    "master_num['transitTextPuncPerc'] = pd.to_numeric(master_num['transitTextPuncPerc'],downcast='unsigned')\n",
    "master_num['transitTextDigitsPerc'] = pd.to_numeric(master_num['transitTextDigitsPerc'],downcast='unsigned')\n",
    "master_num['MaxResponseTimeHours'] = pd.to_numeric(master_num['MaxResponseTimeHours'],downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_mult = {}\n",
    "for i,k in enumerate(master_num.columns):\n",
    "    if i < 37:\n",
    "        for j,l in enumerate(master_num.columns):\n",
    "            col_name = str(k) + ' * ' + str(l)\n",
    "            dt_mult[col_name] = master_num[k]*master_num[l]\n",
    "            dt_mult['listing_id'] = master_num['listing_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_div = {}\n",
    "for i,k in enumerate(master_num.columns):\n",
    "    if i < 37:\n",
    "        for j,l in enumerate(master_num.columns):\n",
    "            col_name = str(k) + ' / ' + str(l)\n",
    "            dt_div[col_name] = master_num[k]/master_num[l]\n",
    "            dt_div['listing_id'] = master_num['listing_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features_dict = dict(dt_div.items() + dt_mult.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_new_features = pd.DataFrame(new_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will then need to load all into Spark in order to be able to join back with master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is where it will all be loaded and joined as spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a df named \"new_master\" will contain all the new columns obtained by the cartesian products plus the ones created "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15)\n",
    "pca.fit(final_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pca.components_)\n",
    "print(pca.explained_variance_ratio_) \n",
    "print(pca.singular_values_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Will need to do some of the segmentation done in the buildSegments notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#master.to_parquet('master.parquet', engine='fastparquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
