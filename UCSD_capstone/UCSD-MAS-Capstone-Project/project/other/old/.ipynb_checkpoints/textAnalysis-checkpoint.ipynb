{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to Explore Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used was created in the regressions notebook under the section dated 4/10/18 i.e. it is three dataframes of listings with average price for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting with listing descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings = pd.read_csv('Datasources/inside_airbnb/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'listing_url', u'scrape_id', u'last_scraped', u'name',\n",
       "       u'summary', u'space', u'description', u'experiences_offered',\n",
       "       u'neighborhood_overview', u'notes', u'transit', u'access',\n",
       "       u'interaction', u'house_rules', u'thumbnail_url', u'medium_url',\n",
       "       u'picture_url', u'xl_picture_url', u'host_id', u'host_url',\n",
       "       u'host_name', u'host_since', u'host_location', u'host_about',\n",
       "       u'host_response_time', u'host_response_rate', u'host_acceptance_rate',\n",
       "       u'host_is_superhost', u'host_thumbnail_url', u'host_picture_url',\n",
       "       u'host_neighbourhood', u'host_listings_count',\n",
       "       u'host_total_listings_count', u'host_verifications',\n",
       "       u'host_has_profile_pic', u'host_identity_verified', u'street',\n",
       "       u'neighbourhood', u'neighbourhood_cleansed',\n",
       "       u'neighbourhood_group_cleansed', u'city', u'state', u'zipcode',\n",
       "       u'market', u'smart_location', u'country_code', u'country', u'latitude',\n",
       "       u'longitude', u'is_location_exact', u'property_type', u'room_type',\n",
       "       u'accommodates', u'bathrooms', u'bedrooms', u'beds', u'bed_type',\n",
       "       u'amenities', u'square_feet', u'price', u'weekly_price',\n",
       "       u'monthly_price', u'security_deposit', u'cleaning_fee',\n",
       "       u'guests_included', u'extra_people', u'minimum_nights',\n",
       "       u'maximum_nights', u'calendar_updated', u'has_availability',\n",
       "       u'availability_30', u'availability_60', u'availability_90',\n",
       "       u'availability_365', u'calendar_last_scraped', u'number_of_reviews',\n",
       "       u'first_review', u'last_review', u'review_scores_rating',\n",
       "       u'review_scores_accuracy', u'review_scores_cleanliness',\n",
       "       u'review_scores_checkin', u'review_scores_communication',\n",
       "       u'review_scores_location', u'review_scores_value', u'requires_license',\n",
       "       u'license', u'jurisdiction_names', u'instant_bookable',\n",
       "       u'cancellation_policy', u'require_guest_profile_picture',\n",
       "       u'require_guest_phone_verification', u'calculated_host_listings_count',\n",
       "       u'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Text columns:\n",
    "space', u'description', u'experiences_offered',\n",
    "       u'neighborhood_overview', u'notes', u'transit', u'access',\n",
    "       u'interaction', u'house_rules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some basic data exploration to see what can be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_features = ['space', 'description', 'experiences_offered', 'neighborhood_overview', 'notes', 'transit', 'access', 'interaction', 'house_rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6608"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: space, Nulls Count: 1635,\n",
      "Column Name: description, Nulls Count: 2,\n",
      "Column Name: experiences_offered, Nulls Count: 0,\n",
      "Column Name: neighborhood_overview, Nulls Count: 2471,\n",
      "Column Name: notes, Nulls Count: 3375,\n",
      "Column Name: transit, Nulls Count: 2636,\n",
      "Column Name: access, Nulls Count: 2273,\n",
      "Column Name: interaction, Nulls Count: 2530,\n",
      "Column Name: house_rules, Nulls Count: 1642,\n"
     ]
    }
   ],
   "source": [
    "#How many rows are null\n",
    "for i in text_features:\n",
    "    print(\"Column Name: %s, Nulls Count: %i,\" %(i, listings[i].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Aquatica Waterpark, Sleep train Amphitheater, ...\n",
       "1    Your spacious room awaiting is with a Queen Si...\n",
       "2    This is an immaculate 3 bedroom, 2 1/2 bath co...\n",
       "3    This 2 Story TownHome  is close to Otay Ranch ...\n",
       "4    Hello; we are offering a private secluded bedr...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    stem = nltk.stem.SnowballStemmer('english')\n",
    "    text = text.lower()\n",
    "\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if token in string.punctuation: continue\n",
    "        yield stem.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(doc):\n",
    "    features = defaultdict(int)\n",
    "\n",
    "    for token in tokenize(doc):\n",
    "        features[token] += 1\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = map(vectorize, listings['description'].iloc[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(listings['description'].iloc[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x42 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf  = TfidfVectorizer()\n",
    "corpus = tfidf.fit_transform(listings['description'].iloc[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import unicodedata\\nfrom sklearn.base import BaseEstimator, TransformerMixin\\n\\n\\nclass TextNormalizer(BaseEstimator, TransformerMixin):\\n\\n    def __init__(self, language='english'):\\n        self.stopwords  = set(nltk.corpus.stopwords.words(language))\\n        self.lemmatizer = WordNetLemmatizer()\\n\\n    def is_punct(self, token):\\n        return all(\\n            unicodedata.category(char).startswith('P') for char in token\\n        )\\n\\n    def is_stopword(self, token):\\n        return token.lower() in self.stopwords\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import unicodedata\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class TextNormalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, language='english'):\n",
    "        self.stopwords  = set(nltk.corpus.stopwords.words(language))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def is_punct(self, token):\n",
    "        return all(\n",
    "            unicodedata.category(char).startswith('P') for char in token\n",
    "        )\n",
    "\n",
    "    def is_stopword(self, token):\n",
    "        return token.lower() in self.stopwords\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "            #('norm', TextNormalizer()),\n",
    "            ('tfidf', CountVectorizer(\n",
    "                                      preprocessor=None, lowercase=False)),\n",
    "            ('model', LatentDirichletAllocation(n_components=3)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00631008,  0.00633041,  0.98735952]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_transform(listings['description'].iloc[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45983179,  0.41599218,  0.48574323,  0.4935438 ,  0.42513109,\n",
       "         0.49232982,  0.46818727,  0.47510106,  0.46043541,  0.48181144,\n",
       "         0.46104118,  0.4672513 ,  0.46112946,  0.46781196,  0.48798804,\n",
       "         0.46004912,  0.45649502,  0.50714713,  0.45663872,  0.45149639,\n",
       "         0.48197087,  0.49384289,  0.47993457,  0.45393433,  0.47950532,\n",
       "         0.46759687,  0.47840348,  0.45564081,  0.46946214,  0.4471119 ,\n",
       "         0.46502624,  0.48493821,  0.47744945,  0.4695461 ,  0.51108699,\n",
       "         0.47885257,  0.48503963,  0.46520381,  0.49782072,  0.43956884,\n",
       "         0.45249155,  0.45283363,  0.45753455],\n",
       "       [ 0.46424561,  0.50247375,  0.47100837,  0.48647535,  0.48216857,\n",
       "         0.47226044,  0.50467765,  0.48286276,  0.4687636 ,  0.45562704,\n",
       "         0.48344338,  0.48210353,  0.46386891,  0.51272288,  0.48884232,\n",
       "         0.48880722,  0.49378582,  0.45475179,  0.49444937,  0.47259159,\n",
       "         0.49888637,  0.47874018,  0.47866714,  0.48707672,  0.48421653,\n",
       "         0.45703737,  0.48202433,  0.48472159,  0.45083924,  0.47388146,\n",
       "         0.49452251,  0.50548409,  0.50832395,  0.45368554,  0.45875777,\n",
       "         0.5240491 ,  0.47038515,  0.49837128,  0.49359211,  0.49692052,\n",
       "         0.49354405,  0.48052393,  0.47098366],\n",
       "       [ 1.26731192,  2.08099448,  2.04130501,  2.8532092 ,  2.04325194,\n",
       "         1.26873901,  1.23588611,  1.24264291,  1.25547683,  1.26123957,\n",
       "         1.30428005,  1.30964188,  1.26544955,  1.24040573,  1.28615441,\n",
       "         2.01659707,  1.24732454,  1.25360002,  1.25145772,  1.2094975 ,\n",
       "         2.03705076,  1.29995367,  1.27508405,  2.06863504,  1.2325402 ,\n",
       "         1.23271554,  1.24263474,  2.06695221,  1.26133572,  1.23290975,\n",
       "         1.29993214,  2.05344529,  1.22740085,  1.25471797,  2.03185689,\n",
       "         1.2252403 ,  1.23950358,  1.24419704,  1.19421788,  1.23570034,\n",
       "         1.28366036,  2.06429084,  1.23540776]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.steps[-1][1].components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for i in model.steps[-1][1].components_:\n",
    "    f=i.argsort()[:-(2 - 1): -1]\n",
    "    lst.append(f)\n",
    "    print f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], dtype=int64), array([], dtype=int64), array([], dtype=int64)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Recreating what I had done before losing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings['description'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings['description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = listings['description'].fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_vectorized = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.7,\n",
      "             learning_method='online', learning_offset=10.0,\n",
      "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=-1, n_topics=20, perp_tol=0.1,\n",
      "             random_state=100, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "lda_model = LatentDirichletAllocation(n_topics=20,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log Likelihood: ', -3209523.9166136212)\n",
      "('Perplexity: ', 850.69712423150474)\n",
      "{'learning_offset': 10.0, 'n_jobs': -1, 'topic_word_prior': None, 'perp_tol': 0.1, 'evaluate_every': -1, 'max_iter': 10, 'mean_change_tol': 0.001, 'batch_size': 128, 'max_doc_update_iter': 100, 'learning_decay': 0.7, 'n_components': 10, 'random_state': 100, 'doc_topic_prior': None, 'n_topics': 20, 'total_samples': 1000000.0, 'learning_method': 'online', 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "print(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Define Search Param\\nsearch_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\\n\\n# Init the Model\\nlda = LatentDirichletAllocation()\\n\\n# Init Grid Search Class\\nmodel = GridSearchCV(lda, param_grid=search_params)\\n\\n# Do the Grid Search\\nmodel.fit(data_vectorized)\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Define Search Param\n",
    "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Best Model - using original lda_mdoel for now\\nbest_lda_model = model.best_estimator_\\nbest_lda_model = lda_model\\n# Model Parameters\\nprint(\"Best Model\\'s Params: \", model.best_params_)\\n\\n# Log Likelihood Score\\nprint(\"Best Log Likelihood Score: \", model.best_score_)\\n\\n# Perplexity\\nprint(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Best Model - using original lda_mdoel for now\n",
    "best_lda_model = model.best_estimator_\n",
    "best_lda_model = lda_model\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(lda_model.n_topics)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(corpus))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic11</th>\n",
       "      <th>Topic12</th>\n",
       "      <th>Topic13</th>\n",
       "      <th>Topic14</th>\n",
       "      <th>Topic15</th>\n",
       "      <th>Topic16</th>\n",
       "      <th>Topic17</th>\n",
       "      <th>Topic18</th>\n",
       "      <th>Topic19</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
       "Doc0    0.00    0.00    0.00    0.90    0.00    0.00     0.0    0.00     0.0   \n",
       "Doc1    0.07    0.15    0.00    0.33    0.00    0.00     0.0    0.00     0.0   \n",
       "Doc2    0.00    0.00    0.28    0.24    0.00    0.00     0.0    0.00     0.0   \n",
       "Doc3    0.00    0.00    0.05    0.79    0.00    0.04     0.0    0.03     0.0   \n",
       "Doc4    0.03    0.00    0.00    0.60    0.01    0.17     0.0    0.00     0.0   \n",
       "\n",
       "      Topic9       ...        Topic11  Topic12  Topic13  Topic14  Topic15  \\\n",
       "Doc0    0.00       ...            0.0     0.00      0.0     0.00      0.0   \n",
       "Doc1    0.23       ...            0.0     0.03      0.0     0.00      0.0   \n",
       "Doc2    0.00       ...            0.0     0.08      0.0     0.00      0.0   \n",
       "Doc3    0.00       ...            0.0     0.00      0.0     0.08      0.0   \n",
       "Doc4    0.07       ...            0.0     0.03      0.0     0.00      0.0   \n",
       "\n",
       "      Topic16  Topic17  Topic18  Topic19  dominant_topic  \n",
       "Doc0     0.00      0.0     0.00      0.0               3  \n",
       "Doc1     0.18      0.0     0.00      0.0               3  \n",
       "Doc2     0.00      0.0     0.00      0.0              10  \n",
       "Doc3     0.00      0.0     0.00      0.0               3  \n",
       "Doc4     0.00      0.0     0.01      0.0               3  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_document_topic.index = [i for i in range(len(df_document_topic))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = df_document_topic.merge(listings, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAN DIEGO, SAN DIEGO TOURISM MARKETING DISTRIC...</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>strict</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>strict</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
       "0    0.00    0.00    0.00    0.90    0.00    0.00     0.0    0.00     0.0   \n",
       "1    0.07    0.15    0.00    0.33    0.00    0.00     0.0    0.00     0.0   \n",
       "2    0.00    0.00    0.28    0.24    0.00    0.00     0.0    0.00     0.0   \n",
       "3    0.00    0.00    0.05    0.79    0.00    0.04     0.0    0.03     0.0   \n",
       "4    0.03    0.00    0.00    0.60    0.01    0.17     0.0    0.00     0.0   \n",
       "\n",
       "   Topic9        ...          review_scores_value  requires_license  license  \\\n",
       "0    0.00        ...                         10.0                 f      NaN   \n",
       "1    0.23        ...                         10.0                 f      NaN   \n",
       "2    0.00        ...                          8.0                 f      NaN   \n",
       "3    0.00        ...                         10.0                 f      NaN   \n",
       "4    0.07        ...                          NaN                 f      NaN   \n",
       "\n",
       "                                  jurisdiction_names  instant_bookable  \\\n",
       "0  SAN DIEGO, SAN DIEGO TOURISM MARKETING DISTRIC...                 f   \n",
       "1                                                NaN                 f   \n",
       "2                                                NaN                 f   \n",
       "3                                                NaN                 f   \n",
       "4                                                NaN                 f   \n",
       "\n",
       "   cancellation_policy  require_guest_profile_picture  \\\n",
       "0             moderate                              f   \n",
       "1               strict                              f   \n",
       "2             flexible                              f   \n",
       "3             moderate                              f   \n",
       "4               strict                              f   \n",
       "\n",
       "   require_guest_phone_verification  calculated_host_listings_count  \\\n",
       "0                                 f                               2   \n",
       "1                                 f                               1   \n",
       "2                                 f                               1   \n",
       "3                                 f                               1   \n",
       "4                                 f                               2   \n",
       "\n",
       "   reviews_per_month  \n",
       "0               4.57  \n",
       "1               0.76  \n",
       "2               0.09  \n",
       "3               3.00  \n",
       "4                NaN  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adding some more basic features created on text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def create_txt_features(pdseries):\n",
    "\n",
    "    textLength = []\n",
    "    textWordsPerc = []\n",
    "    textPuncPerc = []\n",
    "    textDigitsPerc = []\n",
    "\n",
    "    for i in pdseries:\n",
    "        tokens = re.findall(r\"[\\w']+|[.,!?;]\", i)\n",
    "        textLength.append(len(tokens))\n",
    "\n",
    "        if len(tokens)==0:\n",
    "            textWordsPerc.append(0)\n",
    "            textPuncPerc.append(0)\n",
    "            textDigitsPerc.append(0)\n",
    "\n",
    "        else:\n",
    "            textWordsPerc.append(len(i.split())/float(len(tokens)))\n",
    "            textPuncPerc.append(len(''.join(c for c in i if c in string.punctuation))/float(len(tokens)))\n",
    "            textDigitsPerc.append(len(''.join(c for c in i if c in string.digits))/float(len(tokens)))\n",
    "\n",
    "    return textLength, textWordsPerc, textPuncPerc, textDigitsPerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(text)/len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def content_fraction(text):\\n    stopwords = nltk.corpus.stopwords.words('english')\\n    content = [w for w in text if w.lower() not in stopwords]\\n    return len(content)/len(text)\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content)/len(text)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in text_features:\n",
    "    out[i]=out[i].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['space',\n",
       " 'description',\n",
       " 'experiences_offered',\n",
       " 'neighborhood_overview',\n",
       " 'notes',\n",
       " 'transit',\n",
       " 'access',\n",
       " 'interaction',\n",
       " 'house_rules']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['space'])\n",
    "out['space_textLength'] = textLength\n",
    "out['space_textWordsPerc'] = textWordsPerc\n",
    "out['space_textPuncPerc'] = textPuncPerc\n",
    "out['space_textDigitsPerc'] = textDigitsPerc\n",
    "out['space_diversity'] = pd.Series([lexical_diversity(i) for i in out['space']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['description'])\n",
    "out['description_textLength'] = textLength\n",
    "out['description_textWordsPerc'] = textWordsPerc\n",
    "out['description_textPuncPerc'] = textPuncPerc\n",
    "out['description_textDigitsPerc'] = textDigitsPerc\n",
    "out['description_diversity'] = pd.Series([lexical_diversity(i) for i in out['description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['experiences_offered'])\n",
    "out['experiences_offered_textLength'] = textLength\n",
    "out['experiences_offered_textWordsPerc'] = textWordsPerc\n",
    "out['experiences_offered_textPuncPerc'] = textPuncPerc\n",
    "out['experiences_offered_textDigitsPerc'] = textDigitsPerc\n",
    "out['experiences_offered_diversity'] = pd.Series([lexical_diversity(i) for i in out['experiences_offered']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['neighborhood_overview'])\n",
    "out['neighborhood_overview_textLength'] = textLength\n",
    "out['neighborhood_overview_textWordsPerc'] = textWordsPerc\n",
    "out['neighborhood_overview_textPuncPerc'] = textPuncPerc\n",
    "out['neighborhood_overview_textDigitsPerc'] = textDigitsPerc\n",
    "out['neighborhood_overview_diversity'] = pd.Series([lexical_diversity(i) for i in out['neighborhood_overview']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['notes'])\n",
    "out['notes_textLength'] = textLength\n",
    "out['notes_textWordsPerc'] = textWordsPerc\n",
    "out['notes_textPuncPerc'] = textPuncPerc\n",
    "out['notes_textDigitsPerc'] = textDigitsPerc\n",
    "out['notes_diversity'] = pd.Series([lexical_diversity(i) for i in out['notes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['transit'])\n",
    "out['transit_textLength'] = textLength\n",
    "out['transit_textWordsPerc'] = textWordsPerc\n",
    "out['transit_textPuncPerc'] = textPuncPerc\n",
    "out['transit_textDigitsPerc'] = textDigitsPerc\n",
    "out['transit_diversity'] = pd.Series([lexical_diversity(i) for i in out['transit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['access'])\n",
    "out['access_textLength'] = textLength\n",
    "out['access_textWordsPerc'] = textWordsPerc\n",
    "out['access_textPuncPerc'] = textPuncPerc\n",
    "out['access_textDigitsPerc'] = textDigitsPerc\n",
    "out['access_diversity'] = pd.Series([lexical_diversity(i) for i in out['access']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['interaction'])\n",
    "out['interaction_textLength'] = textLength\n",
    "out['interaction_textWordsPerc'] = textWordsPerc\n",
    "out['interaction_textPuncPerc'] = textPuncPerc\n",
    "out['interaction_textDigitsPerc'] = textDigitsPerc\n",
    "out['interaction_diversity'] = pd.Series([lexical_diversity(i) for i in out['interaction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textLength, textWordsPerc, textPuncPerc, textDigitsPerc = create_txt_features(out['house_rules'])\n",
    "out['house_rules_textLength'] = textLength\n",
    "out['house_rules_textWordsPerc'] = textWordsPerc\n",
    "out['house_rules_textPuncPerc'] = textPuncPerc\n",
    "out['house_rules_textDigitsPerc'] = textDigitsPerc\n",
    "out['house_rules_diversity'] = pd.Series([lexical_diversity(i) for i in out['house_rules']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Aquatica Waterpark, Sleep train Amphitheater, ...\n",
       "1    Your spacious room awaiting is with a Queen Si...\n",
       "2    This is an immaculate 3 bedroom, 2 1/2 bath co...\n",
       "3    This 2 Story TownHome  is close to Otay Ranch ...\n",
       "4    Hello; we are offering a private secluded bedr...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(out['description'].head()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_grammar(pdseries):\n",
    "    \n",
    "    import nltk\n",
    "    from nltk.tag import pos_tag, map_tag\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for text in pdseries:\n",
    "        tokenized_text = nltk.word_tokenize(text.decode('utf-8'))\n",
    "        grammar = [i[1] for i in nltk.pos_tag(tokenized_text, tagset='universal')]\n",
    "        from collections import Counter\n",
    "        counter = Counter(grammar)\n",
    "        fr = pd.DataFrame(counter, index=[0])\n",
    "        df = pd.concat([df, fr], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = extract_grammar(out['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      .   ADJ   ADP  ADV  CONJ   DET  NOUN   NUM  PRON  PRT  VERB   X\n",
       "0  13.0   3.0   2.0  1.0   3.0   4.0  37.0   2.0   1.0  1.0   2.0 NaN\n",
       "1  13.0   6.0  10.0  6.0   2.0   4.0  32.0   3.0   3.0  2.0   6.0 NaN\n",
       "2   4.0   2.0   4.0  1.0   2.0   6.0  18.0   3.0   1.0  1.0   5.0 NaN\n",
       "3  18.0  11.0  15.0  4.0  13.0  11.0  83.0   5.0   NaN  2.0  18.0 NaN\n",
       "4  48.0  26.0  17.0  3.0   6.0   7.0  70.0  10.0   5.0  6.0   7.0 NaN"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Datasources/inside_airbnb/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id        int64\n",
       "id                int64\n",
       "date             object\n",
       "reviewer_id       int64\n",
       "reviewer_name    object\n",
       "comments         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92862, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4590"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews['listing_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_augmented = pd.read_csv('listings_augmented_2018-04-25-4-11.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_augmented = listings_augmented.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_augmented['listing_id'] = listings_augmented['listing_id'].astype(str)\n",
    "reviews['listing_id'] = reviews['listing_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_listings = listings_augmented.merge(reviews, how='right', left_on='listing_id',right_on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92862"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matching_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#out.to_csv('listings_withtopics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
