{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages and doing relevant cleaningÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from __future__ import print_function\n",
    "from statsmodels.compat import lzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_fit\n",
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "from statsmodels.graphics.regressionplots import plot_regress_exog\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "linear_regression = linear_model.LinearRegression(normalize=False, fit_intercept=True)\n",
    "def r2_est(X,y):\n",
    "    return r2_score(y, linear_regression.fit(X,y).predict(X))\n",
    "def r2_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, linear_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_validation import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "label_enc = LabelEncoder()\n",
    "label_bin = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_regression = linear_model.LassoLars(normalize=False, fit_intercept=True)\n",
    "def r2_lasso_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, lasso_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_regression = linear_model.Ridge(normalize=False, fit_intercept=True)\n",
    "def r2_ridge_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, ridge_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r2_gbd_est_two(X,y, X_new, y_new, loss_, _rate):\n",
    "    gbd = GradientBoostingRegressor(loss = loss_, learning_rate = _rate)\n",
    "    gbd.fit(X,y)\n",
    "    return gbd.score(X_new, y_new)\n",
    "\n",
    "def r2_gbd_est_two_huber(X,y, X_new, y_new):\n",
    "    return r2_gbd_est_two(X,y, X_new, y_new, 'huber', .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = pd.read_csv('listings_augmented_2018-04-29_V1.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dominant_Topic_feature_list = []\n",
    "Topic_feature_list = []\n",
    "\n",
    "for w in listings_augmented_2018.columns:\n",
    "    if 'Dominant_Topic' in w:\n",
    "        Dominant_Topic_feature_list.append(w)\n",
    "    if '-Topic' in w:\n",
    "        Topic_feature_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for (index, row) in listings_augmented_2018.iterrows():\n",
    "    if index not in range(4324, 4326):\n",
    "        df = df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = df\n",
    "listings_augmented_2018 = listings_augmented_2018.reset_index()\n",
    "listings_augmented_2018['Unnamed: 0'] = listings_augmented_2018.index\n",
    "listings_augmented_2018 = listings_augmented_2018.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018[Topic_feature_list] = listings_augmented_2018[Topic_feature_list].astype('float64')\n",
    "listings_augmented_2018[Dominant_Topic_feature_list] = listings_augmented_2018[Dominant_Topic_feature_list].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = listings_augmented_2018['host_verifications'].map(lambda x: x[1:-1]).map(lambda j: j.split(',')).map(lambda k: set(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_host_verifications = set()\n",
    "\n",
    "for w in a.index:\n",
    "    all_host_verifications = all_host_verifications.union(a[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_amenity(x, amen_):\n",
    "    if amen_ in x:\n",
    "        return 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in all_host_verifications:\n",
    "    listings_augmented_2018['uses' + w] = 0\n",
    "    listings_augmented_2018['uses' + w] = a.map(lambda x: has_amenity(x, w))\n",
    "    \n",
    "uses_verification_list = []\n",
    "for veri in all_host_verifications:\n",
    "    uses_verification_list.append('uses' + veri)\n",
    "\n",
    "listings_augmented_2018[uses_verification_list] = listings_augmented_2018[uses_verification_list].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_response_rate'] = listings_augmented_2018['host_response_rate'].astype(str).map(lambda x: x.rstrip(\"%\"))\n",
    "listings_augmented_2018['host_response_rate'] = listings_augmented_2018['host_response_rate'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['host_response_rate'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['host_acceptance_rate'] = listings_augmented_2018['host_acceptance_rate'].astype(str).map(lambda x: x.rstrip(\"%\"))\n",
    "listings_augmented_2018['host_acceptance_rate'] = listings_augmented_2018['host_acceptance_rate'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['host_acceptance_rate'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['extra_people'] = listings_augmented_2018['extra_people'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['extra_people'] = listings_augmented_2018['extra_people'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['extra_people'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['weekly_price'] = listings_augmented_2018['weekly_price'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['weekly_price'] = listings_augmented_2018['weekly_price'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['weekly_price'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['monthly_price'] = listings_augmented_2018['monthly_price'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['monthly_price'] = listings_augmented_2018['monthly_price'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['monthly_price'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['security_deposit'] = listings_augmented_2018['security_deposit'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['security_deposit'] = listings_augmented_2018['security_deposit'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['security_deposit'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['cleaning_fee'] = listings_augmented_2018['cleaning_fee'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['cleaning_fee'] = listings_augmented_2018['cleaning_fee'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['cleaning_fee'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['ones'] = np.ones(len(listings_augmented_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_is_superhost'] = label_bin.fit_transform(listings_augmented_2018.host_is_superhost)\n",
    "listings_augmented_2018['is_location_exact'] = label_bin.fit_transform(listings_augmented_2018.is_location_exact)\n",
    "listings_augmented_2018['host_identity_verified'] = label_bin.fit_transform(listings_augmented_2018.host_identity_verified)\n",
    "listings_augmented_2018['instant_bookable'] = label_bin.fit_transform(listings_augmented_2018.instant_bookable)\n",
    "listings_augmented_2018['require_guest_profile_picture'] = label_bin.fit_transform(listings_augmented_2018.require_guest_profile_picture)\n",
    "listings_augmented_2018['require_guest_phone_verification'] = label_bin.fit_transform(listings_augmented_2018.require_guest_phone_verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_resp_time_enc'] = label_enc.fit_transform(listings_augmented_2018['host_response_time'].astype(str))\n",
    "listings_augmented_2018['calendar_updated_enc'] = label_enc.fit_transform(listings_augmented_2018['calendar_updated'].astype(str))\n",
    "listings_augmented_2018['bed_type_enc'] = label_enc.fit_transform(listings_augmented_2018['bed_type'].astype(str))\n",
    "listings_augmented_2018['jurisdiction_names_enc'] = label_enc.fit_transform(listings_augmented_2018['jurisdiction_names'].astype(str))\n",
    "listings_augmented_2018['zipcode_enc'] = label_enc.fit_transform(listings_augmented_2018['zipcode'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_resp_time_enc'] = label_enc.fit_transform(listings_augmented_2018['host_response_time'].astype(str))\n",
    "listings_augmented_2018['calendar_updated_enc'] = label_enc.fit_transform(listings_augmented_2018['calendar_updated'].astype(str))\n",
    "listings_augmented_2018['bed_type_enc'] = label_enc.fit_transform(listings_augmented_2018['bed_type'].astype(str))\n",
    "listings_augmented_2018['jurisdiction_names_enc'] = label_enc.fit_transform(listings_augmented_2018['jurisdiction_names'].astype(str))\n",
    "listings_augmented_2018['zipcode_enc'] = label_enc.fit_transform(listings_augmented_2018['zipcode'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.drop(['neighbourhood_group_cleansed','square_feet','has_availability','license','weekly_price','monthly_price'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.drop(['host_response_time','calendar_updated', 'bed_type', 'jurisdiction_names', 'zipcode'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanka\\Anaconda2\\envs\\py27\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "listings_augmented_2018['distance from ocean'] = 0\n",
    "\n",
    "for w in listings_augmented_2018.index:\n",
    "    p = listings_augmented_2018['latitude'][w]\n",
    "    q = listings_augmented_2018['longitude'][w]\n",
    "    lon_diff = (q + 117.235585)*np.pi/180\n",
    "    lat_diff = (p - 32.802458)*np.pi/180\n",
    "    a = np.sin(lat_diff/2)**2 + np.cos(p*np.pi/180)*np.cos(32.802458*np.pi/180)*(np.sin(lon_diff/2)**2)\n",
    "    c = np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    d = 6371*c\n",
    "    listings_augmented_2018['distance from ocean'][w] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.fillna(value=listings_augmented_2018.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = listings_augmented_2018['price_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = listings_augmented_2018.drop('price_y', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features_five_new = ['access_._tokens_sum_ratio', 'access_ADP_tokens_sum_ratio', 'access_ADV_tokens_sum_ratio', 'access_CONJ_tokens_sum_ratio',\n",
    " 'access_DET_tokens_sum_ratio', 'access_PRON_tokens_sum_ratio', 'access_VERB_tokens_sum_ratio', 'access_X_tokens_sum_ratio','description_._tokens_sum_ratio',\n",
    " 'description_ADJ_tokens_sum_ratio', 'description_ADP_tokens_sum_ratio', 'description_CONJ_tokens_sum_ratio','description_DET_tokens_sum_ratio',\n",
    " 'description_NOUN_tokens_sum_ratio', 'description_NUM_tokens_sum_ratio', 'description_PRON_tokens_sum_ratio', 'description_VERB_tokens_sum_ratio',\n",
    " 'description_X_tokens_sum_ratio', 'house_rules_._tokens_sum_ratio', 'house_rules_ADP_tokens_sum_ratio', 'house_rules_ADV_tokens_sum_ratio',\n",
    " 'house_rules_CONJ_tokens_sum_ratio', 'house_rules_DET_tokens_sum_ratio', 'house_rules_NUM_tokens_sum_ratio', 'house_rules_PRON_tokens_sum_ratio',\n",
    " 'house_rules_X_tokens_sum_ratio', 'interaction_._tokens_sum_ratio', 'interaction_ADJ_tokens_sum_ratio', 'interaction_ADP_tokens_sum_ratio',\n",
    " 'interaction_CONJ_tokens_sum_ratio', 'interaction_DET_tokens_sum_ratio', 'interaction_NOUN_tokens_sum_ratio', 'interaction_NUM_tokens_sum_ratio',\n",
    " 'interaction_VERB_tokens_sum_ratio', 'neighborhood_overview_._tokens_sum_ratio', 'neighborhood_overview_ADJ_tokens_sum_ratio', 'neighborhood_overview_ADP_tokens_sum_ratio',\n",
    " 'neighborhood_overview_ADV_tokens_sum_ratio', 'neighborhood_overview_PRON_tokens_sum_ratio', 'neighborhood_overview_PRT_tokens_sum_ratio',\n",
    " 'neighborhood_overview_VERB_tokens_sum_ratio', 'notes_ADP_tokens_sum_ratio', 'notes_ADV_tokens_sum_ratio', 'notes_DET_tokens_sum_ratio',\n",
    " 'notes_NOUN_tokens_sum_ratio', 'notes_NUM_tokens_sum_ratio', 'notes_PRON_tokens_sum_ratio', 'notes_PRT_tokens_sum_ratio', 'notes_VERB_tokens_sum_ratio',\n",
    " 'notes_X_tokens_sum_ratio', 'space_._tokens_sum_ratio', 'space_ADP_tokens_sum_ratio', 'space_CONJ_tokens_sum_ratio', 'space_NOUN_tokens_sum_ratio',\n",
    " 'space_PRT_tokens_sum_ratio', 'space_VERB_tokens_sum_ratio', 'space_X_tokens_sum_ratio', 'transit_._tokens_sum_ratio', 'transit_ADJ_tokens_sum_ratio',\n",
    " 'transit_ADP_tokens_sum_ratio', 'transit_CONJ_tokens_sum_ratio', 'transit_DET_tokens_sum_ratio', 'transit_NOUN_tokens_sum_ratio',\n",
    " 'transit_NUM_tokens_sum_ratio', 'transit_PRON_tokens_sum_ratio', 'transit_PRT_tokens_sum_ratio', 'transit_VERB_tokens_sum_ratio',\n",
    " 'transit_X_tokens_sum_ratio', \"uses 'amex'\", \"uses 'linkedin'\", \"uses'email'\", \"uses 'sent_id'\", \"uses 'kba'\", \"uses 'jumio'\",\n",
    " \"uses'phone'\", \"uses 'reviews'\", \"uses 'manual_online'\", 'host_resp_time_enc', 'calendar_updated_enc', 'bed_type_enc', 'jurisdiction_names_enc',\n",
    " 'zipcode_enc', 'access-Topic1', 'access-Topic12', 'access-Topic13', 'access-Topic16', 'access-Topic3', 'access_ADJ', 'access_ADV',\n",
    " 'access_DET', 'access_KmeansCluster', 'access_NOUN', 'access_PRON', 'access_TextPuncPerc', 'access_TextWordsPerc', 'accommodates',\n",
    " 'availability_365', 'bathrooms', 'bedrooms', 'cleaning_fee', 'description-Topic12', 'description_.', 'description_ADJ', 'description_ADP',\n",
    " 'description_ADV', 'description_DET', 'description_KmeansCluster', 'description_LexicalDiversity', 'description_X', 'extra_people',\n",
    " 'host_id', 'host_response_rate', 'house_rules-Topic7', 'house_rules_ADP', 'house_rules_NUM', 'house_rules_PRT', 'house_rules_TextLength',\n",
    " 'interaction-Topic13', 'interaction-Topic9', 'interaction_ADJ', 'interaction_PRT', 'interaction_TextDigitsPerc', 'interaction_TextPuncPerc',\n",
    " 'interaction_VERB', 'latitude', 'longitude', 'minimum_nights', 'neighborhood_overview-Topic14', 'neighborhood_overview-Topic9',\n",
    " 'neighborhood_overview_ADJ', 'neighborhood_overview_KmeansCluster', 'neighborhood_overview_NUM', 'neighborhood_overview_PRON', 'neighborhood_overview_TextDigitsPerc',\n",
    " 'neighborhood_overview_TextLength', 'neighborhood_overview_VERB', 'notes-Topic10', 'notes-Topic12', 'notes-Topic14', 'notes-Topic15', 'notes-Topic16',\n",
    " 'notes-Topic19', 'notes-Topic2', 'notes-Topic3', 'notes-Topic4', 'notes-Topic8', 'notes-Topic9', 'notes_.', 'notes_TextPuncPerc',\n",
    " 'notes_TextWordsPerc', 'number_of_reviews', 'review_scores_value', 'reviews_per_month', 'security_deposit', 'space-Topic0', 'space-Topic1',\n",
    " 'space-Topic11', 'space-Topic12', 'space-Topic13', 'space-Topic14', 'space-Topic17', 'space-Topic18', 'space-Topic19', 'space-Topic2',\n",
    " 'space-Topic4', 'space-Topic5', 'space-Topic7', 'space-Topic9', 'space_.', 'space_ADJ', 'space_DET', 'space_NOUN', 'space_TextLength',\n",
    " 'space_VERB', 'transit-Dominant_Topic', 'transit-Topic10', 'transit-Topic11', 'transit-Topic13', 'transit-Topic16', 'transit-Topic17', 'transit-Topic19',\n",
    " 'transit-Topic5', 'transit-Topic7', 'transit_DET', 'transit_LexicalDiversity', 'transit_NUM', 'transit_PRON', 'transit_TextWordsPerc',\n",
    " 'transit_VERB', 'hasEssentials', 'has\"Elevator in Building\"', 'hasHangers', 'has\"Buzzer/Wireless Intercom\"', 'hasTV', 'has\"Fire Extinguisher\"',\n",
    " 'hasDryer', 'has\"Air Conditioning\"', 'hasKitchen', 'hasShampoo', 'has\"Hair Dryer\"', 'hasIron', 'has\"Safety Card\"', 'hasDoorman',\n",
    " 'has\"Pets Allowed\"', 'has\"Cable TV\"', 'has\"Laptop Friendly Workspace\"', 'hasCat(s)','has\"24-Hour Check-in\"', 'access_.', 'access_LexicalDiversity',\n",
    " 'access_TextDigitsPerc', 'access_TextLength', 'availability_60', 'availability_90','beds', 'description-Topic2', 'description-Topic5',\n",
    " 'description_NOUN', 'description_TextLength', 'description_TextWordsPerc', 'description_VERB', 'host_acceptance_rate', 'host_listings_count',\n",
    " 'host_total_listings_count', 'house_rules_.', 'house_rules_ADV', 'house_rules_CONJ', 'house_rules_KmeansCluster', 'house_rules_X',\n",
    " 'interaction-Topic10', 'interaction_ADV', 'interaction_DET', 'interaction_KmeansCluster', 'listing_id', 'neighborhood_overview_DET',\n",
    " 'notes-Topic6', 'notes_ADP', 'notes_ADV', 'review_scores_accuracy', 'scrape_id', 'space-Topic10', 'space-Topic15', 'space-Topic16',\n",
    " 'space-Topic3', 'transit-Topic12', 'transit-Topic14', 'transit-Topic8', 'transit_ADJ', 'transit_NOUN', 'has\"Family/Kid Friendly\"',\n",
    " 'hasHeating', 'hasPool', 'has\"First Aid Kit\"', 'has\"Smoking Allowed\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features_five_new_two = positive_features_five_new + ['distance from ocean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new_two], target, test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for validation is 0.6556276939\n",
      "The mean squared error for validation is 9521.79783952\n",
      "The mean absolute error for validation is 60.6322848889\n",
      "The R2 is 0.685877349281\n",
      "The mean squared error is 7888.49272758\n",
      "The mean absolute error for test is 54.9077253779\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The R2 for validation is ' + str(gbd.score(X_val, y_val)))\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(b, y_val)))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(b, y_val)))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The R2 is ' + str(gbd.score(X_test, y_test)))\n",
    "print('The mean squared error is ' + str(mean_squared_error(b, y_test)))\n",
    "print('The mean absolute error for test is ' + str(mean_absolute_error(b, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
