{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages and doing relevant cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from __future__ import print_function\n",
    "from statsmodels.compat import lzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_fit\n",
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "from statsmodels.graphics.regressionplots import plot_regress_exog\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "linear_regression = linear_model.LinearRegression(normalize=False, fit_intercept=True)\n",
    "def r2_est(X,y):\n",
    "    return r2_score(y, linear_regression.fit(X,y).predict(X))\n",
    "def r2_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, linear_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_validation import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "label_enc = LabelEncoder()\n",
    "label_bin = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_regression = linear_model.LassoLars(normalize=False, fit_intercept=True)\n",
    "def r2_lasso_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, lasso_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_regression = linear_model.Ridge(normalize=False, fit_intercept=True)\n",
    "def r2_ridge_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, ridge_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanka\\Anaconda2\\envs\\py27\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (0,1,4,5,6,10,11,12,13,15,17,18,20,21,22,23,26,27,28,33,34,36,45,51,53,54,62,64,65,66,67,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "listings_augmented_2018 = pd.read_csv('listings_augmented_2018-04-25-4-11.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for (index, row) in listings_augmented_2018.iterrows():\n",
    "    if index not in range(4324, 4326):\n",
    "        df = df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = df\n",
    "listings_augmented_2018 = listings_augmented_2018.reset_index()\n",
    "listings_augmented_2018['Unnamed: 0'] = listings_augmented_2018.index\n",
    "listings_augmented_2018 = listings_augmented_2018.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.drop(['price_x', 'monthly_price', 'weekly_price'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['house_rules-Dominant_Topic'] = listings_augmented_2018['house_rules-Dominant_Topic'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_to_set(x):\n",
    "    c = set()\n",
    "    for w in x[1:-1].split(\",\"):\n",
    "        c.add(w)\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['amenities_set'] = listings_augmented_2018['amenities'].fillna('{}').map(string_to_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '\"24-Hour Check-in\"',\n",
       " '\"Air Conditioning\"',\n",
       " '\"Buzzer/Wireless Intercom\"',\n",
       " '\"Cable TV\"',\n",
       " '\"Carbon Monoxide Detector\"',\n",
       " '\"Elevator in Building\"',\n",
       " '\"Family/Kid Friendly\"',\n",
       " '\"Fire Extinguisher\"',\n",
       " '\"First Aid Kit\"',\n",
       " '\"Free Parking on Premises\"',\n",
       " '\"Hair Dryer\"',\n",
       " '\"Hot Tub\"',\n",
       " '\"Indoor Fireplace\"',\n",
       " '\"Laptop Friendly Workspace\"',\n",
       " '\"Lock on Bedroom Door\"',\n",
       " '\"Other pet(s)\"',\n",
       " '\"Pets Allowed\"',\n",
       " '\"Pets live on this property\"',\n",
       " '\"Safety Card\"',\n",
       " '\"Smoke Detector\"',\n",
       " '\"Smoking Allowed\"',\n",
       " '\"Suitable for Events\"',\n",
       " '\"Wheelchair Accessible\"',\n",
       " '\"Wireless Internet\"',\n",
       " '\"translation missing: en.hosting_amenity_49\"',\n",
       " '\"translation missing: en.hosting_amenity_50\"',\n",
       " 'Breakfast',\n",
       " 'Cat(s)',\n",
       " 'Dog(s)',\n",
       " 'Doorman',\n",
       " 'Dryer',\n",
       " 'Essentials',\n",
       " 'Gym',\n",
       " 'Hangers',\n",
       " 'Heating',\n",
       " 'Internet',\n",
       " 'Iron',\n",
       " 'Kitchen',\n",
       " 'Pool',\n",
       " 'Shampoo',\n",
       " 'TV',\n",
       " 'Washer'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_amenities = set()\n",
    "\n",
    "for idx in listings_augmented_2018['amenities'].fillna('{}').map(string_to_set).index:\n",
    "    all_amenities = all_amenities.union(listings_augmented_2018['amenities'].fillna('{}').map(string_to_set)[idx])\n",
    "    \n",
    "all_amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_amenity(x, amen_):\n",
    "    if amen_ in x:\n",
    "        return 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for amen in all_amenities:\n",
    "    listings_augmented_2018['has' + amen] = 0\n",
    "    listings_augmented_2018['has' + amen] = listings_augmented_2018['amenities_set'].map(lambda x: has_amenity(x, amen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_amenties_list = []\n",
    "for amen in all_amenities:\n",
    "    has_amenties_list.append('has' + amen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018[has_amenties_list] = listings_augmented_2018[has_amenties_list].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = listings_augmented_2018['price_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = listings_augmented_2018.drop('price_y', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['bathrooms*cleaning_fee'] = X['bathrooms'] * X['cleaning_fee']\n",
    "X['bathrooms*guests_included'] = X['bathrooms'] * X['guests_included']\n",
    "X['bathrooms*addommodates'] = X['accommodates'] * X['bathrooms']\n",
    "X['accomodates*cleaning_fee'] = X['accommodates'] * X['cleaning_fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['bedrooms*accommodates'] = X['accommodates'] * X['bedrooms']\n",
    "X['has\"Elevator in Building\"*accommodates'] = X['accommodates'] * X['has\"Elevator in Building\"']\n",
    "X['has\"Air Conditioning\"*accommodates'] = X['accommodates'] * X['has\"Air Conditioning\"']\n",
    "X['accommodates*hasPool'] = X['accommodates'] * X['hasPool']\n",
    "X['accommodates*hasTV'] = X['accommodates'] * X['hasTV']\n",
    "X['accommodates*hasHangers'] = X['accommodates'] * X['hasHangers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features_two = ['access-Topic1', 'access-Topic12','access-Topic13','access-Topic16','access-Topic3','access_.','access_ADJ',\n",
    " 'access_ADV','access_DET','access_KmeansCluster','access_LexicalDiversity','access_NOUN','access_PRON','access_TextDigitsPerc',\n",
    " 'access_TextLength','access_TextPuncPerc','access_TextWordsPerc','accommodates','availability_365','availability_60','availability_90','bathrooms',\n",
    " 'bedrooms','beds','cleaning_fee','description-Topic12','description-Topic2','description-Topic5','description_.','description_ADJ',\n",
    " 'description_ADP','description_ADV','description_DET','description_KmeansCluster','description_LexicalDiversity','description_NOUN',\n",
    " 'description_TextLength','description_TextWordsPerc','description_VERB','description_X','extra_people','has_availability','host_acceptance_rate',\n",
    " 'host_id','host_listings_count','host_response_rate','host_total_listings_count','house_rules-Topic7','house_rules_.','house_rules_ADP',\n",
    " 'house_rules_ADV','house_rules_CONJ','house_rules_KmeansCluster','house_rules_NUM','house_rules_PRT','house_rules_TextLength',\n",
    " 'house_rules_X','interaction-Topic10','interaction-Topic13','interaction-Topic9','interaction_ADJ','interaction_ADV','interaction_DET',\n",
    " 'interaction_KmeansCluster','interaction_PRT','interaction_TextDigitsPerc','interaction_TextPuncPerc','interaction_VERB','latitude',\n",
    " 'license','listing_id','longitude','minimum_nights','neighborhood_overview-Topic14', 'neighborhood_overview-Topic9','neighborhood_overview_ADJ',\n",
    " 'neighborhood_overview_DET','neighborhood_overview_KmeansCluster','neighborhood_overview_NUM','neighborhood_overview_PRON',\n",
    " 'neighborhood_overview_TextDigitsPerc','neighborhood_overview_TextLength','neighborhood_overview_VERB','neighbourhood_group_cleansed',\n",
    " 'notes-Topic10','notes-Topic12','notes-Topic14','notes-Topic15','notes-Topic16','notes-Topic19','notes-Topic2','notes-Topic3',\n",
    " 'notes-Topic4','notes-Topic6','notes-Topic8','notes-Topic9','notes_.','notes_ADP','notes_ADV','notes_TextPuncPerc','notes_TextWordsPerc',\n",
    " 'number_of_reviews','review_scores_accuracy','review_scores_value','reviews_per_month','scrape_id','security_deposit','space-Topic0',\n",
    " 'space-Topic1','space-Topic10','space-Topic11','space-Topic12','space-Topic13','space-Topic14','space-Topic15','space-Topic16',\n",
    " 'space-Topic17','space-Topic18','space-Topic19','space-Topic2','space-Topic3','space-Topic4','space-Topic5','space-Topic7',\n",
    " 'space-Topic9','space_.','space_ADJ','space_DET','space_NOUN','space_TextLength','space_VERB','transit-Dominant_Topic','transit-Topic10',\n",
    " 'transit-Topic11','transit-Topic12','transit-Topic13','transit-Topic14','transit-Topic16','transit-Topic17','transit-Topic19',\n",
    " 'transit-Topic5','transit-Topic7','transit-Topic8','transit_ADJ','transit_DET','transit_LexicalDiversity','transit_NOUN',\n",
    " 'transit_NUM','transit_PRON','transit_TextWordsPerc','transit_VERB','hasEssentials','has\"Elevator in Building\"','hasHangers',\n",
    " 'has\"Buzzer/Wireless Intercom\"','hasTV','has\"Fire Extinguisher\"','hasDryer','has\"Air Conditioning\"','hasKitchen','has\"Family/Kid Friendly\"',\n",
    " 'hasShampoo','hasHeating','has\"Hair Dryer\"','hasIron','has\"Safety Card\"','hasDoorman','hasPool','has\"Pets Allowed\"','has\"First Aid Kit\"',\n",
    " 'has\"Cable TV\"','has\"Laptop Friendly Workspace\"', 'has\"Smoking Allowed\"','hasCat(s)','has\"24-Hour Check-in\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_one = positive_features_two + ['bathrooms*cleaning_fee', 'bathrooms*guests_included', 'bathrooms*addommodates', 'accomodates*cleaning_fee', 'accommodates*hasPool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[features_one], target, test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for validation is 9297.13085021\n",
      "The mean absolute error for validation is 59.8645364935\n",
      "The mean squared error is 7708.08151516\n",
      "The mean absolute error for test is 54.57975142\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "selector = RFECV(gbd, step = 3, cv = 6)\n",
    "selector = selector.fit(X_train_two, y_train_two)\n",
    "b = selector.predict(X_val)\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(b, y_val)))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(b, y_val)))\n",
    "selector = selector.fit(X_train, y_train)\n",
    "b = selector.predict(X_test)\n",
    "print('The mean squared error is ' + str(mean_squared_error(b, y_test)))\n",
    "print('The mean absolute error for test is ' + str(mean_absolute_error(b, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " In this iteration, we try predicting the log of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[features_one], np.log(target), test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for validation is 9960.31221394\n",
      "The mean absolute error for validation is 60.078360866\n",
      "The mean squared error is 8129.30726622\n",
      "The mean absolute error is 53.7948536054\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(np.exp(b), np.exp(y_val))))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(np.exp(b), np.exp(y_val))))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The mean squared error is ' + str(mean_squared_error(np.exp(b), np.exp(y_test))))\n",
    "print('The mean absolute error is ' + str(mean_absolute_error(np.exp(b), np.exp(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77824679945072361"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extra Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this iteration, we try predicting the log of the log of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[features_one], np.log(np.log(target)), test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for validation is 10422.507332\n",
      "The mean absolute error for validation is 60.8349910422\n",
      "The mean squared error is 8091.04332325\n",
      "The mean absolute error is 53.4629409316\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(np.exp(np.exp(b)), np.exp(np.exp(y_val)))))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(np.exp(np.exp(b)), np.exp(np.exp(y_val)))))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The mean squared error is ' + str(mean_squared_error(np.exp(np.exp(b)), np.exp(np.exp(y_test)))))\n",
    "print('The mean absolute error is ' + str(mean_absolute_error(np.exp(np.exp(b)), np.exp(np.exp(y_test)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77675358237839254"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
