{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages and doing relevant cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanka\\Anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from __future__ import print_function\n",
    "from statsmodels.compat import lzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_fit\n",
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "from statsmodels.graphics.regressionplots import plot_regress_exog\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "linear_regression = linear_model.LinearRegression(normalize=False, fit_intercept=True)\n",
    "def r2_est(X,y):\n",
    "    return r2_score(y, linear_regression.fit(X,y).predict(X))\n",
    "def r2_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, linear_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanka\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\sanka\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_validation import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "label_enc = LabelEncoder()\n",
    "label_bin = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_regression = linear_model.LassoLars(normalize=False, fit_intercept=True)\n",
    "def r2_lasso_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, lasso_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_regression = linear_model.Ridge(normalize=False, fit_intercept=True)\n",
    "def r2_ridge_est_two(X,y, X_new, y_new):\n",
    "    return r2_score(y_new, ridge_regression.fit(X,y).predict(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r2_gbd_est_two(X,y, X_new, y_new, loss_, _rate):\n",
    "    gbd = GradientBoostingRegressor(loss = loss_, learning_rate = _rate)\n",
    "    gbd.fit(X,y)\n",
    "    return gbd.score(X_new, y_new)\n",
    "\n",
    "def r2_gbd_est_two_huber(X,y, X_new, y_new):\n",
    "    return r2_gbd_est_two(X,y, X_new, y_new, 'huber', .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = pd.read_csv('listings_augmented_2018-04-29_V1.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dominant_Topic_feature_list = []\n",
    "Topic_feature_list = []\n",
    "\n",
    "for w in listings_augmented_2018.columns:\n",
    "    if 'Dominant_Topic' in w:\n",
    "        Dominant_Topic_feature_list.append(w)\n",
    "    if '-Topic' in w:\n",
    "        Topic_feature_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your Inn Keeper. Welcome to San Diego. I am a native resident of San Diego.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_augmented_2018['Unnamed: 0'][4325]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for (index, row) in listings_augmented_2018.iterrows():\n",
    "    if index not in range(4324, 4326):\n",
    "        df = df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = df\n",
    "listings_augmented_2018 = listings_augmented_2018.reset_index()\n",
    "listings_augmented_2018['Unnamed: 0'] = listings_augmented_2018.index\n",
    "listings_augmented_2018 = listings_augmented_2018.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018[Topic_feature_list] = listings_augmented_2018[Topic_feature_list].astype('float64')\n",
    "listings_augmented_2018[Dominant_Topic_feature_list] = listings_augmented_2018[Dominant_Topic_feature_list].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = listings_augmented_2018['host_verifications'].map(lambda x: x[1:-1]).map(lambda j: j.split(',')).map(lambda k: set(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_host_verifications = set()\n",
    "\n",
    "for w in a.index:\n",
    "    all_host_verifications = all_host_verifications.union(a[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_amenity(x, amen_):\n",
    "    if amen_ in x:\n",
    "        return 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in all_host_verifications:\n",
    "    listings_augmented_2018['uses' + w] = 0\n",
    "    listings_augmented_2018['uses' + w] = a.map(lambda x: has_amenity(x, w))\n",
    "    \n",
    "uses_verification_list = []\n",
    "for veri in all_host_verifications:\n",
    "    uses_verification_list.append('uses' + veri)\n",
    "\n",
    "listings_augmented_2018[uses_verification_list] = listings_augmented_2018[uses_verification_list].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_response_rate'] = listings_augmented_2018['host_response_rate'].astype(str).map(lambda x: x.rstrip(\"%\"))\n",
    "listings_augmented_2018['host_response_rate'] = listings_augmented_2018['host_response_rate'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['host_response_rate'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['host_acceptance_rate'] = listings_augmented_2018['host_acceptance_rate'].astype(str).map(lambda x: x.rstrip(\"%\"))\n",
    "listings_augmented_2018['host_acceptance_rate'] = listings_augmented_2018['host_acceptance_rate'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['host_acceptance_rate'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['extra_people'] = listings_augmented_2018['extra_people'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['extra_people'] = listings_augmented_2018['extra_people'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['extra_people'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['weekly_price'] = listings_augmented_2018['weekly_price'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['weekly_price'] = listings_augmented_2018['weekly_price'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['weekly_price'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['monthly_price'] = listings_augmented_2018['monthly_price'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['monthly_price'] = listings_augmented_2018['monthly_price'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['monthly_price'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['security_deposit'] = listings_augmented_2018['security_deposit'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['security_deposit'] = listings_augmented_2018['security_deposit'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['security_deposit'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "listings_augmented_2018['cleaning_fee'] = listings_augmented_2018['cleaning_fee'].astype(str).map(lambda x: x.lstrip('$'))\n",
    "listings_augmented_2018['cleaning_fee'] = listings_augmented_2018['cleaning_fee'].apply(pd.to_numeric, errors='coerce')\n",
    "listings_augmented_2018['cleaning_fee'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['ones'] = np.ones(len(listings_augmented_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_is_superhost'] = label_bin.fit_transform(listings_augmented_2018.host_is_superhost)\n",
    "listings_augmented_2018['is_location_exact'] = label_bin.fit_transform(listings_augmented_2018.is_location_exact)\n",
    "listings_augmented_2018['host_identity_verified'] = label_bin.fit_transform(listings_augmented_2018.host_identity_verified)\n",
    "listings_augmented_2018['instant_bookable'] = label_bin.fit_transform(listings_augmented_2018.instant_bookable)\n",
    "listings_augmented_2018['require_guest_profile_picture'] = label_bin.fit_transform(listings_augmented_2018.require_guest_profile_picture)\n",
    "listings_augmented_2018['require_guest_phone_verification'] = label_bin.fit_transform(listings_augmented_2018.require_guest_phone_verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_resp_time_enc'] = label_enc.fit_transform(listings_augmented_2018['host_response_time'].astype(str))\n",
    "listings_augmented_2018['calendar_updated_enc'] = label_enc.fit_transform(listings_augmented_2018['calendar_updated'].astype(str))\n",
    "listings_augmented_2018['bed_type_enc'] = label_enc.fit_transform(listings_augmented_2018['bed_type'].astype(str))\n",
    "listings_augmented_2018['jurisdiction_names_enc'] = label_enc.fit_transform(listings_augmented_2018['jurisdiction_names'].astype(str))\n",
    "listings_augmented_2018['zipcode_enc'] = label_enc.fit_transform(listings_augmented_2018['zipcode'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018['host_resp_time_enc'] = label_enc.fit_transform(listings_augmented_2018['host_response_time'].astype(str))\n",
    "listings_augmented_2018['calendar_updated_enc'] = label_enc.fit_transform(listings_augmented_2018['calendar_updated'].astype(str))\n",
    "listings_augmented_2018['bed_type_enc'] = label_enc.fit_transform(listings_augmented_2018['bed_type'].astype(str))\n",
    "listings_augmented_2018['jurisdiction_names_enc'] = label_enc.fit_transform(listings_augmented_2018['jurisdiction_names'].astype(str))\n",
    "listings_augmented_2018['zipcode_enc'] = label_enc.fit_transform(listings_augmented_2018['zipcode'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.drop(['neighbourhood_group_cleansed','square_feet','has_availability','license','weekly_price','monthly_price'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.drop(['host_response_time','calendar_updated', 'bed_type', 'jurisdiction_names', 'zipcode'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_augmented_2018 = listings_augmented_2018.fillna(value=listings_augmented_2018.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = listings_augmented_2018['price_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = listings_augmented_2018.drop('price_y', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features_five_new = ['access_._tokens_sum_ratio', 'access_ADP_tokens_sum_ratio', 'access_ADV_tokens_sum_ratio', 'access_CONJ_tokens_sum_ratio',\n",
    " 'access_DET_tokens_sum_ratio', 'access_PRON_tokens_sum_ratio', 'access_VERB_tokens_sum_ratio', 'access_X_tokens_sum_ratio','description_._tokens_sum_ratio',\n",
    " 'description_ADJ_tokens_sum_ratio', 'description_ADP_tokens_sum_ratio', 'description_CONJ_tokens_sum_ratio','description_DET_tokens_sum_ratio',\n",
    " 'description_NOUN_tokens_sum_ratio', 'description_NUM_tokens_sum_ratio', 'description_PRON_tokens_sum_ratio', 'description_VERB_tokens_sum_ratio',\n",
    " 'description_X_tokens_sum_ratio', 'house_rules_._tokens_sum_ratio', 'house_rules_ADP_tokens_sum_ratio', 'house_rules_ADV_tokens_sum_ratio',\n",
    " 'house_rules_CONJ_tokens_sum_ratio', 'house_rules_DET_tokens_sum_ratio', 'house_rules_NUM_tokens_sum_ratio', 'house_rules_PRON_tokens_sum_ratio',\n",
    " 'house_rules_X_tokens_sum_ratio', 'interaction_._tokens_sum_ratio', 'interaction_ADJ_tokens_sum_ratio', 'interaction_ADP_tokens_sum_ratio',\n",
    " 'interaction_CONJ_tokens_sum_ratio', 'interaction_DET_tokens_sum_ratio', 'interaction_NOUN_tokens_sum_ratio', 'interaction_NUM_tokens_sum_ratio',\n",
    " 'interaction_VERB_tokens_sum_ratio', 'neighborhood_overview_._tokens_sum_ratio', 'neighborhood_overview_ADJ_tokens_sum_ratio', 'neighborhood_overview_ADP_tokens_sum_ratio',\n",
    " 'neighborhood_overview_ADV_tokens_sum_ratio', 'neighborhood_overview_PRON_tokens_sum_ratio', 'neighborhood_overview_PRT_tokens_sum_ratio',\n",
    " 'neighborhood_overview_VERB_tokens_sum_ratio', 'notes_ADP_tokens_sum_ratio', 'notes_ADV_tokens_sum_ratio', 'notes_DET_tokens_sum_ratio',\n",
    " 'notes_NOUN_tokens_sum_ratio', 'notes_NUM_tokens_sum_ratio', 'notes_PRON_tokens_sum_ratio', 'notes_PRT_tokens_sum_ratio', 'notes_VERB_tokens_sum_ratio',\n",
    " 'notes_X_tokens_sum_ratio', 'space_._tokens_sum_ratio', 'space_ADP_tokens_sum_ratio', 'space_CONJ_tokens_sum_ratio', 'space_NOUN_tokens_sum_ratio',\n",
    " 'space_PRT_tokens_sum_ratio', 'space_VERB_tokens_sum_ratio', 'space_X_tokens_sum_ratio', 'transit_._tokens_sum_ratio', 'transit_ADJ_tokens_sum_ratio',\n",
    " 'transit_ADP_tokens_sum_ratio', 'transit_CONJ_tokens_sum_ratio', 'transit_DET_tokens_sum_ratio', 'transit_NOUN_tokens_sum_ratio',\n",
    " 'transit_NUM_tokens_sum_ratio', 'transit_PRON_tokens_sum_ratio', 'transit_PRT_tokens_sum_ratio', 'transit_VERB_tokens_sum_ratio',\n",
    " 'transit_X_tokens_sum_ratio', \"uses 'amex'\", \"uses 'linkedin'\", \"uses'email'\", \"uses 'sent_id'\", \"uses 'kba'\", \"uses 'jumio'\",\n",
    " \"uses'phone'\", \"uses 'reviews'\", \"uses 'manual_online'\", 'host_resp_time_enc', 'calendar_updated_enc', 'bed_type_enc', 'jurisdiction_names_enc',\n",
    " 'zipcode_enc', 'access-Topic1', 'access-Topic12', 'access-Topic13', 'access-Topic16', 'access-Topic3', 'access_ADJ', 'access_ADV',\n",
    " 'access_DET', 'access_KmeansCluster', 'access_NOUN', 'access_PRON', 'access_TextPuncPerc', 'access_TextWordsPerc', 'accommodates',\n",
    " 'availability_365', 'bathrooms', 'bedrooms', 'cleaning_fee', 'description-Topic12', 'description_.', 'description_ADJ', 'description_ADP',\n",
    " 'description_ADV', 'description_DET', 'description_KmeansCluster', 'description_LexicalDiversity', 'description_X', 'extra_people',\n",
    " 'host_id', 'host_response_rate', 'house_rules-Topic7', 'house_rules_ADP', 'house_rules_NUM', 'house_rules_PRT', 'house_rules_TextLength',\n",
    " 'interaction-Topic13', 'interaction-Topic9', 'interaction_ADJ', 'interaction_PRT', 'interaction_TextDigitsPerc', 'interaction_TextPuncPerc',\n",
    " 'interaction_VERB', 'latitude', 'longitude', 'minimum_nights', 'neighborhood_overview-Topic14', 'neighborhood_overview-Topic9',\n",
    " 'neighborhood_overview_ADJ', 'neighborhood_overview_KmeansCluster', 'neighborhood_overview_NUM', 'neighborhood_overview_PRON', 'neighborhood_overview_TextDigitsPerc',\n",
    " 'neighborhood_overview_TextLength', 'neighborhood_overview_VERB', 'notes-Topic10', 'notes-Topic12', 'notes-Topic14', 'notes-Topic15', 'notes-Topic16',\n",
    " 'notes-Topic19', 'notes-Topic2', 'notes-Topic3', 'notes-Topic4', 'notes-Topic8', 'notes-Topic9', 'notes_.', 'notes_TextPuncPerc',\n",
    " 'notes_TextWordsPerc', 'number_of_reviews', 'review_scores_value', 'reviews_per_month', 'security_deposit', 'space-Topic0', 'space-Topic1',\n",
    " 'space-Topic11', 'space-Topic12', 'space-Topic13', 'space-Topic14', 'space-Topic17', 'space-Topic18', 'space-Topic19', 'space-Topic2',\n",
    " 'space-Topic4', 'space-Topic5', 'space-Topic7', 'space-Topic9', 'space_.', 'space_ADJ', 'space_DET', 'space_NOUN', 'space_TextLength',\n",
    " 'space_VERB', 'transit-Dominant_Topic', 'transit-Topic10', 'transit-Topic11', 'transit-Topic13', 'transit-Topic16', 'transit-Topic17', 'transit-Topic19',\n",
    " 'transit-Topic5', 'transit-Topic7', 'transit_DET', 'transit_LexicalDiversity', 'transit_NUM', 'transit_PRON', 'transit_TextWordsPerc',\n",
    " 'transit_VERB', 'hasEssentials', 'has\"Elevator in Building\"', 'hasHangers', 'has\"Buzzer/Wireless Intercom\"', 'hasTV', 'has\"Fire Extinguisher\"',\n",
    " 'hasDryer', 'has\"Air Conditioning\"', 'hasKitchen', 'hasShampoo', 'has\"Hair Dryer\"', 'hasIron', 'has\"Safety Card\"', 'hasDoorman',\n",
    " 'has\"Pets Allowed\"', 'has\"Cable TV\"', 'has\"Laptop Friendly Workspace\"', 'hasCat(s)','has\"24-Hour Check-in\"', 'access_.', 'access_LexicalDiversity',\n",
    " 'access_TextDigitsPerc', 'access_TextLength', 'availability_60', 'availability_90','beds', 'description-Topic2', 'description-Topic5',\n",
    " 'description_NOUN', 'description_TextLength', 'description_TextWordsPerc', 'description_VERB', 'host_acceptance_rate', 'host_listings_count',\n",
    " 'host_total_listings_count', 'house_rules_.', 'house_rules_ADV', 'house_rules_CONJ', 'house_rules_KmeansCluster', 'house_rules_X',\n",
    " 'interaction-Topic10', 'interaction_ADV', 'interaction_DET', 'interaction_KmeansCluster', 'listing_id', 'neighborhood_overview_DET',\n",
    " 'notes-Topic6', 'notes_ADP', 'notes_ADV', 'review_scores_accuracy', 'scrape_id', 'space-Topic10', 'space-Topic15', 'space-Topic16',\n",
    " 'space-Topic3', 'transit-Topic12', 'transit-Topic14', 'transit-Topic8', 'transit_ADJ', 'transit_NOUN', 'has\"Family/Kid Friendly\"',\n",
    " 'hasHeating', 'hasPool', 'has\"First Aid Kit\"', 'has\"Smoking Allowed\"']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Including Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interaction: var host_listings_count and var bathrooms R2: 0.011\n",
    "Interaction: var host_total_listings_count and var bathrooms R2: 0.011\n",
    "Interaction: var accommodates and var bathrooms R2: 0.027\n",
    "Interaction: var accommodates and var bedrooms R2: 0.024\n",
    "Interaction: var accommodates and var     beds R2: 0.016\n",
    "Interaction: var accommodates and var cleaning_fee R2: 0.030\n",
    "Interaction: var bathrooms and var bedrooms R2: 0.028\n",
    "Interaction: var bathrooms and var     beds R2: 0.016\n",
    "Interaction: var bathrooms and var cleaning_fee R2: 0.040\n",
    "Interaction: var bathrooms and var calculated_host_listings_count R2: 0.011\n",
    "Interaction: var bedrooms and var     beds R2: 0.011\n",
    "Interaction: var bedrooms and var cleaning_fee R2: 0.026\n",
    "Interaction: var     beds and var cleaning_fee R2: 0.020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactions_list = ['host_listings_count*bathrooms', 'host_total_listings_count*bathrooms', 'accommodates*bathrooms', 'accommodates*bedrooms', \n",
    "                    'accommodates*beds', 'accommodates*cleaning_fee', 'bathrooms*bedrooms', 'bathrooms*beds', 'bathrooms*cleaning_fee',\n",
    "                    'bathrooms*calculated_host_listings_count', 'bedrooms*beds', 'bedrooms*cleaning_fee', 'beds*cleaning_fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['host_listings_count*bathrooms'] = X['host_listings_count']*X['bathrooms']\n",
    "X['host_total_listings_count*bathrooms'] = X['host_total_listings_count']*X['bathrooms']\n",
    "X['accommodates*bathrooms'] = X['accommodates']*X['bathrooms']\n",
    "X['accommodates*bedrooms'] = X['accommodates']*X['bedrooms']\n",
    "X['accommodates*beds'] = X['accommodates']*X['beds']\n",
    "X['accommodates*cleaning_fee'] = X['accommodates']*X['cleaning_fee']\n",
    "X['bathrooms*bedrooms'] = X['bathrooms']*X['bedrooms']\n",
    "X['bathrooms*beds'] = X['bathrooms']*X['beds']\n",
    "X['bathrooms*cleaning_fee'] = X['bathrooms']*X['cleaning_fee']\n",
    "X['bathrooms*calculated_host_listings_count'] = X['bathrooms']*X['calculated_host_listings_count']\n",
    "X['bedrooms*beds'] = X['bedrooms']*X['beds']\n",
    "X['bedrooms*cleaning_fee'] = X['bedrooms']*X['cleaning_fee']\n",
    "X['beds*cleaning_fee'] = X['beds']*X['cleaning_fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['bathrooms*guests_included'] = X['bathrooms'] * X['guests_included']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_important_interactions = ['bathrooms*cleaning_fee', 'accommodates*cleaning_fee', 'bathrooms*bedrooms', 'accommodates*bathrooms', \n",
    "                              'bedrooms*cleaning_fee', 'accommodates*bedrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_important_interactions_two = ['bathrooms*cleaning_fee', 'accommodates*cleaning_fee', 'bathrooms*bedrooms', 'accommodates*bathrooms', \n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_important_interactions_three = ['bathrooms*cleaning_fee', 'accommodates*cleaning_fee', 'bathrooms*bedrooms', 'accommodates*bathrooms', \n",
    "                              'bathrooms*guests_included']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_important_interactions_four = ['bathrooms*cleaning_fee', 'accommodates*cleaning_fee', 'accommodates*bathrooms', \n",
    "                              'bathrooms*guests_included']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new + interactions_list], target, test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for validation is 0.66896732923\n",
      "The mean squared error for validation is 9152.96065774\n",
      "The mean absolute error for validation is 60.4391415682\n",
      "The R2 is 0.685825267904\n",
      "The mean squared error is 7889.8006357\n",
      "The mean absolute error for test is 55.0673400086\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The R2 for validation is ' + str(gbd.score(X_val, y_val)))\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(b, y_val)))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(b, y_val)))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The R2 is ' + str(gbd.score(X_test, y_test)))\n",
    "print('The mean squared error is ' + str(mean_squared_error(b, y_test)))\n",
    "print('The mean absolute error for test is ' + str(mean_absolute_error(b, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new + most_important_interactions], target, test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for validation is 0.659170180079\n",
      "The mean squared error for validation is 9423.84908857\n",
      "The mean absolute error for validation is 60.7462528554\n",
      "The R2 is 0.688033950564\n",
      "The mean squared error is 7834.33447602\n",
      "The mean absolute error for test is 55.0471308754\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The R2 for validation is ' + str(gbd.score(X_val, y_val)))\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(b, y_val)))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(b, y_val)))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The R2 is ' + str(gbd.score(X_test, y_test)))\n",
    "print('The mean squared error is ' + str(mean_squared_error(b, y_test)))\n",
    "print('The mean absolute error for test is ' + str(mean_absolute_error(b, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new + most_important_interactions_two], target, test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for validation is 0.662141763864\n",
      "The mean squared error for validation is 9341.68562894\n",
      "The mean absolute error for validation is 60.8056992931\n",
      "The R2 is 0.693775281396\n",
      "The mean squared error is 7690.15370329\n",
      "The mean absolute error for test is 54.5311349946\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The R2 for validation is ' + str(gbd.score(X_val, y_val)))\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(b, y_val)))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(b, y_val)))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The R2 is ' + str(gbd.score(X_test, y_test)))\n",
    "print('The mean squared error is ' + str(mean_squared_error(b, y_test)))\n",
    "print('The mean absolute error for test is ' + str(mean_absolute_error(b, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new + most_important_interactions_three], target, test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for validation is 0.670599502241\n",
      "The mean squared error for validation is 9107.83153099\n",
      "The mean absolute error for validation is 60.0063984023\n",
      "The R2 is 0.686082356003\n",
      "The mean squared error is 7883.34443906\n",
      "The mean absolute error for test is 54.7144570134\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The R2 for validation is ' + str(gbd.score(X_val, y_val)))\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(b, y_val)))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(b, y_val)))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The R2 is ' + str(gbd.score(X_test, y_test)))\n",
    "print('The mean squared error is ' + str(mean_squared_error(b, y_test)))\n",
    "print('The mean absolute error for test is ' + str(mean_absolute_error(b, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new + most_important_interactions_four], target, test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for validation is 0.665196263374\n",
      "The mean squared error for validation is 9257.22957276\n",
      "The mean absolute error for validation is 60.149952992\n",
      "The R2 is 0.693162805402\n",
      "The mean squared error is 7705.53467761\n",
      "The mean absolute error for test is 54.3339753745\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The R2 for validation is ' + str(gbd.score(X_val, y_val)))\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(b, y_val)))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(b, y_val)))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The R2 is ' + str(gbd.score(X_test, y_test)))\n",
    "print('The mean squared error is ' + str(mean_squared_error(b, y_test)))\n",
    "print('The mean absolute error for test is ' + str(mean_absolute_error(b, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new + most_important_interactions_four], np.log(target), test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for validation is 9507.72611263\n",
      "The mean absolute error for validation is 59.3442097941\n",
      "The mean squared error is 8190.41403982\n",
      "The mean absolute error is 53.9527821799\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(np.exp(b), np.exp(y_val))))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(np.exp(b), np.exp(y_val))))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The mean squared error is ' + str(mean_squared_error(np.exp(b), np.exp(y_test))))\n",
    "print('The mean absolute error is ' + str(mean_absolute_error(np.exp(b), np.exp(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77803077755618477"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[positive_features_five_new + most_important_interactions_four], np.log(np.log(target)), test_size=.30, random_state=1)\n",
    "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size=.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for validation is 9902.04588711\n",
      "The mean absolute error for validation is 59.9653915462\n",
      "The mean squared error is 8148.60660348\n",
      "The mean absolute error is 54.0086624772\n"
     ]
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor(loss = 'huber', learning_rate = .1)\n",
    "gbd.fit(X_train_two, y_train_two)\n",
    "b = gbd.predict(X_val)\n",
    "print('The mean squared error for validation is ' + str(mean_squared_error(np.exp(np.exp(b)), np.exp(np.exp(y_val)))))\n",
    "print('The mean absolute error for validation is ' + str(mean_absolute_error(np.exp(np.exp(b)), np.exp(np.exp(y_val)))))\n",
    "gbd.fit(X_train, y_train)\n",
    "b = gbd.predict(X_test)\n",
    "print('The mean squared error is ' + str(mean_squared_error(np.exp(np.exp(b)), np.exp(np.exp(y_test)))))\n",
    "print('The mean absolute error is ' + str(mean_absolute_error(np.exp(np.exp(b)), np.exp(np.exp(y_test)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77653392095300555"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda2]",
   "language": "python",
   "name": "conda-env-Anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
