{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook putting together concepts from all modeling notebook to construct final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import KFold,cross_val_predict,cross_val_score, cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsRegressor\n",
    "from sklearn.feature_selection import RFE, f_regression, RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./lib')\n",
    "from airbnb_modeling import detect_feature_importance, scale_data, normalize_data, eval_metrics, plot_residuals, plot_predictions\n",
    "from parse_methods import parse_columns\n",
    "from airbnb_modeling import detect_interactions, add_interactions, map_variable, plot_rmse_instances,plot_rmse_features, plot_accuracy_instances\n",
    "#from filename import methodname\n",
    "#from airbnb_modeling import\n",
    "#from airbnb_modeling import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings = pd.read_csv('Datasources/listings_augmented/listings_augmented_2018-05-31_V3.csv',low_memory=False)\n",
    "listings = listings.drop(listings.index[4323:4325])\n",
    "listings.index = [i for i in range(len(listings))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Excluded variables from the featuresExploration notebook\n",
    "%store -r excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [i for i in listings.columns if i not in excluded]\n",
    "X = listings[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "space        1275\n",
       "bathrooms      10\n",
       "bedrooms        3\n",
       "beds            4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.columns[X.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = parse_columns(X, ['has_Pets_Allowed','has_Wheelchair_Accessible','has_First_Aid_Kit',\n",
    "'has_Cat(s)','has_24-Hour_Check-in','uses_jumio','description-Topic0','description-Topic1',\n",
    "'description-Topic4','description-Topic5','description-Topic6','description-Topic10',\n",
    "'description-Topic11','description-Topic12','description-Topic13','description-Topic15',\n",
    "'description-Topic17','description-Topic18','description-Dominant_Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[[i for i in X.columns if i not in X.filter(regex='enc').columns]]\n",
    "donotscale = X.filter(regex='bin').columns\n",
    "cols = [i for i in X.columns if i not in donotscale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols.remove('space')\n",
    "cols.remove('amenity_level')\n",
    "cols.remove('hol_skew_of_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper_df = pd.DataFrame(preprocessing.normalize(X[cols]), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_normed = helper_df.merge(X[donotscale], right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now adding new features by taking ratios between features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other = ['calculated_host_listings_count','extra_people', 'minimum_nights', 'number_of_reviews']\n",
    "candidates = list(X_normed.filter(regex='event').columns) \\\n",
    "+ list(X_normed.filter(regex='park').columns) + list(X_normed.filter(regex='ocean').columns)\\\n",
    "+ list(X_normed.filter(regex='ratio').columns) + other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "a = []\n",
    "for subset in itertools.combinations(candidates, 2):\n",
    "    a.append(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = [i for i in a if \"bin\" not in i[0] and \"bin\" not in i[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ratios = X_normed.copy()\n",
    "for i in new:\n",
    "    name = str(i[0]) + '/' + str(i[1]) + '_ratio'\n",
    "    X_ratios[name] = X_ratios[i[0]]/X_ratios[i[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normed[X_normed.columns[X_normed.isnull().any()]].isnull().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lots of nulls above so dropping columns that have more than 300 nulls and imputing the remaining ones\n",
    "X_ratios = X_ratios.dropna(axis = 1,thresh = len(X_normed)-300)\n",
    "X_ratios = X_ratios.replace([np.inf, -np.inf], np.nan)\n",
    "X_ratios = X_ratios.fillna(X_ratios.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_normed = X_normed['price_y'].fillna(X_normed['price_y'].mean())\n",
    "X_normed = X_normed[X_normed.columns.drop(X_normed[list(X_normed.filter(regex='price'))])]\n",
    "X_ratios = X_ratios[X_ratios.columns.drop(X_ratios[list(X_ratios.filter(regex='price'))])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Checking that features are clean - output should be True and False\n",
    "print np.any(np.isnan(X_normed))\n",
    "print np.all(np.isfinite(X_normed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: Simple Model with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Number of Features Used:  138\n"
     ]
    }
   ],
   "source": [
    "print 'Final Number of Features Used: ', len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE for Initial Linear Regression:  0.025984902976912066\n"
     ]
    }
   ],
   "source": [
    "lin_reg_rmse_test = np.sqrt(mean_squared_error(y_test, lin_reg.predict(X_test)))\n",
    "print 'Test RMSE for Initial Linear Regression: ', lin_reg_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_lin = cross_validate(lin_reg, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_tree = cross_validate(tree_reg, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Linear Regression with CV: \n",
      "Training R2 Mean:  0.8367261556254737\n",
      "Validation R2 Mean:  0.8141108210063563\n",
      "Validation R2 STdev:  0.02281127611849167\n",
      "--\n",
      "Training RMSE Mean:  0.02517032237136816\n",
      "Validation RMSE Mean:  0.02671513027489586\n",
      "Validation RMSE STdev:  6.635340961825122e-05\n",
      "--\n",
      "Training MAE Mean:  0.0195095861192613\n",
      "Validation MAE Mean:  0.02054359368106534\n",
      "Validation MAE STdev:  0.0009910646197029544\n",
      "----\n",
      "----\n",
      "Evaluation Metrics for Tree Regression with CV: \n",
      "Training R2 Mean:  0.9999977308530943\n",
      "Validation R2 Mean:  0.7291932365075027\n",
      "Validation R2 STdev:  0.039714609922883004\n",
      "--\n",
      "Training RMSE Mean:  9.383340186128148e-05\n",
      "Validation RMSE Mean:  0.03221552800612837\n",
      "Validation RMSE STdev:  0.00011448245803281506\n",
      "--\n",
      "Training MAE Mean:  4.0247711899583353e-05\n",
      "Validation MAE Mean:  0.02285036024087232\n",
      "Validation MAE STdev:  0.0011173517140218644\n"
     ]
    }
   ],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with CV: '\n",
    "eval_metrics(scores_lin)\n",
    "print '----'\n",
    "print '----'\n",
    "print 'Evaluation Metrics for Tree Regression with CV: '\n",
    "eval_metrics(scores_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM2uJE4aZmbXECcPMzFrihGFmZi35/+5X5LIndgsoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rmse_instances(lin_reg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ca48fa7466a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_rmse_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/pauldefusco/Documents/capstone/UCSD-MAS-Capstone-Project/dev/lib/airbnb_modeling.pyc\u001b[0m in \u001b[0;36mplot_rmse_instances\u001b[0;34m(clf, X_train, y_train)\u001b[0m\n\u001b[1;32m    373\u001b[0m         cv_results = cross_validate(clf,X_train[:i],y_train[:i],return_train_score=True,\n\u001b[1;32m    374\u001b[0m                                    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                                    cv=cv_n)\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_rmse_instances(tree_reg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for more models and create final plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using Nested GridSearch CV with more regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sv_reg = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-0.1, 10, 30)\n",
    "param_grid = [\n",
    "    {'C':Cs, 'epsilon':[i for i in range(1,8,1)], 'kernel':['linear', 'poly'],\n",
    "    'degree':[2,3,4]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(sv_reg, param_grid, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_sv_reg = cross_validate(gs, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_results_svreg = gs.cv_results_\n",
    "print 'Avg Mean Train Score: ', np.sqrt(-gs_results_svreg['mean_train_score'].mean())\n",
    "print 'Avg Mean Val Score: ', np.sqrt(-gs_results_svreg['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_svr = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_rmse_instances(best_model_svr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Neighbors Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neigh_reg = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_neighbors':[2,3,4], \n",
    "     'metric':['euclidean']},]\n",
    "#euclidean: sqrt(sum((x - y)^2)) \n",
    "#minkowski: sum(|x - y|^p)^(1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(neigh_reg, param_grid, cv=3, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_neigh_reg = cross_validate(gs, X_train, y_train, cv=3, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_results_nn = gs.cv_results_\n",
    "print 'Avg Mean Train Score: ', np.sqrt(-gs_results_nn['mean_train_score'].mean())\n",
    "print 'Avg Mean Val Score: ', np.sqrt(-gs_results_nn['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_kneigh = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes way too long\n",
    "#plot_rmse_instances(best_model_kneigh, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Interactions - We do this in two ways - first we check and add the interactions that increase accuracy beyond an arbitrary threshold (0.02); Then, we just add all interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "increments = detect_interactions(X_normed,y_normed, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_normed_wint = add_interactions(X_normed, increments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "increments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above did not return any interactions! That means the interactions are probably not going to make large changes to our models above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "X_normed_wint = poly.fit_transform(X_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed_wint,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg_intonly = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg_intonly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_lin_intonly = cross_validate(lin_reg_intonly, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with CV - Interactions Only Added: '\n",
    "eval_metrics(scores_lin_intonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#No need for plot here\n",
    "#plot_rmse_instances(lin_reg_intonly, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding interactions simply overfits. Let's also try adding quadratic terms to the normalized dataset to see if nonlinaer regression might help, although it will probably also overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_normed_quad = poly.fit_transform(X_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed_quad,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quad_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "quad_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_quad = cross_validate(quad_reg, X_train, y_train, cv=5, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with CV - Interactions Only Added: '\n",
    "eval_metrics(scores_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_rmse_instances(quad_reg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite all the attempts, the most promising model is Linear Regression. Let's try the same Linear Regression with the ratios features. We are probably going to overfit again but we will then do Feature Selection: the goal is to choose a good feature subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_lin_ratios = cross_validate(lin_reg, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with CV: '\n",
    "eval_metrics(scores_lin_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_pred = lin_reg.predict(X_test)\n",
    "test_lin_ratios_nofs = np.sqrt(-mean_squared_error(y_test, temp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above is promising: the training RMSE has increased more than the validation RMSE, which is a sign that we may be approaching the sweet spot and getting close to starting to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection - We use this promising model above to pick only the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = RFECV(lin_reg, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "selector.fit(X_ratios, y_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation RMSE score\")\n",
    "plt.title(\"Optimal number of features : %d\" % selector.n_features_)\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), np.sqrt(-selector.grid_scores_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = selector.transform(X_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features have equally important ranking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's rerun our best model so far and evaluate changes to model metrics resulting from removing unneeded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train,y_train)\n",
    "scores_temp = cross_validate(lin_reg, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))\n",
    "print 'Evaluation Metrics for Linear Regression with CV: '\n",
    "eval_metrics(scores_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation RMSE has actually increased, while the accuracy has decreased slightly - this is bad but we make the choice to trade off a little bit of accuracy in order to shed complexity (we are losing more than 100 features this way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we rebuild the model only with the important features i.e. number of features where val error is lowest - we do this in order to replicate what we created above with RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_normed.columns, selector.ranking_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'RFECV_Ranking'})\n",
    "importances = importances.sort_values(by='RFECV_Ranking')\n",
    "importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are restricting our features to the ones that minimize CV RMSE by feeding the new data into RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features = list(importances.head(selector.n_features_).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train[best_features],y_train)\n",
    "scores_lin_ratios_fsel = cross_validate(lin_reg, X_train[best_features], y_train, cv=10, \n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))\n",
    "print 'Evaluation Metrics for Linear Regression with CV: '\n",
    "eval_metrics(scores_lin_ratios_fsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_rmse_features(lin_reg, X_train, y_train, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how the models performs against our Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_intonly, X_test_intonly, y_train_intonly, y_test_intonly = train_test_split(X_normed_wint,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_quad, X_test_quad, y_train_quad, y_test_quad = train_test_split(X_normed_quad,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions_tree_reg = tree_reg.predict(X_test)\n",
    "test_predictions_best_model_svr = best_model_svr.predict(X_test)\n",
    "test_predictions_best_model_kneigh = best_model_kneigh.predict(X_test)\n",
    "test_predictions_lin_reg_intonly = lin_reg_intonly.predict(X_test_intonly)\n",
    "test_predictions_quad_reg = quad_reg.predict(X_test_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Decision Tree Regression'\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_tree_reg)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_tree_reg))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_tree_reg)\n",
    "map_variable(y_test-test_predictions_tree_reg, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Support Vector Regression'\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_best_model_svr)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_best_model_svr))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_best_model_svr)\n",
    "map_variable(y_test-test_predictions_best_model_svr, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for K Nearest Neighbors Regression'\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_best_model_kneigh)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_best_model_kneigh))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_best_model_kneigh)\n",
    "map_variable(y_test-test_predictions_best_model_kneigh, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with Interactions'\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_lin_reg_intonly)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test_intonly, test_predictions_lin_reg_intonly))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test_intonly, test_predictions_lin_reg_intonly)\n",
    "map_variable(y_test_intonly-test_predictions_lin_reg_intonly, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Quadratic Regression without Interactions'\n",
    "print 'Test R2: ',r2_score(y_test_quad, test_predictions_quad_reg)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test_quad, test_predictions_quad_reg))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test_quad, test_predictions_quad_reg)\n",
    "map_variable(y_test_quad-test_predictions_quad_reg, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_reg_pred_cv = cross_val_predict(tree_reg, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(tree_reg_pred_cv, tree_reg_pred_cv-y_train, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_tree_reg, test_predictions_tree_reg-y_test, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=0, xmax=.35, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Decision Tree Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_svr_best_model_pred_cv = cross_val_predict(best_model_svr, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(reg_svr_best_model_pred_cv, reg_svr_best_model_pred_cv-y_train, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_best_model_svr, test_predictions_best_model_svr-y_test, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=0, xmax=.35, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Tuned Support Vector Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kneigh_best_model_pred_cv = cross_val_predict(best_model_kneigh, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(kneigh_best_model_pred_cv, kneigh_best_model_pred_cv-y_train, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_best_model_kneigh, test_predictions_best_model_kneigh-y_test, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=-.05, xmax=.35, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Tuned K Neighbor Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes too long\n",
    "#lin_reg_intonly_pred_cv = cross_val_predict(lin_reg_intonly, X_train_intonly, y_train_intonly, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"plt.scatter(lin_reg_intonly_pred_cv, lin_reg_intonly_pred_cv-y_train_intonly, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_lin_reg_intonly, test_predictions_lin_reg_intonly-y_test_intonly, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=y_train_intonly.min()-1, xmax=y_train_intonly.max()+1, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Linear Regression with Interactions')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes too long\n",
    "#quad_reg_pred_cv = cross_val_predict(quad_reg, X_train_quad, y_train_quad, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"plt.scatter(quad_reg_pred_cv, quad_reg_pred_cv-y_train_quad, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_quad_reg, test_predictions_quad_reg-y_test_quad, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='CV Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=y_train_intonly.min()-1, xmax=y_train_intonly.max()+1, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Quadratic Regression')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model After Adding Ratios and Doing Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train, y_train)\n",
    "test_predictions_ratios_lin_reg = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with Ratio Features & Feature Selection'\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_ratios_lin_reg)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_ratios_lin_reg))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_ratios_lin_reg)\n",
    "map_variable(y_test-test_predictions_ratios_lin_reg, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratios_lin_reg_pred_cv = cross_val_predict(lin_reg, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(ratios_lin_reg_pred_cv, ratios_lin_reg_pred_cv-y_train, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_ratios_lin_reg, test_predictions_ratios_lin_reg-y_test, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=-.3, xmax=.4, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Linear Regression with Ratio Features & Feature Selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's introduce some degree of regularization to see if we can decrease validation RMSE even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-8, -0.5, 30)\n",
    "param_grid = [{'alpha': alphas},]\n",
    "n_folds = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(lasso, param_grid, cv=n_folds,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores_lasso = np.sqrt(-gs.cv_results_['mean_train_score'])\n",
    "train_scores_std_lasso = np.sqrt(-gs.cv_results_['std_train_score'])\n",
    "val_scores_lasso = np.sqrt(-gs.cv_results_['mean_test_score'])\n",
    "val_scores_std_lasso = np.sqrt(-gs.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure().set_size_inches(10, 6)\n",
    "plt.semilogx(alphas, val_scores_lasso)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = val_scores_std_lasso / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, val_scores_lasso + std_error, 'b--')\n",
    "plt.semilogx(alphas, val_scores_lasso - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, val_scores_lasso + std_error, val_scores_lasso - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(val_scores_lasso), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_lasso = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comparing Model Coefficients by using best model parameters obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = []\n",
    "for a in alphas:\n",
    "    lasso = linear_model.Lasso(alpha=a, fit_intercept=False)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Lasso Coefficients as a Function of Alpha')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions_lasso = best_model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_variable(y_test-test_predictions_lasso, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Test R2: ',r2_score(y_test, test_predictions_lasso)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_lasso))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, np.abs(best_model_lasso.coef_)):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Lasso_Coef'})\n",
    "importances = importances.sort_values(by='Lasso_Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Number of Nonzero coefficients: \", len(importances[importances['Lasso_Coef']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(best_model_lasso)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying Ridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-8, -0.5, 30)\n",
    "param_grid = [{'alpha': alphas},]\n",
    "n_folds = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(ridge, param_grid, cv=n_folds,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores_ridge = np.sqrt(-gs.cv_results_['mean_train_score'])\n",
    "train_scores_std_ridge = np.sqrt(-gs.cv_results_['std_train_score'])\n",
    "val_scores_ridge = np.sqrt(-gs.cv_results_['mean_test_score'])\n",
    "val_scores_std_ridge = np.sqrt(-gs.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure().set_size_inches(10, 6)\n",
    "plt.semilogx(alphas, val_scores_ridge)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = val_scores_std_ridge / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, val_scores_ridge + std_error, 'b--')\n",
    "plt.semilogx(alphas, val_scores_ridge - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, val_scores_ridge + std_error, val_scores_ridge - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(val_scores_ridge), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comparing Model Coefficients by using best model parameters obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = []\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=a, fit_intercept=False)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge Coefficients as a Function of Alpha')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_ridge = gs.best_estimator_\n",
    "test_predictions_ridge = best_model_ridge.predict(X_test)\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_ridge)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_ridge))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_variable(y_test-test_predictions_ridge, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, np.abs(best_model_ridge.coef_)):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Ridge_Coef'})\n",
    "importances = importances.sort_values(by='Ridge_Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Number of Nonzero coefficients: \", len(importances[importances['Ridge_Coef']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(best_model_ridge)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Using ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en = linear_model.ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-8, -0.5, 30)\n",
    "param_grid = [{'alpha': alphas},]\n",
    "n_folds = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(en, param_grid, cv=n_folds,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores_en = np.sqrt(-gs.cv_results_['mean_train_score'])\n",
    "train_scores_std_en = np.sqrt(-gs.cv_results_['std_train_score'])\n",
    "val_scores_en = np.sqrt(-gs.cv_results_['mean_test_score'])\n",
    "val_scores_std_en = np.sqrt(-gs.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure().set_size_inches(10, 6)\n",
    "plt.semilogx(alphas, val_scores_en)\n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = val_scores_std_en / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, val_scores_en + std_error, 'b--')\n",
    "plt.semilogx(alphas, val_scores_en - std_error, 'b--')\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, val_scores_en + std_error, val_scores_en - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel('CV score +/- std error')\n",
    "plt.xlabel('alpha')\n",
    "plt.axhline(np.max(val_scores_en), linestyle='--', color='.5')\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comparing Model Coefficients by using best model parameters obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = []\n",
    "for a in alphas:\n",
    "    ridge = linear_model.ElasticNet(alpha=a, fit_intercept=False)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Elastic Net Coefficients as a Function of Alpha')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_en = gs.best_estimator_\n",
    "test_predictions_en = best_model_en.predict(X_test)\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_en)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_en))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_variable(y_test-test_predictions_en, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, np.abs(best_model_en.coef_)):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'EN_Coef'})\n",
    "importances = importances.sort_values(by='EN_Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Number of Nonzero coefficients: \" ,len(importances[importances['EN_Coef']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(best_model_en)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Regressor Does very well on both Training and Validation - a promising model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators':[3,10,30], 'max_features':[8,10,12]},\n",
    "    {'bootstrap': [True,False], 'n_estimators':[3,10], 'max_features':[10,12]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_for_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(new_for_reg, param_grid, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr_scores = cross_validate(gs, X_train, y_train, cv=6, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"CV Training RMSE: \", np.sqrt(-rfr_scores['train_score'].mean())\n",
    "print \"CV Validation RMSE: \",np.sqrt(-rfr_scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_results_rf = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_best_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp = rf_best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "imp = pd.DataFrame(sorted(zip(X_ratios.columns, imp),reverse=True,key=itemgetter(1)), columns=['Feature', 'Importance']).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we are strongly overfitting. Can this be improved with feature selection? Let's look at how many top features minimize validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_rmse_features(rf_best_model, X_train, y_train, imp.Feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the top n features such that n minimizes training error\n",
    "The above needs to be run again - there was an error in the viz method - for now I am picking the top 80 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios[list(imp.Feature.head(50))], y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr_best = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features=12, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=1,\n",
    "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=30, n_jobs=1, oob_score=False, random_state=None,\n",
    "           verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_rfr_scores = cross_validate(rfr_best, X_train, y_train, cv=6, scoring=('r2','neg_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"CV Training RMSE: \", best_rfr_scores['train_r2'].mean()\n",
    "print \"CV Validation RMSE: \",best_rfr_scores['test_r2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"CV Training RMSE: \", np.sqrt(-best_rfr_scores['train_neg_mean_squared_error'].mean())\n",
    "print \"CV Validation RMSE: \",np.sqrt(-best_rfr_scores['test_neg_mean_squared_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions_rf = rfr_best.predict(X_test)\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_rf)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_rf))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_variable(y_test-test_predictions_rf, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr_best_train_pred_cv = cross_val_predict(rfr_best, X_train, y_train, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(rfr_best_train_pred_cv, rfr_best_train_pred_cv-y_train, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_rf, test_predictions_rf-y_test, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=-.1, xmax=.4, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Tuned Random Forest Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "br = BaggingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators':[3,10,30], 'max_features':[i for i in range(31,81,20)]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(br, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print gs.best_params_\n",
    "print gs.best_estimator_\n",
    "gs_results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores_br = np.sqrt(-gs.cv_results_['mean_train_score'])\n",
    "train_scores_std_br = np.sqrt(-gs.cv_results_['std_train_score'])\n",
    "val_scores_br = np.sqrt(-gs.cv_results_['mean_test_score'])\n",
    "val_scores_std_br = np.sqrt(-gs.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_br = gs.best_estimator_\n",
    "test_predictions_br = best_model_br.predict(X_test)\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_br)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_br))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_variable(y_test-test_predictions_br, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(best_model_br)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abr = AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators':[3,10,30]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(abr, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print gs.best_params_\n",
    "print gs.best_estimator_\n",
    "gs_results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores_abr = np.sqrt(-gs.cv_results_['mean_train_score'])\n",
    "train_scores_std_abr = np.sqrt(-gs.cv_results_['std_train_score'])\n",
    "val_scores_abr = np.sqrt(-gs.cv_results_['mean_test_score'])\n",
    "val_scores_std_abr = np.sqrt(-gs.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_abr = gs.best_estimator_\n",
    "test_predictions_abr = best_model_abr.predict(X_test)\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_abr)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_abr))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_abr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_variable(y_test-test_predictions_abr, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(best_model_abr)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators':[3,10,30]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(gbr, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print gs.best_params_\n",
    "print gs.best_estimator_\n",
    "gs_results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores_gbr = np.sqrt(-gs.cv_results_['mean_train_score'])\n",
    "train_scores_std_gbr = np.sqrt(-gs.cv_results_['std_train_score'])\n",
    "val_scores_gbr = np.sqrt(-gs.cv_results_['mean_test_score'])\n",
    "val_scores_std_gbr = np.sqrt(-gs.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_gbr = gs.best_estimator_\n",
    "test_predictions_gbr = best_model_gbr.predict(X_test)\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_gbr)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_gbr))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_variable(y_test-test_predictions_gbr, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(best_model_gbr)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for First Batch of Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ['Linear', 'Decision Tree', 'Support Vector', 'KNN', 'Linear w Interactions', 'Quadratic', 'Linear w Feature Sel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errors = [np.sqrt(-scores_lin['train_neg_mean_squared_error'].mean()),\n",
    "                np.sqrt(-scores_tree['train_neg_mean_squared_error'].mean())+.001,\n",
    "                np.sqrt(-gs_results_svreg['mean_train_score'].mean()),\n",
    "                np.sqrt(-gs_results_nn['mean_train_score'].mean()),\n",
    "                np.sqrt(-scores_lin_intonly['train_neg_mean_squared_error'].mean())+.001, \n",
    "                np.sqrt(-scores_quad['train_neg_mean_squared_error'].mean())+.001, \n",
    "                np.sqrt(-scores_lin_ratios['train_neg_mean_squared_error'].mean()),\n",
    "                np.sqrt(-scores_lin_ratios_fsel['train_neg_mean_squared_error'].mean())]\n",
    "\n",
    "val_errors = [np.sqrt(-scores_lin['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-scores_tree['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-gs_results_svreg['mean_test_score'].mean()),\n",
    "              np.sqrt(-gs_results_nn['mean_test_score'].mean()),\n",
    "              np.sqrt(-scores_lin_intonly['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-scores_quad['test_neg_mean_squared_error'].mean()), \n",
    "              np.sqrt(-scores_lin_ratios['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-scores_lin_ratios_fsel['test_neg_mean_squared_error'].mean())]\n",
    "\n",
    "test_errors = [lin_reg_rmse_test,\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_tree_reg)),\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_best_model_svr)),\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_best_model_kneigh)),\n",
    "            np.sqrt(mean_squared_error(y_test_intonly, test_predictions_lin_reg_intonly)),\n",
    "            np.sqrt(mean_squared_error(y_test_quad, test_predictions_quad_reg)),\n",
    "               test_lin_ratios_nofs,\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_ratios_lin_reg))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "x1 = [i-0.2 for i in range(len(train_errors))]\n",
    "x2 = [i for i in range(len(train_errors))]\n",
    "x3 = [i+0.2 for i in range(len(train_errors))]\n",
    "ax.bar(x1, train_errors, width=0.2, color='b', align='center')\n",
    "ax.bar(x2, val_errors, width=0.2, color='g', align='center')\n",
    "ax.bar(x3, test_errors, width=0.2, color='r', align='center')\n",
    "ax.set_xticklabels(X)\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i-0.05 for i in x2]))\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Regression Models Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for Regularized Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(-scores_quad['train_neg_mean_squared_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ['Lasso', 'Ridge', 'Elastic Net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errors = [train_scores_lasso.mean(), train_scores_ridge.mean(), train_scores_en.mean()]\n",
    "val_errors = [val_scores_lasso.mean(), val_scores_ridge.mean(), val_scores_en.mean()]\n",
    "test_errors = [np.sqrt(mean_squared_error(y_test, test_predictions_lasso)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_ridge)), \n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_en))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, test_predictions_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "x1 = [i-0.2 for i in range(len(train_errors))]\n",
    "x2 = [i for i in range(len(train_errors))]\n",
    "x3 = [i+0.2 for i in range(len(train_errors))]\n",
    "ax.bar(x1, train_errors, width=0.2, color='b', align='center')\n",
    "ax.bar(x2, val_errors, width=0.2, color='g', align='center')\n",
    "ax.bar(x3, test_errors, width=0.2, color='r', align='center')\n",
    "ax.set_xticklabels(X)\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i-0.05 for i in x2]))\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Regularized Models Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ['Random Forest', 'Bagging', 'AdaBoost', 'Gradient Boosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(-best_rfr_scores['train_neg_mean_squared_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errors = [np.sqrt(-best_rfr_scores['train_neg_mean_squared_error'].mean()),\n",
    "                train_scores_br.mean(),\n",
    "                train_scores_abr.mean(),\n",
    "                train_scores_gbr.mean()]\n",
    "\n",
    "val_errors = [np.sqrt(-best_rfr_scores['test_neg_mean_squared_error'].mean()),\n",
    "              val_scores_br.mean(),\n",
    "              val_scores_abr.mean(),\n",
    "              val_scores_gbr.mean()]\n",
    "\n",
    "test_errors = [np.sqrt(mean_squared_error(y_test, test_predictions_rf)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_br)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_abr)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_gbr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "ax = plt.subplot(111)\n",
    "x1 = [i-0.2 for i in range(len(train_errors))]\n",
    "x2 = [i for i in range(len(train_errors))]\n",
    "x3 = [i+0.2 for i in range(len(train_errors))]\n",
    "ax.bar(x1, train_errors, width=0.2, color='b', align='center')\n",
    "ax.bar(x2, val_errors, width=0.2, color='g', align='center')\n",
    "ax.bar(x3, test_errors, width=0.2, color='r', align='center')\n",
    "ax.set_xticklabels(X)\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i-0.05 for i in x2]))\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Ensembles Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA To explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_comps = 200\n",
    "pca = PCA(n_components=n_comps)\n",
    "model_fit = pca.fit(X_ratios)\n",
    "X_transform = model_fit.transform(X_ratios)\n",
    "print'Score for PCA with %i Components: %i' %(n_comps,model_fit.score(X_ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight: 25 components will tell us everything! We will run Gridsearch CV to confirm later but looking at this plot would be enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print 'Explained Variance: '\n",
    "print pd.Series(model_fit.explained_variance_).head()\n",
    "print '\\n'\n",
    "print 'Explained Variance Ratio: '\n",
    "print pd.Series(model_fit.explained_variance_ratio_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features.pca import PCADecomposition\n",
    "from yellowbrick.features.importances import FeatureImportances\n",
    "\n",
    "\n",
    "visualizer = PCADecomposition(n_components=25, scale=False, colormap='autumn')\n",
    "visualizer.fit(X_normed)\n",
    "visualizer.transform(X_normed)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features.pca import PCADecomposition\n",
    "from yellowbrick.features.importances import FeatureImportances\n",
    "\n",
    "\n",
    "visualizer = PCADecomposition(n_components=25, scale=False, colormap='autumn')\n",
    "visualizer.fit(X_ratios)\n",
    "visualizer.transform(X_ratios)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features.pca import PCADecomposition\n",
    "from yellowbrick.features.importances import FeatureImportances\n",
    "\n",
    "\n",
    "visualizer = PCADecomposition(n_components=25, scale=False, proj_dim=3, c='r')\n",
    "visualizer.fit(X_normed)\n",
    "visualizer.transform(X_normed)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualizer = PCADecomposition(scale=False,n_components=25, proj_dim=3, c='y')\n",
    "visualizer.fit(X_ratios)\n",
    "visualizer.transform(X_ratios)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "comps = [i for i in range(20,28,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('pca', pca), ('reg', test_lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = GridSearchCV(pipe, dict(pca__n_components=comps), cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(X_normed, y_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight: 26 is actually the optimal number of components!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator.best_estimator_.named_steps['reg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now actually running the regression on the reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed, y_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=26)\n",
    "lr = linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('pca', pca), ('reg', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)\n",
    "pipe.predict(X_test)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight: with this rudimental, untuned linear regression on 60 principal components we obtained an R2 of 58%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Just checking that it's the same as above...\n",
    "print 'R2 with PCA with 60 components: ', r2_score(y_test,pipe.predict(X_test))\n",
    "print 'RMSE with PCA with 60 components: ', mean_squared_error(y_test,pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'CV Accuracy: ', cross_val_score(pipe, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
