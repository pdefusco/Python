{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Binary Classification with Time Series Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Objective: modify David Ziganto's introduction to online learning to learn with time series dataset\n",
    "- Dataset source: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "- Original Post: https://dziganto.github.io/data%20science/online%20learning/python/scikit-learn/An-Introduction-To-Online-Machine-Learning/\n",
    "- Referenced Notebook: https://github.com/dziganto/dziganto.github.io/blob/master/_notebooks/Online_Learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation with Time Series Split on the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating unseen dataset with last 50 instances to simulate future data instances to demo online learning\n",
    "unseen_data = df.iloc[len(df)-50:len(df),:]\n",
    "seen_data = df.iloc[:len(df)-50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simplifying df to a few numeric features to keep demo simple\n",
    "X = seen_data[['age', 'duration', 'campaign', 'pdays']]\n",
    "#Binarizing y \n",
    "y = [1 if i == 'yes' else 0 for i in seen_data['y'] ]\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five rows of X\n",
      "[[ 56 261   1 999]\n",
      " [ 57 149   1 999]\n",
      " [ 37 226   1 999]\n",
      " [ 40 151   1 999]\n",
      " [ 56 307   1 999]]\n",
      "\n",
      "\n",
      "First five rows of y\n",
      "[0 0 0 0 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Showing first five rows of x and y\n",
    "print('First five rows of X')\n",
    "print(X[:5,:])\n",
    "print('\\n')\n",
    "print('First five rows of y')\n",
    "print(y[:5])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replicating X and y for unseen future data\n",
    "X_new = unseen_data[['age', 'duration', 'campaign', 'pdays']]\n",
    "#Binarizing y \n",
    "y_new = [1 if i == 'yes' else 0 for i in unseen_data['y'] ]\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size = 0.33, \n",
    "                                                    random_state=2, \n",
    "                                                    shuffle = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape:  (27562, 4)\n",
      "y Train Shape:  (27562,)\n",
      "X Test Shape:  (13576, 4)\n",
      "y Test Shape:  (13576,)\n"
     ]
    }
   ],
   "source": [
    "print('X Train Shape: ', X_train.shape)\n",
    "print('y Train Shape: ', y_train.shape)\n",
    "print('X Test Shape: ', X_test.shape)\n",
    "print('y Test Shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Training and Test Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested CV with Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluating both online SVM (hinge) and Logistic Regression (huber) \n",
    "#Notice target classes are highly imbalanced\n",
    "param_search = {'loss' : ['hinge','huber'], \n",
    "                'alpha':[0.25,0.5,0.75], \n",
    "                'penalty':['l2'],\n",
    "                'shuffle':[True], \n",
    "                'learning_rate':['optimal'],\n",
    "                'class_weight':['balanced'],\n",
    "                'verbose':[1], \n",
    "               'max_iter':[100], \n",
    "               'tol': [1e-3], \n",
    "               'random_state':[22]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_search, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.73, NNZs: 4, Bias: -0.573634, T: 9188, Avg. loss: 0.425316\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.74, NNZs: 4, Bias: -0.558219, T: 18376, Avg. loss: 0.390935\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.73, NNZs: 4, Bias: -0.557949, T: 27564, Avg. loss: 0.396620\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.74, NNZs: 4, Bias: -0.559139, T: 36752, Avg. loss: 0.397546\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.73, NNZs: 4, Bias: -0.561580, T: 45940, Avg. loss: 0.398684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 4, Bias: -0.560068, T: 55128, Avg. loss: 0.396829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.74, NNZs: 4, Bias: -0.560469, T: 64316, Avg. loss: 0.396647\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.554143, T: 18375, Avg. loss: 0.400382\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.557717, T: 36750, Avg. loss: 0.396155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.561190, T: 55125, Avg. loss: 0.394634\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.557158, T: 73500, Avg. loss: 0.390511\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.558663, T: 91875, Avg. loss: 0.397099\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.559143, T: 110250, Avg. loss: 0.395496\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.559720, T: 128625, Avg. loss: 0.394199\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.560663, T: 147000, Avg. loss: 0.395361\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.559975, T: 165375, Avg. loss: 0.393944\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 9 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.120226, T: 9188, Avg. loss: 0.079163\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.129275, T: 18376, Avg. loss: 0.077501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.134293, T: 27564, Avg. loss: 0.076968\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.137635, T: 36752, Avg. loss: 0.076681\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.140234, T: 45940, Avg. loss: 0.076428\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.142352, T: 55128, Avg. loss: 0.076249\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.144157, T: 64316, Avg. loss: 0.076074\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.156382, T: 18375, Avg. loss: 0.076092\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.164511, T: 36750, Avg. loss: 0.074661\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.169625, T: 55125, Avg. loss: 0.074042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.173407, T: 73500, Avg. loss: 0.073648\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.176137, T: 91875, Avg. loss: 0.073447\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.178335, T: 110250, Avg. loss: 0.073249\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.25, NNZs: 4, Bias: -0.180241, T: 128625, Avg. loss: 0.073063\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.580418, T: 9188, Avg. loss: 0.453972\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.582903, T: 18376, Avg. loss: 0.382572\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.584503, T: 27564, Avg. loss: 0.384039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.586787, T: 36752, Avg. loss: 0.384009\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.587447, T: 45940, Avg. loss: 0.383750\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.587091, T: 55128, Avg. loss: 0.382776\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.587995, T: 64316, Avg. loss: 0.382434\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.589778, T: 18375, Avg. loss: 0.383954\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.589986, T: 36750, Avg. loss: 0.378226\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.590594, T: 55125, Avg. loss: 0.377218\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.589221, T: 73500, Avg. loss: 0.375323\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.589772, T: 91875, Avg. loss: 0.378628\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.589579, T: 110250, Avg. loss: 0.378511\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.589741, T: 128625, Avg. loss: 0.377762\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.589978, T: 147000, Avg. loss: 0.378315\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.589596, T: 165375, Avg. loss: 0.377686\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 9 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.15, NNZs: 4, Bias: -0.019494, T: 9188, Avg. loss: 0.088662\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.15, NNZs: 4, Bias: -0.020251, T: 18376, Avg. loss: 0.088553\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.15, NNZs: 4, Bias: -0.020367, T: 27564, Avg. loss: 0.088516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 4, Bias: -0.020444, T: 36752, Avg. loss: 0.088521\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.15, NNZs: 4, Bias: -0.020460, T: 45940, Avg. loss: 0.088515\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.15, NNZs: 4, Bias: -0.020528, T: 55128, Avg. loss: 0.088516\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.059006, T: 18375, Avg. loss: 0.085226\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.059073, T: 36750, Avg. loss: 0.085403\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.059341, T: 55125, Avg. loss: 0.085359\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.059622, T: 73500, Avg. loss: 0.085307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.059718, T: 91875, Avg. loss: 0.085325\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.059802, T: 110250, Avg. loss: 0.085317\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.56, NNZs: 4, Bias: -0.539889, T: 9188, Avg. loss: 0.505195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.582014, T: 18376, Avg. loss: 0.403467\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.593866, T: 27564, Avg. loss: 0.387752\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.600731, T: 36752, Avg. loss: 0.382650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.604997, T: 45940, Avg. loss: 0.379423\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.606774, T: 55128, Avg. loss: 0.377038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.609025, T: 64316, Avg. loss: 0.375433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.610404, T: 73504, Avg. loss: 0.374848\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.610933, T: 82692, Avg. loss: 0.373553\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.611641, T: 91880, Avg. loss: 0.373750\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.612072, T: 101068, Avg. loss: 0.372751\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.612710, T: 110256, Avg. loss: 0.373542\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.613019, T: 119444, Avg. loss: 0.372870\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.613194, T: 128632, Avg. loss: 0.372798\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 14 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.54, NNZs: 4, Bias: -0.616962, T: 18375, Avg. loss: 0.371147\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617988, T: 36750, Avg. loss: 0.367035\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617603, T: 55125, Avg. loss: 0.365657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617279, T: 73500, Avg. loss: 0.363978\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617567, T: 91875, Avg. loss: 0.366381\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617262, T: 110250, Avg. loss: 0.366457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617450, T: 128625, Avg. loss: 0.365752\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617555, T: 147000, Avg. loss: 0.366254\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.617499, T: 165375, Avg. loss: 0.365873\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 9 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.032792, T: 9188, Avg. loss: 0.089195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.033230, T: 18376, Avg. loss: 0.089140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.033263, T: 27564, Avg. loss: 0.089119\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.033288, T: 36752, Avg. loss: 0.089130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.033278, T: 45940, Avg. loss: 0.089129\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.033306, T: 55128, Avg. loss: 0.089131\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.056581, T: 18375, Avg. loss: 0.087031\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.056352, T: 36750, Avg. loss: 0.087172\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.056406, T: 55125, Avg. loss: 0.087174\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.056498, T: 73500, Avg. loss: 0.087146\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.056489, T: 91875, Avg. loss: 0.087166\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.056486, T: 110250, Avg. loss: 0.087167\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.613583, T: 27562, Avg. loss: 0.356913\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.618515, T: 55124, Avg. loss: 0.359675\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.619449, T: 82686, Avg. loss: 0.360947\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.620021, T: 110248, Avg. loss: 0.360380\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.620136, T: 137810, Avg. loss: 0.359781\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.620175, T: 165372, Avg. loss: 0.359849\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=2),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'loss': ['hinge', 'huber'], 'alpha': [0.25, 0.5, 0.75], 'penalty': ['l2'], 'shuffle': [True], 'learning_rate': ['optimal'], 'class_weight': ['balanced'], 'verbose': [1], 'max_iter': [100], 'tol': [0.001], 'random_state': [22]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Hyperparameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best Estimator Hyperparameters:')\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicting on Test set\n",
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8992339422510313\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on Test Set:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Final Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_estimator = SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, shuffle=True, tol=0.001,\n",
    "       validation_fraction=0.1, verbose=1, warm_start=False, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.21, NNZs: 4, Bias: 3.372936, T: 41138, Avg. loss: 454.982334\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.17, NNZs: 4, Bias: 3.366401, T: 82276, Avg. loss: 12.507060\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.15, NNZs: 4, Bias: 3.362384, T: 123414, Avg. loss: 7.452187\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 4, Bias: 3.359697, T: 164552, Avg. loss: 5.310327\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 4, Bias: 3.357477, T: 205690, Avg. loss: 4.294072\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.14, NNZs: 4, Bias: 3.355670, T: 246828, Avg. loss: 3.550125\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.14, NNZs: 4, Bias: 3.354170, T: 287966, Avg. loss: 3.044687\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.352866, T: 329104, Avg. loss: 2.778474\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.351684, T: 370242, Avg. loss: 2.396802\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.350647, T: 411380, Avg. loss: 2.208822\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.349703, T: 452518, Avg. loss: 2.047502\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.348842, T: 493656, Avg. loss: 1.917355\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.348057, T: 534794, Avg. loss: 1.828177\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.347329, T: 575932, Avg. loss: 1.721643\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.346635, T: 617070, Avg. loss: 1.608878\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.346006, T: 658208, Avg. loss: 1.544030\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.345399, T: 699346, Avg. loss: 1.484269\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.344839, T: 740484, Avg. loss: 1.424483\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.344298, T: 781622, Avg. loss: 1.337122\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.343791, T: 822760, Avg. loss: 1.341488\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.343309, T: 863898, Avg. loss: 1.282952\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.342847, T: 905036, Avg. loss: 1.223402\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.342411, T: 946174, Avg. loss: 1.202105\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.341996, T: 987312, Avg. loss: 1.153847\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.341586, T: 1028450, Avg. loss: 1.155305\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.341201, T: 1069588, Avg. loss: 1.109025\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.340824, T: 1110726, Avg. loss: 1.105036\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.340464, T: 1151864, Avg. loss: 1.069879\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.340118, T: 1193002, Avg. loss: 1.045991\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.339782, T: 1234140, Avg. loss: 1.014951\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.339454, T: 1275278, Avg. loss: 1.002706\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.339148, T: 1316416, Avg. loss: 1.008249\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.338838, T: 1357554, Avg. loss: 0.985283\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.338543, T: 1398692, Avg. loss: 0.952514\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.338256, T: 1439830, Avg. loss: 0.958012\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337976, T: 1480968, Avg. loss: 0.934857\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337707, T: 1522106, Avg. loss: 0.917594\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337443, T: 1563244, Avg. loss: 0.909848\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337186, T: 1604382, Avg. loss: 0.888672\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336935, T: 1645520, Avg. loss: 0.868167\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336690, T: 1686658, Avg. loss: 0.875201\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336454, T: 1727796, Avg. loss: 0.870711\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336219, T: 1768934, Avg. loss: 0.850662\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335993, T: 1810072, Avg. loss: 0.865557\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335772, T: 1851210, Avg. loss: 0.858475\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335559, T: 1892348, Avg. loss: 0.830014\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335340, T: 1933486, Avg. loss: 0.830053\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335134, T: 1974624, Avg. loss: 0.828002\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334930, T: 2015762, Avg. loss: 0.818992\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334730, T: 2056900, Avg. loss: 0.805388\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334533, T: 2098038, Avg. loss: 0.790275\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334340, T: 2139176, Avg. loss: 0.796391\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334155, T: 2180314, Avg. loss: 0.783100\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.333969, T: 2221452, Avg. loss: 0.783194\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333787, T: 2262590, Avg. loss: 0.778785\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333607, T: 2303728, Avg. loss: 0.781862\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333432, T: 2344866, Avg. loss: 0.769338\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333261, T: 2386004, Avg. loss: 0.758456\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333091, T: 2427142, Avg. loss: 0.758119\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332924, T: 2468280, Avg. loss: 0.744859\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332764, T: 2509418, Avg. loss: 0.751835\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332601, T: 2550556, Avg. loss: 0.751087\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332443, T: 2591694, Avg. loss: 0.740591\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332288, T: 2632832, Avg. loss: 0.736607\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332134, T: 2673970, Avg. loss: 0.742866\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331985, T: 2715108, Avg. loss: 0.717438\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331834, T: 2756246, Avg. loss: 0.731164\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331686, T: 2797384, Avg. loss: 0.731492\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331544, T: 2838522, Avg. loss: 0.715885\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331400, T: 2879660, Avg. loss: 0.721492\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331260, T: 2920798, Avg. loss: 0.699440\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331121, T: 2961936, Avg. loss: 0.710020\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330988, T: 3003074, Avg. loss: 0.696186\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330852, T: 3044212, Avg. loss: 0.700072\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330719, T: 3085350, Avg. loss: 0.692408\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330587, T: 3126488, Avg. loss: 0.708661\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330458, T: 3167626, Avg. loss: 0.687553\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.09, NNZs: 4, Bias: 3.330331, T: 3208764, Avg. loss: 0.686489\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330205, T: 3249902, Avg. loss: 0.695707\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330080, T: 3291040, Avg. loss: 0.685401\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329958, T: 3332178, Avg. loss: 0.691703\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329838, T: 3373316, Avg. loss: 0.684070\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329718, T: 3414454, Avg. loss: 0.670122\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329600, T: 3455592, Avg. loss: 0.683122\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329481, T: 3496730, Avg. loss: 0.670157\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329365, T: 3537868, Avg. loss: 0.670999\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.329252, T: 3579006, Avg. loss: 0.662839\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.329137, T: 3620144, Avg. loss: 0.666623\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.329025, T: 3661282, Avg. loss: 0.663094\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328916, T: 3702420, Avg. loss: 0.658477\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328805, T: 3743558, Avg. loss: 0.663722\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328698, T: 3784696, Avg. loss: 0.658787\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328591, T: 3825834, Avg. loss: 0.663022\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328485, T: 3866972, Avg. loss: 0.656724\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328380, T: 3908110, Avg. loss: 0.651502\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328276, T: 3949248, Avg. loss: 0.652986\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328175, T: 3990386, Avg. loss: 0.644196\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328073, T: 4031524, Avg. loss: 0.650671\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.327973, T: 4072662, Avg. loss: 0.651362\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.327875, T: 4113800, Avg. loss: 0.642825\n",
      "Total training time: 0.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the final model on the entire seen dataset\n",
    "final_estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0018559 ,  0.00575112, -0.08175267, -0.00336232]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_estimator.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.85, NNZs: 4, Bias: 0.346484, T: 50, Avg. loss: 24592.327698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.08, NNZs: 4, Bias: 0.306976, T: 100, Avg. loss: 3624.928276\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.28, NNZs: 4, Bias: 0.266718, T: 150, Avg. loss: 1811.045660\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.64, NNZs: 4, Bias: 0.245833, T: 200, Avg. loss: 1478.066820\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.57, NNZs: 4, Bias: 0.229612, T: 250, Avg. loss: 1110.732229\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.20, NNZs: 4, Bias: 0.216060, T: 300, Avg. loss: 828.798631\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 10.45, NNZs: 4, Bias: 0.198915, T: 350, Avg. loss: 1048.322157\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.92, NNZs: 4, Bias: 0.189090, T: 400, Avg. loss: 669.862176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.93, NNZs: 4, Bias: 0.179680, T: 450, Avg. loss: 616.754742\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.30, NNZs: 4, Bias: 0.169224, T: 500, Avg. loss: 501.083900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 6.47, NNZs: 4, Bias: 0.162377, T: 550, Avg. loss: 434.467784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 6.45, NNZs: 4, Bias: 0.156067, T: 600, Avg. loss: 367.111855\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 5.58, NNZs: 4, Bias: 0.148153, T: 650, Avg. loss: 358.182980\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.96, NNZs: 4, Bias: 0.142814, T: 700, Avg. loss: 351.463445\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 5.04, NNZs: 4, Bias: 0.137784, T: 750, Avg. loss: 286.253050\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.59, NNZs: 4, Bias: 0.133011, T: 800, Avg. loss: 288.096673\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 5.11, NNZs: 4, Bias: 0.126778, T: 850, Avg. loss: 287.736859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.35, NNZs: 4, Bias: 0.122473, T: 900, Avg. loss: 319.225137\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.11, NNZs: 4, Bias: 0.117112, T: 950, Avg. loss: 261.820930\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 3.99, NNZs: 4, Bias: 0.113382, T: 1000, Avg. loss: 223.475752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 3.60, NNZs: 4, Bias: 0.109739, T: 1050, Avg. loss: 254.842847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 3.32, NNZs: 4, Bias: 0.105407, T: 1100, Avg. loss: 150.649001\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3.61, NNZs: 4, Bias: 0.100969, T: 1150, Avg. loss: 193.332217\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 3.80, NNZs: 4, Bias: 0.098777, T: 1200, Avg. loss: 234.349499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 3.51, NNZs: 4, Bias: 0.094686, T: 1250, Avg. loss: 201.667893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 3.96, NNZs: 4, Bias: 0.090764, T: 1300, Avg. loss: 145.583636\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 3.78, NNZs: 4, Bias: 0.087812, T: 1350, Avg. loss: 235.730151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3.29, NNZs: 4, Bias: 0.085250, T: 1400, Avg. loss: 166.467432\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3.17, NNZs: 4, Bias: 0.082701, T: 1450, Avg. loss: 163.438122\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3.23, NNZs: 4, Bias: 0.080318, T: 1500, Avg. loss: 120.413358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3.37, NNZs: 4, Bias: 0.076953, T: 1550, Avg. loss: 163.044272\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3.38, NNZs: 4, Bias: 0.074565, T: 1600, Avg. loss: 153.427998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3.37, NNZs: 4, Bias: 0.071338, T: 1650, Avg. loss: 175.670398\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3.34, NNZs: 4, Bias: 0.069144, T: 1700, Avg. loss: 143.920170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3.13, NNZs: 4, Bias: 0.067047, T: 1750, Avg. loss: 139.566435\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 35 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_estimator.fit(X_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.85931351,  1.14843782, -0.24904998, -0.52056329]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_estimator.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
