{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Binary Classification with Time Series Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Objective: modify David Ziganto's introduction to online learning to learn with time series dataset\n",
    "- Dataset source: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "- Original Post: https://dziganto.github.io/data%20science/online%20learning/python/scikit-learn/An-Introduction-To-Online-Machine-Learning/\n",
    "- Referenced Notebook: https://github.com/dziganto/dziganto.github.io/blob/master/_notebooks/Online_Learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation with Time Series Split on the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating unseen dataset with last 50 instances to simulate future data instances to demo online learning\n",
    "unseen_data = df.iloc[len(df)-50:len(df),:]\n",
    "seen_data = df.iloc[:len(df)-50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplifying df to a few numeric features to keep demo simple\n",
    "X = seen_data[['age', 'duration', 'campaign', 'pdays']]\n",
    "#Binarizing y \n",
    "y = [1 if i == 'yes' else 0 for i in seen_data['y'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replicating X and y for unseen future data\n",
    "X_new = unseen_data[['age', 'duration', 'campaign', 'pdays']]\n",
    "#Binarizing y \n",
    "y_new = [1 if i == 'yes' else 0 for i in unseen_data['y'] ]\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X),np.array(y), \n",
    "                                                    test_size = 0.33, \n",
    "                                                    random_state=22, \n",
    "                                                    shuffle = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape:  (27562, 4)\n",
      "y Train Shape:  (27562,)\n",
      "X Test Shape:  (13576, 4)\n",
      "y Test Shape:  (13576,)\n"
     ]
    }
   ],
   "source": [
    "print('X Train Shape: ', X_train.shape)\n",
    "print('y Train Shape: ', y_train.shape)\n",
    "print('X Test Shape: ', X_test.shape)\n",
    "print('y Test Shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Training and Test Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested CV with Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluating both online SVM (hinge) and Logistic Regression (huber) \n",
    "#Notice target classes are highly imbalanced\n",
    "param_search = {'loss' : ['hinge','huber'], \n",
    "                'alpha':[0.25,0.5,0.75], \n",
    "                'penalty':['l2'],\n",
    "                'shuffle':[True], \n",
    "                'learning_rate':['optimal'],\n",
    "                'class_weight':['balanced'],\n",
    "                'verbose':[1], \n",
    "               'max_iter':[100], \n",
    "               'tol': [1e-3], \n",
    "               'random_state':[22]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_search, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.73, NNZs: 4, Bias: -0.591786, T: 9188, Avg. loss: 0.427356\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.564878, T: 18376, Avg. loss: 0.400334\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.553763, T: 27564, Avg. loss: 0.401777\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.553838, T: 36752, Avg. loss: 0.404139\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.553846, T: 45940, Avg. loss: 0.405852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.553558, T: 55128, Avg. loss: 0.403494\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.554575, T: 64316, Avg. loss: 0.406084\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.563350, T: 18375, Avg. loss: 0.394724\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.74, NNZs: 4, Bias: -0.563692, T: 36750, Avg. loss: 0.392278\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.560442, T: 55125, Avg. loss: 0.390419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.563243, T: 73500, Avg. loss: 0.394540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.564118, T: 91875, Avg. loss: 0.393793\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.562828, T: 110250, Avg. loss: 0.390957\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.563720, T: 128625, Avg. loss: 0.392881\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.75, NNZs: 4, Bias: -0.563056, T: 147000, Avg. loss: 0.392640\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 8 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.27, NNZs: 4, Bias: -0.299599, T: 9188, Avg. loss: 0.064051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.27, NNZs: 4, Bias: -0.303461, T: 18376, Avg. loss: 0.063411\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.27, NNZs: 4, Bias: -0.306425, T: 27564, Avg. loss: 0.063012\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.27, NNZs: 4, Bias: -0.308501, T: 36752, Avg. loss: 0.062808\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.27, NNZs: 4, Bias: -0.309955, T: 45940, Avg. loss: 0.062717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.27, NNZs: 4, Bias: -0.311202, T: 55128, Avg. loss: 0.062578\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 4, Bias: -0.481987, T: 18375, Avg. loss: 0.049090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.29, NNZs: 4, Bias: -0.486138, T: 36750, Avg. loss: 0.048314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.29, NNZs: 4, Bias: -0.488711, T: 55125, Avg. loss: 0.048089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.29, NNZs: 4, Bias: -0.490243, T: 73500, Avg. loss: 0.047983\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.29, NNZs: 4, Bias: -0.491428, T: 91875, Avg. loss: 0.047878\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.29, NNZs: 4, Bias: -0.492492, T: 110250, Avg. loss: 0.047760\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.61, NNZs: 4, Bias: -0.596314, T: 9188, Avg. loss: 0.413222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.587765, T: 18376, Avg. loss: 0.387214\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.581875, T: 27564, Avg. loss: 0.386917\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.582282, T: 36752, Avg. loss: 0.388107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.581892, T: 45940, Avg. loss: 0.389816\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.582457, T: 55128, Avg. loss: 0.388526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.583038, T: 64316, Avg. loss: 0.389504\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.589880, T: 18375, Avg. loss: 0.380854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.590371, T: 36750, Avg. loss: 0.376219\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.589935, T: 55125, Avg. loss: 0.375305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.62, NNZs: 4, Bias: -0.590792, T: 73500, Avg. loss: 0.377962\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.590853, T: 91875, Avg. loss: 0.377540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.590291, T: 110250, Avg. loss: 0.376108\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.63, NNZs: 4, Bias: -0.590347, T: 128625, Avg. loss: 0.377201\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.196158, T: 9188, Avg. loss: 0.075073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.195733, T: 18376, Avg. loss: 0.075085\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.195929, T: 27564, Avg. loss: 0.075036\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.196018, T: 36752, Avg. loss: 0.075032\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.195984, T: 45940, Avg. loss: 0.075043\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.196016, T: 55128, Avg. loss: 0.075036\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.274168, T: 18375, Avg. loss: 0.068767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.274318, T: 36750, Avg. loss: 0.068584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.274644, T: 55125, Avg. loss: 0.068566\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.274688, T: 73500, Avg. loss: 0.068573\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.274725, T: 91875, Avg. loss: 0.068564\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 4, Bias: -0.274811, T: 110250, Avg. loss: 0.068544\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.605213, T: 9188, Avg. loss: 0.403133\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.602560, T: 18376, Avg. loss: 0.384324\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 4, Bias: -0.601709, T: 27564, Avg. loss: 0.381246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.56, NNZs: 4, Bias: -0.601576, T: 36752, Avg. loss: 0.381336\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.56, NNZs: 4, Bias: -0.601178, T: 45940, Avg. loss: 0.382673\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 4, Bias: -0.601444, T: 55128, Avg. loss: 0.381781\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.56, NNZs: 4, Bias: -0.601777, T: 64316, Avg. loss: 0.382601\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 4, Bias: -0.601740, T: 73504, Avg. loss: 0.380772\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 8 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.608264, T: 18375, Avg. loss: 0.376761\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.609144, T: 36750, Avg. loss: 0.370088\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.609158, T: 55125, Avg. loss: 0.369395\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.609281, T: 73500, Avg. loss: 0.371089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.609426, T: 91875, Avg. loss: 0.370921\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.609244, T: 110250, Avg. loss: 0.369951\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.55, NNZs: 4, Bias: -0.609317, T: 128625, Avg. loss: 0.370759\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.159796, T: 9188, Avg. loss: 0.079476\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.159513, T: 18376, Avg. loss: 0.079484\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.159644, T: 27564, Avg. loss: 0.079451\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.159703, T: 36752, Avg. loss: 0.079449\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.159680, T: 45940, Avg. loss: 0.079456\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.10, NNZs: 4, Bias: -0.159702, T: 55128, Avg. loss: 0.079451\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.212706, T: 18375, Avg. loss: 0.075145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.212698, T: 36750, Avg. loss: 0.075027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.212858, T: 55125, Avg. loss: 0.075027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.212849, T: 73500, Avg. loss: 0.075036\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.212843, T: 91875, Avg. loss: 0.075032\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.11, NNZs: 4, Bias: -0.212877, T: 110250, Avg. loss: 0.075022\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 4, Bias: 0.116346, T: 27562, Avg. loss: 0.099261\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.16, NNZs: 4, Bias: 0.114697, T: 55124, Avg. loss: 0.098867\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.15, NNZs: 4, Bias: 0.113969, T: 82686, Avg. loss: 0.098820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 4, Bias: 0.113522, T: 110248, Avg. loss: 0.098789\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.15, NNZs: 4, Bias: 0.113185, T: 137810, Avg. loss: 0.098762\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.15, NNZs: 4, Bias: 0.112894, T: 165372, Avg. loss: 0.098752\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 6 epochs took 0.02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=2),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'loss': ['hinge', 'huber'], 'alpha': [0.25, 0.5, 0.75], 'penalty': ['l2'], 'shuffle': [True], 'learning_rate': ['optimal'], 'class_weight': ['balanced'], 'verbose': [1], 'max_iter': [100], 'tol': [0.001], 'random_state': [22]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Hyperparameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.5, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='huber', max_iter=100,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best Estimator Hyperparameters:')\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicting on Test set\n",
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.22127283441367118\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on Test Set:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Final Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, shuffle=True, tol=0.001,\n",
    "       validation_fraction=0.1, verbose=1, warm_start=False, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.21, NNZs: 4, Bias: 3.372936, T: 41138, Avg. loss: 454.982334\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.17, NNZs: 4, Bias: 3.366401, T: 82276, Avg. loss: 12.507060\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.15, NNZs: 4, Bias: 3.362384, T: 123414, Avg. loss: 7.452187\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 4, Bias: 3.359697, T: 164552, Avg. loss: 5.310327\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 4, Bias: 3.357477, T: 205690, Avg. loss: 4.294072\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.14, NNZs: 4, Bias: 3.355670, T: 246828, Avg. loss: 3.550125\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.14, NNZs: 4, Bias: 3.354170, T: 287966, Avg. loss: 3.044687\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.352866, T: 329104, Avg. loss: 2.778474\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.351684, T: 370242, Avg. loss: 2.396802\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.350647, T: 411380, Avg. loss: 2.208822\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.349703, T: 452518, Avg. loss: 2.047502\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.348842, T: 493656, Avg. loss: 1.917355\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.13, NNZs: 4, Bias: 3.348057, T: 534794, Avg. loss: 1.828177\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.347329, T: 575932, Avg. loss: 1.721643\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.346635, T: 617070, Avg. loss: 1.608878\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.346006, T: 658208, Avg. loss: 1.544030\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.345399, T: 699346, Avg. loss: 1.484269\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.344839, T: 740484, Avg. loss: 1.424483\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.344298, T: 781622, Avg. loss: 1.337122\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.343791, T: 822760, Avg. loss: 1.341488\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.343309, T: 863898, Avg. loss: 1.282952\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.12, NNZs: 4, Bias: 3.342847, T: 905036, Avg. loss: 1.223402\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.342411, T: 946174, Avg. loss: 1.202105\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.341996, T: 987312, Avg. loss: 1.153847\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.341586, T: 1028450, Avg. loss: 1.155305\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.341201, T: 1069588, Avg. loss: 1.109025\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.340824, T: 1110726, Avg. loss: 1.105036\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.340464, T: 1151864, Avg. loss: 1.069879\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.340118, T: 1193002, Avg. loss: 1.045991\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.339782, T: 1234140, Avg. loss: 1.014951\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.339454, T: 1275278, Avg. loss: 1.002706\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.339148, T: 1316416, Avg. loss: 1.008249\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.338838, T: 1357554, Avg. loss: 0.985283\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.11, NNZs: 4, Bias: 3.338543, T: 1398692, Avg. loss: 0.952514\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.338256, T: 1439830, Avg. loss: 0.958012\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337976, T: 1480968, Avg. loss: 0.934857\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337707, T: 1522106, Avg. loss: 0.917594\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337443, T: 1563244, Avg. loss: 0.909848\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.337186, T: 1604382, Avg. loss: 0.888672\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336935, T: 1645520, Avg. loss: 0.868167\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336690, T: 1686658, Avg. loss: 0.875201\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336454, T: 1727796, Avg. loss: 0.870711\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.336219, T: 1768934, Avg. loss: 0.850662\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335993, T: 1810072, Avg. loss: 0.865557\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335772, T: 1851210, Avg. loss: 0.858475\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335559, T: 1892348, Avg. loss: 0.830014\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335340, T: 1933486, Avg. loss: 0.830053\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.335134, T: 1974624, Avg. loss: 0.828002\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334930, T: 2015762, Avg. loss: 0.818992\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334730, T: 2056900, Avg. loss: 0.805388\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334533, T: 2098038, Avg. loss: 0.790275\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334340, T: 2139176, Avg. loss: 0.796391\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.334155, T: 2180314, Avg. loss: 0.783100\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.10, NNZs: 4, Bias: 3.333969, T: 2221452, Avg. loss: 0.783194\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333787, T: 2262590, Avg. loss: 0.778785\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333607, T: 2303728, Avg. loss: 0.781862\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333432, T: 2344866, Avg. loss: 0.769338\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333261, T: 2386004, Avg. loss: 0.758456\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.333091, T: 2427142, Avg. loss: 0.758119\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332924, T: 2468280, Avg. loss: 0.744859\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332764, T: 2509418, Avg. loss: 0.751835\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332601, T: 2550556, Avg. loss: 0.751087\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332443, T: 2591694, Avg. loss: 0.740591\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332288, T: 2632832, Avg. loss: 0.736607\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.332134, T: 2673970, Avg. loss: 0.742866\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331985, T: 2715108, Avg. loss: 0.717438\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331834, T: 2756246, Avg. loss: 0.731164\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331686, T: 2797384, Avg. loss: 0.731492\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331544, T: 2838522, Avg. loss: 0.715885\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331400, T: 2879660, Avg. loss: 0.721492\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331260, T: 2920798, Avg. loss: 0.699440\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.331121, T: 2961936, Avg. loss: 0.710020\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330988, T: 3003074, Avg. loss: 0.696186\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330852, T: 3044212, Avg. loss: 0.700072\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330719, T: 3085350, Avg. loss: 0.692408\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330587, T: 3126488, Avg. loss: 0.708661\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330458, T: 3167626, Avg. loss: 0.687553\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330331, T: 3208764, Avg. loss: 0.686489\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330205, T: 3249902, Avg. loss: 0.695707\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.330080, T: 3291040, Avg. loss: 0.685401\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329958, T: 3332178, Avg. loss: 0.691703\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329838, T: 3373316, Avg. loss: 0.684070\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329718, T: 3414454, Avg. loss: 0.670122\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329600, T: 3455592, Avg. loss: 0.683122\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329481, T: 3496730, Avg. loss: 0.670157\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.09, NNZs: 4, Bias: 3.329365, T: 3537868, Avg. loss: 0.670999\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.329252, T: 3579006, Avg. loss: 0.662839\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.329137, T: 3620144, Avg. loss: 0.666623\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.329025, T: 3661282, Avg. loss: 0.663094\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328916, T: 3702420, Avg. loss: 0.658477\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328805, T: 3743558, Avg. loss: 0.663722\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328698, T: 3784696, Avg. loss: 0.658787\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328591, T: 3825834, Avg. loss: 0.663022\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328485, T: 3866972, Avg. loss: 0.656724\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328380, T: 3908110, Avg. loss: 0.651502\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328276, T: 3949248, Avg. loss: 0.652986\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.08, NNZs: 4, Bias: 3.328175, T: 3990386, Avg. loss: 0.644196\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.328073, T: 4031524, Avg. loss: 0.650671\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.327973, T: 4072662, Avg. loss: 0.651362\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.08, NNZs: 4, Bias: 3.327875, T: 4113800, Avg. loss: 0.642825\n",
      "Total training time: 0.43 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the final model on the entire seen dataset\n",
    "final_estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0018559 ,  0.00575112, -0.08175267, -0.00336232]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_estimator.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#([[-0.0018559 ,  0.00575112, -0.08175267, -0.00336232]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 31. 202.   3. 999.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-354-42d46f473e21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    741\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         X, y = check_X_y(X, y, 'csr', dtype=np.float64, order=\"C\",\n\u001b[0;32m--> 570\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 31. 202.   3. 999.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "final_estimator.fit(X_new[1], y_new[1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 23.85, NNZs: 4, Bias: 0.346484, T: 50, Avg. loss: 24592.327698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 25.08, NNZs: 4, Bias: 0.306976, T: 100, Avg. loss: 3624.928276\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.28, NNZs: 4, Bias: 0.266718, T: 150, Avg. loss: 1811.045660\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.64, NNZs: 4, Bias: 0.245833, T: 200, Avg. loss: 1478.066820\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.57, NNZs: 4, Bias: 0.229612, T: 250, Avg. loss: 1110.732229\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.20, NNZs: 4, Bias: 0.216060, T: 300, Avg. loss: 828.798631\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 10.45, NNZs: 4, Bias: 0.198915, T: 350, Avg. loss: 1048.322157\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.92, NNZs: 4, Bias: 0.189090, T: 400, Avg. loss: 669.862176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.93, NNZs: 4, Bias: 0.179680, T: 450, Avg. loss: 616.754742\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.30, NNZs: 4, Bias: 0.169224, T: 500, Avg. loss: 501.083900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 6.47, NNZs: 4, Bias: 0.162377, T: 550, Avg. loss: 434.467784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 6.45, NNZs: 4, Bias: 0.156067, T: 600, Avg. loss: 367.111855\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 5.58, NNZs: 4, Bias: 0.148153, T: 650, Avg. loss: 358.182980\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.96, NNZs: 4, Bias: 0.142814, T: 700, Avg. loss: 351.463445\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 5.04, NNZs: 4, Bias: 0.137784, T: 750, Avg. loss: 286.253050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.59, NNZs: 4, Bias: 0.133011, T: 800, Avg. loss: 288.096673\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 5.11, NNZs: 4, Bias: 0.126778, T: 850, Avg. loss: 287.736859\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.35, NNZs: 4, Bias: 0.122473, T: 900, Avg. loss: 319.225137\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.11, NNZs: 4, Bias: 0.117112, T: 950, Avg. loss: 261.820930\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 3.99, NNZs: 4, Bias: 0.113382, T: 1000, Avg. loss: 223.475752\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 3.60, NNZs: 4, Bias: 0.109739, T: 1050, Avg. loss: 254.842847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 3.32, NNZs: 4, Bias: 0.105407, T: 1100, Avg. loss: 150.649001\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3.61, NNZs: 4, Bias: 0.100969, T: 1150, Avg. loss: 193.332217\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 3.80, NNZs: 4, Bias: 0.098777, T: 1200, Avg. loss: 234.349499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 3.51, NNZs: 4, Bias: 0.094686, T: 1250, Avg. loss: 201.667893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 3.96, NNZs: 4, Bias: 0.090764, T: 1300, Avg. loss: 145.583636\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 3.78, NNZs: 4, Bias: 0.087812, T: 1350, Avg. loss: 235.730151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3.29, NNZs: 4, Bias: 0.085250, T: 1400, Avg. loss: 166.467432\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3.17, NNZs: 4, Bias: 0.082701, T: 1450, Avg. loss: 163.438122\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3.23, NNZs: 4, Bias: 0.080318, T: 1500, Avg. loss: 120.413358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3.37, NNZs: 4, Bias: 0.076953, T: 1550, Avg. loss: 163.044272\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3.38, NNZs: 4, Bias: 0.074565, T: 1600, Avg. loss: 153.427998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3.37, NNZs: 4, Bias: 0.071338, T: 1650, Avg. loss: 175.670398\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3.34, NNZs: 4, Bias: 0.069144, T: 1700, Avg. loss: 143.920170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3.13, NNZs: 4, Bias: 0.067047, T: 1750, Avg. loss: 139.566435\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 35 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_estimator.fit(X_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.85931351,  1.14843782, -0.24904998, -0.52056329]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_estimator.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#array([[-2.85931351,  1.14843782, -0.24904998, -0.52056329]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
