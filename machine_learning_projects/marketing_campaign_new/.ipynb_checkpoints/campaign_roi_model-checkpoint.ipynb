{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Campaign ROI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Objective: create ML model to select target customers within customer segment as part of given campaign\n",
    "- Customers are selected within the segment based on avg customer clv\n",
    "- A higher avg customer clv will allow for a proportionally lower decision threshold, and viceversa\n",
    "- Duration cannot be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/data_ready.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.y\n",
    "duration = df.duration\n",
    "df.drop(['y', 'duration'], axis=1, inplace=True)\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size = 0.33, \n",
    "                                                    random_state=2, \n",
    "                                                    shuffle = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape:  (27595, 28)\n",
      "y Train Shape:  (27595,)\n",
      "X Test Shape:  (13593, 28)\n",
      "y Test Shape:  (13593,)\n"
     ]
    }
   ],
   "source": [
    "print('X Train Shape: ', X_train.shape)\n",
    "print('y Train Shape: ', y_train.shape)\n",
    "print('X Test Shape: ', X_test.shape)\n",
    "print('y Test Shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluating both online SVM (hinge) and Logistic Regression (huber) \n",
    "#Notice target classes are highly imbalanced\n",
    "param_search = {'loss' : ['hinge','huber'], \n",
    "                'alpha':[0.25,0.5,0.75], \n",
    "                'penalty':['l2'],\n",
    "                'shuffle':[True], \n",
    "                'learning_rate':['optimal'],\n",
    "                'class_weight':['balanced'],\n",
    "                'verbose':[1], \n",
    "               'max_iter':[100], \n",
    "               'tol': [1e-3], \n",
    "               'random_state':[22]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_search, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.44, NNZs: 28, Bias: -0.384444, T: 9199, Avg. loss: 0.548898\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.383742, T: 18398, Avg. loss: 0.532487\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.373864, T: 27597, Avg. loss: 0.542197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.375940, T: 36796, Avg. loss: 0.540919\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.46, NNZs: 28, Bias: -0.370361, T: 45995, Avg. loss: 0.537397\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.369908, T: 55194, Avg. loss: 0.541684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.367317, T: 64393, Avg. loss: 0.539294\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.44, NNZs: 28, Bias: -0.386728, T: 18397, Avg. loss: 0.547049\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.378646, T: 36794, Avg. loss: 0.540897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.374023, T: 55191, Avg. loss: 0.540615\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.374752, T: 73588, Avg. loss: 0.540814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.373060, T: 91985, Avg. loss: 0.543103\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.374733, T: 110382, Avg. loss: 0.544037\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.370754, T: 128779, Avg. loss: 0.543270\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.405870, T: 9199, Avg. loss: 0.051501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.414393, T: 18398, Avg. loss: 0.049780\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.28, NNZs: 28, Bias: -0.416999, T: 27597, Avg. loss: 0.049363\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.418807, T: 36796, Avg. loss: 0.049229\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.420823, T: 45995, Avg. loss: 0.049049\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.422083, T: 55194, Avg. loss: 0.048940\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.28, NNZs: 28, Bias: -0.423223, T: 64393, Avg. loss: 0.048847\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.27, NNZs: 28, Bias: -0.142072, T: 18397, Avg. loss: 0.075581\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.28, NNZs: 28, Bias: -0.171593, T: 36794, Avg. loss: 0.070015\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.28, NNZs: 28, Bias: -0.188234, T: 55191, Avg. loss: 0.068116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.199694, T: 73588, Avg. loss: 0.066932\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.208669, T: 91985, Avg. loss: 0.066087\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.215702, T: 110382, Avg. loss: 0.065450\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.221573, T: 128779, Avg. loss: 0.064894\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.226569, T: 147176, Avg. loss: 0.064405\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.29, NNZs: 28, Bias: -0.231069, T: 165573, Avg. loss: 0.064011\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 9 epochs took 0.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.42, NNZs: 28, Bias: -0.369482, T: 9199, Avg. loss: 0.545343\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.367003, T: 18398, Avg. loss: 0.544418\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.360451, T: 27597, Avg. loss: 0.550134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.362099, T: 36796, Avg. loss: 0.551063\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.359891, T: 45995, Avg. loss: 0.548765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.358202, T: 55194, Avg. loss: 0.551073\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.42, NNZs: 28, Bias: -0.375852, T: 18397, Avg. loss: 0.547142\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.364992, T: 36794, Avg. loss: 0.549190\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.362793, T: 55191, Avg. loss: 0.550519\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.362107, T: 73588, Avg. loss: 0.551747\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.361791, T: 91985, Avg. loss: 0.552754\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.43, NNZs: 28, Bias: -0.362768, T: 110382, Avg. loss: 0.553256\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.20, NNZs: 28, Bias: -0.233821, T: 9199, Avg. loss: 0.067637\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.20, NNZs: 28, Bias: -0.239770, T: 18398, Avg. loss: 0.066523\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.20, NNZs: 28, Bias: -0.243527, T: 27597, Avg. loss: 0.066009\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.20, NNZs: 28, Bias: -0.245830, T: 36796, Avg. loss: 0.065822\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.20, NNZs: 28, Bias: -0.247862, T: 45995, Avg. loss: 0.065611\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.20, NNZs: 28, Bias: -0.249427, T: 55194, Avg. loss: 0.065467\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.20, NNZs: 28, Bias: -0.250810, T: 64393, Avg. loss: 0.065337\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.18, NNZs: 28, Bias: 0.017392, T: 18397, Avg. loss: 0.088608\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.18, NNZs: 28, Bias: 0.007714, T: 36794, Avg. loss: 0.087015\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 28, Bias: 0.002311, T: 55191, Avg. loss: 0.086413\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.18, NNZs: 28, Bias: -0.001466, T: 73588, Avg. loss: 0.086040\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.18, NNZs: 28, Bias: -0.004458, T: 91985, Avg. loss: 0.085758\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.18, NNZs: 28, Bias: -0.006777, T: 110382, Avg. loss: 0.085566\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.18, NNZs: 28, Bias: -0.008757, T: 128779, Avg. loss: 0.085376\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.41, NNZs: 28, Bias: -0.371681, T: 9199, Avg. loss: 0.535148\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.42, NNZs: 28, Bias: -0.367760, T: 18398, Avg. loss: 0.546294\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 28, Bias: -0.363359, T: 27597, Avg. loss: 0.551300\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.41, NNZs: 28, Bias: -0.362087, T: 36796, Avg. loss: 0.552811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.42, NNZs: 28, Bias: -0.361799, T: 45995, Avg. loss: 0.551353\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.41, NNZs: 28, Bias: -0.360347, T: 55194, Avg. loss: 0.552585\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.40, NNZs: 28, Bias: -0.382679, T: 18397, Avg. loss: 0.545349\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 28, Bias: -0.376643, T: 36794, Avg. loss: 0.543597\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.40, NNZs: 28, Bias: -0.375676, T: 55191, Avg. loss: 0.544526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.40, NNZs: 28, Bias: -0.373826, T: 73588, Avg. loss: 0.546355\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.40, NNZs: 28, Bias: -0.373437, T: 91985, Avg. loss: 0.547535\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.40, NNZs: 28, Bias: -0.374105, T: 110382, Avg. loss: 0.547692\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.40, NNZs: 28, Bias: -0.373264, T: 128779, Avg. loss: 0.546798\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 7 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 28, Bias: -0.159014, T: 9199, Avg. loss: 0.074847\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.16, NNZs: 28, Bias: -0.160356, T: 18398, Avg. loss: 0.074481\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.16, NNZs: 28, Bias: -0.161299, T: 27597, Avg. loss: 0.074294\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.16, NNZs: 28, Bias: -0.161886, T: 36796, Avg. loss: 0.074279\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.16, NNZs: 28, Bias: -0.162372, T: 45995, Avg. loss: 0.074212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 28, Bias: -0.162751, T: 55194, Avg. loss: 0.074182\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.15, NNZs: 28, Bias: 0.004607, T: 18397, Avg. loss: 0.088105\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.15, NNZs: 28, Bias: 0.001390, T: 36794, Avg. loss: 0.087576\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.15, NNZs: 28, Bias: -0.000381, T: 55191, Avg. loss: 0.087374\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.15, NNZs: 28, Bias: -0.001612, T: 73588, Avg. loss: 0.087258\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.15, NNZs: 28, Bias: -0.002562, T: 91985, Avg. loss: 0.087162\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.15, NNZs: 28, Bias: -0.003300, T: 110382, Avg. loss: 0.087116\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 6 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.44, NNZs: 28, Bias: -0.382045, T: 27595, Avg. loss: 0.561674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.44, NNZs: 28, Bias: -0.369329, T: 55190, Avg. loss: 0.544815\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.44, NNZs: 28, Bias: -0.368222, T: 82785, Avg. loss: 0.542201\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.44, NNZs: 28, Bias: -0.370735, T: 110380, Avg. loss: 0.545668\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.364369, T: 137975, Avg. loss: 0.544191\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.365166, T: 165570, Avg. loss: 0.544128\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.364049, T: 193165, Avg. loss: 0.545829\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.45, NNZs: 28, Bias: -0.365540, T: 220760, Avg. loss: 0.545237\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 8 epochs took 0.06 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=2),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'loss': ['hinge', 'huber'], 'alpha': [0.25, 0.5, 0.75], 'penalty': ['l2'], 'shuffle': [True], 'learning_rate': ['optimal'], 'class_weight': ['balanced'], 'verbose': [1], 'max_iter': [100], 'tol': [0.001], 'random_state': [22]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Hyperparameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.25, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best Estimator Hyperparameters:')\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicting on Test set\n",
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.7180166262046641\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on Test Set:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating methods to retrain and repredict with online learning algo on a rolling window basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(df, now):\n",
    "    \n",
    "    days_training = 21\n",
    "    days_prediction = 7\n",
    "    \n",
    "    modeling_start_day = pd.Timestamp(now - timedelta(days=days_training))\n",
    "    modeling_end_day = pd.Timestamp(now - timedelta(days=1))\n",
    "    \n",
    "    prediction_start_day = pd.Timestamp(now)\n",
    "    prediction_end_day = pd.Timestamp(now + timedelta(days=days_prediction))\n",
    "    \n",
    "    modeling_set = df[(df.index > modeling_start_day) & (df.index < modeling_end_day)]\n",
    "    prediction_set = df[(df.index > prediction_start_day) & (df.index < prediction_end_day)]\n",
    "    \n",
    "    return modeling_set, prediction_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_prep(df):\n",
    "    \n",
    "    y = df.y.copy()\n",
    "    duration = df.duration\n",
    "    df.drop(['y', 'duration'], axis=1, inplace=True)\n",
    "    X = df.copy()\n",
    "    \n",
    "    #X = np.array(X)\n",
    "    #y = np.array(y)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state=2, \n",
    "                                                    shuffle = None)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    estimator = SGDClassifier()\n",
    "    \n",
    "    #Evaluating both online SVM (hinge) and Logistic Regression (huber) \n",
    "    #Notice target classes are highly imbalanced\n",
    "    param_search = {'loss' : ['hinge','huber'], \n",
    "                    'alpha':[0.25,0.5,0.75], \n",
    "                    'penalty':['l2'],\n",
    "                    'shuffle':[True], \n",
    "                    'learning_rate':['optimal'],\n",
    "                    'class_weight':['balanced'],\n",
    "                    'verbose':[1], \n",
    "                    'max_iter':[100], \n",
    "                    'tol': [1e-3], \n",
    "                    'random_state':[22]}\n",
    "\n",
    "    cv = TimeSeriesSplit(n_splits=2)\n",
    "    \n",
    "    gs = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_search, scoring = 'accuracy')\n",
    "    \n",
    "    gs.fit(X_train,y_train)\n",
    "    \n",
    "    print(gs.best_estimator_.coef_)\n",
    "    \n",
    "    #Predicting on Test set\n",
    "    y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "    print('Accuracy on Test Set:', accuracy_score(y_test,y_pred))\n",
    "    \n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_online(X,y, best_estimator_):\n",
    "    \n",
    "    print('Chosen Estimator Coefficients:')\n",
    "    print(best_estimator_.coef_)\n",
    "    \n",
    "    print('Chosen Estimator Hyperparameters:')\n",
    "    print(best_estimator_)\n",
    "    \n",
    "    return best_estimator_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Steps:\n",
    "#1 - split data after setting now (should set now on rolling window basis to demo entire thing)\n",
    "#2 - data prep mod and pred datasets\n",
    "#3 - train model with train_model with input mod dataset\n",
    "#4 - predict with online_predict with input pred dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now() - timedelta(3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, pred = split_data(df, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "X_mod, y_mod = data_prep(mod)\n",
    "X_pred, y_pred = data_prep(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.92, NNZs: 24, Bias: 0.316905, T: 179, Avg. loss: 1.488864\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.64, NNZs: 24, Bias: 0.151976, T: 358, Avg. loss: 1.184963\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.69, NNZs: 24, Bias: 0.195289, T: 537, Avg. loss: 1.087385\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.65, NNZs: 24, Bias: 0.217886, T: 716, Avg. loss: 1.063068\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.68, NNZs: 24, Bias: 0.235409, T: 895, Avg. loss: 1.024222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.68, NNZs: 24, Bias: 0.232876, T: 1074, Avg. loss: 1.122068\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.68, NNZs: 24, Bias: 0.230519, T: 1253, Avg. loss: 1.104401\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.66, NNZs: 24, Bias: 0.221458, T: 1432, Avg. loss: 1.089591\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.66, NNZs: 24, Bias: 0.228645, T: 1611, Avg. loss: 1.052587\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.66, NNZs: 24, Bias: 0.232938, T: 1790, Avg. loss: 1.025052\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.50, NNZs: 24, Bias: -0.412436, T: 356, Avg. loss: 1.285218\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.66, NNZs: 24, Bias: -0.321932, T: 712, Avg. loss: 0.935136\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.62, NNZs: 24, Bias: -0.296199, T: 1068, Avg. loss: 0.829719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.61, NNZs: 24, Bias: -0.268842, T: 1424, Avg. loss: 0.805883\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.65, NNZs: 24, Bias: -0.243129, T: 1780, Avg. loss: 0.849867\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.65, NNZs: 24, Bias: -0.228005, T: 2136, Avg. loss: 0.863470\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.65, NNZs: 24, Bias: -0.213277, T: 2492, Avg. loss: 0.838847\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.63, NNZs: 24, Bias: -0.209655, T: 2848, Avg. loss: 0.859686\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.63, NNZs: 24, Bias: -0.196878, T: 3204, Avg. loss: 0.861361\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 9 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.20, NNZs: 24, Bias: -0.004901, T: 179, Avg. loss: 0.092952\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.008752, T: 358, Avg. loss: 0.091174\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 24, Bias: -0.007517, T: 537, Avg. loss: 0.090506\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.010380, T: 716, Avg. loss: 0.089540\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.010996, T: 895, Avg. loss: 0.088269\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.18, NNZs: 24, Bias: -0.010633, T: 1074, Avg. loss: 0.089154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.18, NNZs: 24, Bias: -0.011098, T: 1253, Avg. loss: 0.088881\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.18, NNZs: 24, Bias: -0.011721, T: 1432, Avg. loss: 0.088683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 24, Bias: -0.012671, T: 1611, Avg. loss: 0.088139\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 24, Bias: -0.013115, T: 1790, Avg. loss: 0.087872\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 24, Bias: -0.232620, T: 356, Avg. loss: 0.082031\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.229075, T: 712, Avg. loss: 0.077781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.229444, T: 1068, Avg. loss: 0.076039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.230445, T: 1424, Avg. loss: 0.075061\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.230651, T: 1780, Avg. loss: 0.075419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.230667, T: 2136, Avg. loss: 0.075569\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.230962, T: 2492, Avg. loss: 0.075135\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.17, NNZs: 24, Bias: -0.231137, T: 2848, Avg. loss: 0.075329\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 8 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.60, NNZs: 24, Bias: 0.055392, T: 179, Avg. loss: 1.087920\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.46, NNZs: 24, Bias: 0.047988, T: 358, Avg. loss: 1.116935\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.50, NNZs: 24, Bias: 0.072907, T: 537, Avg. loss: 1.062943\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.48, NNZs: 24, Bias: 0.084919, T: 716, Avg. loss: 1.030723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.48, NNZs: 24, Bias: 0.088406, T: 895, Avg. loss: 0.988177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.48, NNZs: 24, Bias: 0.093755, T: 1074, Avg. loss: 1.036915\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.48, NNZs: 24, Bias: 0.097861, T: 1253, Avg. loss: 1.028061\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.48, NNZs: 24, Bias: 0.107666, T: 1432, Avg. loss: 1.035310\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.48, NNZs: 24, Bias: 0.111259, T: 1611, Avg. loss: 1.017415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.49, NNZs: 24, Bias: 0.116918, T: 1790, Avg. loss: 1.002418\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.30, NNZs: 24, Bias: -0.527024, T: 356, Avg. loss: 1.000270\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.41, NNZs: 24, Bias: -0.472585, T: 712, Avg. loss: 0.757803\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 24, Bias: -0.445459, T: 1068, Avg. loss: 0.705635\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.41, NNZs: 24, Bias: -0.430728, T: 1424, Avg. loss: 0.699541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.42, NNZs: 24, Bias: -0.418836, T: 1780, Avg. loss: 0.723072\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.43, NNZs: 24, Bias: -0.406243, T: 2136, Avg. loss: 0.728465\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.43, NNZs: 24, Bias: -0.399337, T: 2492, Avg. loss: 0.716798\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.42, NNZs: 24, Bias: -0.394196, T: 2848, Avg. loss: 0.730132\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.42, NNZs: 24, Bias: -0.388459, T: 3204, Avg. loss: 0.729681\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 9 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.10, NNZs: 24, Bias: -0.050117, T: 179, Avg. loss: 0.089897\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.10, NNZs: 24, Bias: -0.048795, T: 358, Avg. loss: 0.089770\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.10, NNZs: 24, Bias: -0.048174, T: 537, Avg. loss: 0.089468\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.10, NNZs: 24, Bias: -0.047951, T: 716, Avg. loss: 0.089005\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.10, NNZs: 24, Bias: -0.048265, T: 895, Avg. loss: 0.088404\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.10, NNZs: 24, Bias: -0.048083, T: 1074, Avg. loss: 0.088932\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 24, Bias: -0.207469, T: 356, Avg. loss: 0.082397\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.09, NNZs: 24, Bias: -0.205689, T: 712, Avg. loss: 0.080529\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.09, NNZs: 24, Bias: -0.205874, T: 1068, Avg. loss: 0.079771\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.09, NNZs: 24, Bias: -0.206375, T: 1424, Avg. loss: 0.079328\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.09, NNZs: 24, Bias: -0.206479, T: 1780, Avg. loss: 0.079536\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 24, Bias: -0.206486, T: 2136, Avg. loss: 0.079628\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 24, Bias: -0.206634, T: 2492, Avg. loss: 0.079422\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.41, NNZs: 24, Bias: -0.152395, T: 179, Avg. loss: 0.891709\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.35, NNZs: 24, Bias: -0.125462, T: 358, Avg. loss: 0.951649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.37, NNZs: 24, Bias: -0.115015, T: 537, Avg. loss: 0.925083\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.37, NNZs: 24, Bias: -0.104893, T: 716, Avg. loss: 0.906781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.37, NNZs: 24, Bias: -0.098604, T: 895, Avg. loss: 0.871503\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.38, NNZs: 24, Bias: -0.092370, T: 1074, Avg. loss: 0.910642\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.38, NNZs: 24, Bias: -0.093857, T: 1253, Avg. loss: 0.898941\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.37, NNZs: 24, Bias: -0.087882, T: 1432, Avg. loss: 0.899380\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.37, NNZs: 24, Bias: -0.083928, T: 1611, Avg. loss: 0.886589\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.37, NNZs: 24, Bias: -0.084470, T: 1790, Avg. loss: 0.874272\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 24, Bias: -0.484173, T: 356, Avg. loss: 0.945129\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.35, NNZs: 24, Bias: -0.452761, T: 712, Avg. loss: 0.727994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.33, NNZs: 24, Bias: -0.443800, T: 1068, Avg. loss: 0.683254\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.32, NNZs: 24, Bias: -0.438997, T: 1424, Avg. loss: 0.671353\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.34, NNZs: 24, Bias: -0.432446, T: 1780, Avg. loss: 0.688101\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.34, NNZs: 24, Bias: -0.428019, T: 2136, Avg. loss: 0.688802\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.33, NNZs: 24, Bias: -0.426655, T: 2492, Avg. loss: 0.677751\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.33, NNZs: 24, Bias: -0.424259, T: 2848, Avg. loss: 0.686302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.33, NNZs: 24, Bias: -0.421369, T: 3204, Avg. loss: 0.684877\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 9 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 24, Bias: -0.049991, T: 179, Avg. loss: 0.090406\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.07, NNZs: 24, Bias: -0.049107, T: 358, Avg. loss: 0.090409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 24, Bias: -0.048692, T: 537, Avg. loss: 0.090209\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 24, Bias: -0.048543, T: 716, Avg. loss: 0.089900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 24, Bias: -0.048753, T: 895, Avg. loss: 0.089499\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.07, NNZs: 24, Bias: -0.048631, T: 1074, Avg. loss: 0.089852\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.170389, T: 356, Avg. loss: 0.084674\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.169201, T: 712, Avg. loss: 0.083388\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.169324, T: 1068, Avg. loss: 0.082883\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.169659, T: 1424, Avg. loss: 0.082587\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.169728, T: 1780, Avg. loss: 0.082726\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.169733, T: 2136, Avg. loss: 0.082787\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.169831, T: 2492, Avg. loss: 0.082650\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 24, Bias: -0.073637, T: 533, Avg. loss: 0.090025\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.075294, T: 1066, Avg. loss: 0.088727\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.075311, T: 1599, Avg. loss: 0.088953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.075429, T: 2132, Avg. loss: 0.088833\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.075546, T: 2665, Avg. loss: 0.088807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.075464, T: 3198, Avg. loss: 0.088950\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.06, NNZs: 24, Bias: -0.075418, T: 3731, Avg. loss: 0.088865\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[[ 0.         -0.01324855  0.02413147 -0.00327032 -0.00510643  0.01099745\n",
      "   0.02014456 -0.02087035  0.01430147 -0.01242296  0.00737951  0.01324855\n",
      "   0.00380792 -0.00483253  0.00562529 -0.01283703  0.00945093 -0.00018139\n",
      "  -0.01324855 -0.01324855 -0.00802273 -0.00018139 -0.0011292   0.01324855\n",
      "   0.          0.          0.         -0.00402247]]\n",
      "Accuracy on Test Set: 0.7921348314606742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "best_est = train_model(X_mod,y_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Estimator Coefficients:\n",
      "[[ 0.         -0.01324855  0.02413147 -0.00327032 -0.00510643  0.01099745\n",
      "   0.02014456 -0.02087035  0.01430147 -0.01242296  0.00737951  0.01324855\n",
      "   0.00380792 -0.00483253  0.00562529 -0.01283703  0.00945093 -0.00018139\n",
      "  -0.01324855 -0.01324855 -0.00802273 -0.00018139 -0.0011292   0.01324855\n",
      "   0.          0.          0.         -0.00402247]]\n",
      "Chosen Estimator Hyperparameters:\n",
      "SGDClassifier(alpha=0.75, average=False, class_weight='balanced',\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='huber', max_iter=100,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=22, shuffle=True, tol=0.001,\n",
      "       validation_fraction=0.1, verbose=1, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_online(X_pred, y_pred, best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1194,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df[(df.index < pd.Timestamp(now + timedelta(7))) & (df.index > pd.Timestamp(now))].y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include Tuning Functionality Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune According to Campaign ROI as defined by differenced between avg loan and deposit interest rates and fixed/var campaign costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1, max_iter=100, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_conf_matrix(clf, X,y):\n",
    "    y_pred = clf.predict(X)\n",
    "    cmx = pd.DataFrame(confusion_matrix(y, y_pred), \n",
    "                   index = ['No', 'Yes'],\n",
    "                   columns = ['No', 'Yes'])\n",
    "    return cmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(cmx):\n",
    "    cmap = mpl.colors.ListedColormap(['green'])\n",
    "    cmap1 = mpl.colors.ListedColormap(['red'])\n",
    "    mask1 = (cmx.isin([cmx.iloc[0,0],cmx.iloc[1,1]]))\n",
    "    \n",
    "    f, ax = plt.subplots(figsize = (9,6))\n",
    "    sns.heatmap(cmx, annot=True, fmt = 'g', cmap = cmap,\n",
    "            cbar = False, annot_kws={\"size\": 20},\n",
    "            ax=ax)\n",
    "    sns.heatmap(cmx, mask=mask1 , cmap=cmap1, cbar=False)\n",
    "\n",
    "    ax.set_ylabel('True label', fontsize = 15)\n",
    "    ax.set_xlabel('Predicted label', fontsize = 15)\n",
    "    ax.set_title(\"Confusion Matrix\", fontsize = 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating Confusion Matrix for Dirty Model:\n",
    "cmx = make_conf_matrix(clf, X, y)\n",
    "plot_conf_matrix(cmx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign Targets: 9527\n"
     ]
    }
   ],
   "source": [
    "print(\"Campaign Targets:\", cmx.iloc[1,1]+cmx.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accept_est = cmx.iloc[1,1]\n",
    "reject_est = cmx.iloc[0,1]\n",
    "total_targeted = accept_est+reject_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#enhancement: create rolling window logistic regression predicting next month's subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xex = X[['year','month','age','job','marital']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-05-05</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-05</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-05</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-05</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-05</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  month  age  job  marital\n",
       "Date                                      \n",
       "2008-05-05  2008      5   56    3        1\n",
       "2008-05-05  2008      5   57    7        1\n",
       "2008-05-05  2008      5   37    7        1\n",
       "2008-05-05  2008      5   40    0        1\n",
       "2008-05-05  2008      5   56    7        1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xex.reset_index(drop=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y.reset_index(drop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "Xex.drop(columns='Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xex,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array([1,2,3,1,1]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each value in decision threshold range, \n",
    "    #create logistic regression\n",
    "    #calculate profit for campaign with average CLV for next x months\n",
    "#select the logistic regression yielding the highest ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campaign ROI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r 'pred_clv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>7763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>4374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>6685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>5175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  count\n",
       "0  2008      5   7763\n",
       "1  2008      6   4374\n",
       "2  2008      7   6685\n",
       "3  2008      8   5175\n",
       "4  2008     10     67"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_monthly = df[['year','month','day']].groupby(by=['year','month']).count()\n",
    "customers_monthly = customers_monthly.reset_index()\n",
    "customers_monthly.rename(columns = {'day':'count'},inplace=True)\n",
    "customers_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customers_monthly['perc_of_total'] = customers_monthly['count']/customers_monthly['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_revenue(accept_est, pred_clv):\n",
    "    return accept_est*pred_clv     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate revenue on a monthly basis comparing with predicted customer clv\n",
    "#compare y with y pred and do a monthly classification matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 32, index implies 26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-78127d160074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrevenue_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_revenue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomers_monthly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_clv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-3169b12f5981>\u001b[0m in \u001b[0;36mcalc_revenue\u001b[0;34m(accept_est, pred_clv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_revenue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccept_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_clv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccept_est\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpred_clv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         return construct_result(left, result,\n\u001b[0;32m-> 1071\u001b[0;31m                                 index=left.index, name=res_name, dtype=None)\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_construct_result\u001b[0;34m(left, result, index, name, dtype)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0menough\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mstill\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mto\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \"\"\"\n\u001b[0;32m--> 980\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    260\u001b[0m                             \u001b[0;34m'Length of passed values is {val}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                             \u001b[0;34m'index implies {ind}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                             .format(val=len(data), ind=len(index)))\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 32, index implies 26"
     ]
    }
   ],
   "source": [
    "revenue_est = calc_revenue(customers_monthly['count'], pred_clv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[446637.00753979],\n",
       "       [501670.21111085],\n",
       "       [601489.25756288],\n",
       "       [581586.91486844],\n",
       "       [618839.30795804],\n",
       "       [657785.29383017],\n",
       "       [668546.34464979],\n",
       "       [602267.51151426],\n",
       "       [433297.83443806],\n",
       "       [522265.27937144],\n",
       "       [562186.62036074],\n",
       "       [390829.6445475 ],\n",
       "       [468068.19524095]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revenue_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
